{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 31012,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "üåç‚úàÔ∏è Nomad: A Gemini/LangGraph Travel Agent_v1",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "google_gemini_2_0_flash_api_api_gemini_2_0_flash_1_path = kagglehub.model_download('google/gemini-2.0-flash-api/Api/gemini-2.0-flash/1')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "DP0lp22brLY4"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1 align=\"center\" style=\"color:#4F46E5; background-color:#EEF2FF; padding:15px; border-radius:10px; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);\">üåç‚úàÔ∏è Conversational Travel Recommender Agent ü§ñ</h1>\n",
        "\n",
        "<div style=\"background-color:#F0FDF4; padding:15px; border-radius:8px; margin-top:20px; border:1px dashed #22C55E;\">\n",
        "  <h2 style=\"color:#15803D;\">üìã Project Overview</h2>\n",
        "  <p style=\"color:gray\">Welcome to this Capstone Project for the Google & Kaggle 5-Day Generative AI Intensive Course (2025Q1)! This notebook implements a <strong>Conversational Travel Recommender Agent</strong> named \"Nomad\". The agent interactively guides users through preference gathering (vibe, activities, weather, budget) using a conversational flow managed by LangGraph. It then leverages the Google Gemini API for generating personalized city recommendations, enhanced with real-world context like images and weather via Function Calling, and detailed Point of Interest (POI) information using Retrieval-Augmented Generation (RAG) on the <a href=\"https://github.com/baturin/wikivoyage-listings\" target=\"_blank\">Wikivoyage dataset</a>. Grounding via Google Search is used to find relevant events for the selected city.</p>\n",
        "</div>\n",
        "\n",
        "<h2 style=\"color:#0F766E; border-bottom:3px solid #0D9488; padding-bottom:8px;\">üó∫Ô∏è Approach & Capabilities Showcase</h2>\n",
        "\n",
        "<p style=\"color:#374151; background-color:#EEF2FF; padding:15px; border-radius:10px; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);\">This project demonstrates a multi-phase agentic workflow orchestrated using LangGraph:</p>\n",
        "\n",
        "<h3 style=\"color:#065F46;\">Phase 1: Preference Gathering & Recommendation</h3>\n",
        "<ol style=\"background-color:#ECFDF5; padding:15px 15px 15px 40px; border-radius:8px; border:2px dashed #047857;\">\n",
        "  <li style=\"color:#047857; margin-bottom:10px;\"><strong>Engage User & Gather Preferences:</strong> Initiates a conversation using <strong>LangGraph</strong> to manage state. Employs an LLM (Gemini) node to ask sequential questions about travel 'vibe', 'activities', 'weather', and 'budget'.</li>\n",
        "  <li style=\"color:#047857; margin-bottom:10px;\"><strong>Parse User Input:</strong> Uses another LLM node configured for <strong>Structured Output (JSON)</strong> to reliably parse the user's responses and store them in the agent's state.</li>\n",
        "  <li style=\"color:#047857; margin-bottom:10px;\"><strong>Generate City Recommendations:</strong> Once preferences are complete, triggers an LLM call (Gemini) requesting 3-5 diverse global cities, formatted using <strong>Structured Output (JSON)</strong>.</li>\n",
        "  <li style=\"color:#047857; margin-bottom:10px;\"><strong>Verify & Enhance Recommendations:</strong> Checks generated cities against the loaded Wikivoyage dataset to flag which have detailed POI data available. Uses <strong>Function Calling</strong> to trigger parallel calls to the Unsplash API (via a custom tool) to fetch relevant images for each recommendation.</li>\n",
        "  <li style=\"color:#047857; margin-bottom:10px;\"><strong>Present & Select:</strong> Displays the recommendations with images and details in a user-friendly HTML format. Prompts the user to select a city (marked with ‚úÖ) for further exploration.</li>\n",
        "</ol>\n",
        "\n",
        "<h3 style=\"color:#065F46;\">Phase 2: Detailed Exploration & Q&A</h3>\n",
        "<ol start=\"6\" style=\"background-color:#ECFDF5; padding:15px 15px 15px 40px; border-radius:8px; border:2px dashed #047857; margin-top:15px;\">\n",
        "  <li style=\"color:#047857; margin-bottom:10px;\"><strong>Gather Detailed Information:</strong> For the selected city:\n",
        "      <ul>\n",
        "          <li>Performs <strong>RAG</strong> using ChromaDB (vector store) and Gemini embeddings (`text-embedding-004`) to find relevant POIs from Wikivoyage based on user preferences.</li>\n",
        "          <li>Fetches live weather data via a <strong>direct Python call</strong> to the predefined OpenWeatherMap tool function (`get_weather`).</li>\n",
        "          <li>Calls the Gemini LLM configured with <strong>Grounding</strong> (Google Search). This LLM uses the RAG context and grounding results to generate a city summary, POI descriptions, and a list of current/upcoming events, outputting them using <strong>Structured Output (JSON)</strong>. (Note: The LLM itself does not call the weather tool in this phase).</li>\n",
        "      </ul>\n",
        "  </li>\n",
        "  <li style=\"color:#047857; margin-bottom:10px;\"><strong>Display City Details:</strong> Presents a comprehensive overview including the generated summary, the fetched weather, suggested POIs, and events using HTML.</li>\n",
        "  <li style=\"color:#047857;\"><strong>Interactive Q&A:</strong> Enters a loop allowing the user to ask follow-up questions about the selected city. Answers are generated by:\n",
        "      <ul>\n",
        "          <li>Performing <strong>RAG</strong> again on the Wikivoyage POIs based on the user's question.</li>\n",
        "          <li>Feeding the RAG context and conversation history to a Gemini LLM to generate a direct answer.</li>\n",
        "      </ul>\n",
        "  </li>\n",
        "</ol>\n",
        "\n",
        "<div style=\"background-color:#FFFBEB; padding:15px; border-radius:8px; margin-top:20px; border:1px solid #FBBF24;\">\n",
        "  <h3 style=\"color:#B45309;\">üí° Demo Mode for Evaluation üí°</h3>\n",
        "  <p style=\"color:#78350F;\">This notebook includes a flag `INTERACTIVE_MODE` near the execution cells.\n",
        "  <ul>\n",
        "    <li style=\"color:#78350F;\">Set `INTERACTIVE_MODE = True` (Default/Intended Use): Enables the full interactive experience where the agent prompts you for input via the console.</li>\n",
        "    <li style=\"color:#78350F;\">Set `INTERACTIVE_MODE = False` (For Kaggle Evaluation): The agent will use predefined demo inputs for preferences, automatically select the first valid city, and ask predefined Q&A questions. <strong>This ensures the notebook runs end-to-end without halting, as required by the competition rules.</strong></li>\n",
        "  </ul>\n",
        "  Please ensure `INTERACTIVE_MODE = False` if submitting for automated evaluation.\n",
        "  </p>\n",
        "</div>\n",
        "\n",
        "<div style=\"background-color:#EFF6FF; padding:15px; border-radius:8px; margin-top:20px; border:1px dashed #3B82F6;\">\n",
        "  <h2 style=\"color:#1E40AF; text-align:center;\">üõ†Ô∏è Key Technologies & Capabilities Demonstrated üí°</h2>\n",
        "  <ul style=\"list-style-type:none; padding-left:20px;\">\n",
        "    <li style=\"color:#1E40AF; margin-bottom:8px;\"><span style=\"display:inline-block; width:25px; text-align:center;\">üß†</span> <strong>Google Gemini API:</strong> Core LLM for conversational generation, reasoning, structured output, and grounding (`gemini-2.0-flash`, `gemini-1.5-flash-latest`).</li>\n",
        "    <li style=\"color:#1E40AF; margin-bottom:8px;\"><span style=\"display:inline-block; width:25px; text-align:center;\">üîó</span> <strong>LangGraph:</strong> Framework for building the stateful, multi-step conversational agent.</li>\n",
        "    <li style=\"color:#1E40AF; margin-bottom:8px;\"><span style=\"display:inline-block; width:25px; text-align:center;\">üìö</span> <strong>RAG (Retrieval-Augmented Generation):</strong> Using Wikivoyage POI Embeddings (`text-embedding-004`) + ChromaDB (Vector Store) for contextual POI suggestions (Phase 2) and Q&A.</li>\n",
        "    <li style=\"color:#1E40AF; margin-bottom:8px;\"><span style=\"display:inline-block; width:25px; text-align:center;\">üìû</span> <strong>Function Calling / Tool Use:</strong> Defining tools (`@tool`) for external APIs (Unsplash, OpenWeatherMap). Used via LLM-triggered calls (LangGraph `ToolNode`) in Phase 1 for images, and via direct Python invocation in Phase 2 for weather.</li>\n",
        "    <li style=\"color:#1E40AF; margin-bottom:8px;\"><span style=\"display:inline-block; width:25px; text-align:center;\">üåê</span> <strong>Grounding (Google Search):</strong> Used by the LLM in Phase 2 to find current/upcoming events in the selected city.</li>\n",
        "    <li style=\"color:#1E40AF; margin-bottom:8px;\"><span style=\"display:inline-block; width:25px; text-align:center;\">üìã</span> <strong>Structured Output (JSON):</strong> Used for parsing user preferences, generating recommendations, and formatting detailed city information.</li>\n",
        "    <li style=\"color:#1E40AF; margin-bottom:8px;\"><span style=\"display:inline-block; width:25px; text-align:center;\">üíæ</span> <strong>Vector Store:</strong> ChromaDB for persistent storage and retrieval of POI embeddings.</li>\n",
        "    <li style=\"color:#1E40AF;\"><span style=\"display:inline-block; width:25px; text-align:center;\">üìä</span> <strong>Pandas:</strong> Data loading, cleaning, and preprocessing of the Wikivoyage dataset.</li>\n",
        "  </ul>\n",
        "</div>\n",
        "\n",
        "<div style=\"background-color:#FEF2F2; padding:15px; border-radius:8px; margin-top:20px; border:1px dashed #EF4444;\">\n",
        "  <h2 style=\"color:#B91C1C; text-align:center;\">üéØ Project Goal & Capstone Evaluation</h2>\n",
        "  <p style=\"text-align:center; color:gray\">The primary goal is to build a functional prototype demonstrating the effective integration of multiple Gen AI capabilities (LangGraph, RAG, Function Calling, Grounding, Structured Output) to create a personalized, interactive travel recommender. This notebook aims to meet the Capstone evaluation criteria, focusing on <strong>Use Case/Innovation</strong> and <strong>Documentation Quality</strong>, ensuring clarity in explanations and code, and providing a non-interactive mode for evaluation.</p>\n",
        "</div>\n",
        "\n",
        "<hr style=\"border:0; height:3px; background-image:linear-gradient(to right, rgba(0,0,0,0), rgba(79,70,229,0.75), rgba(0,0,0,0));\">\n",
        "\n",
        "<p align=\"center\" style=\"font-style:italic; color:#6B7280;\">Let's embark on building our intelligent travel companion! üó∫Ô∏è‚ú®</p>"
      ],
      "metadata": {
        "id": "MNe-3_72rLY6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color:#F0FDF4; padding:15px; border-radius:8px; margin-top:20px; border:1px dashed #22C55E;\">\n",
        "  <h2 style=\"color:#15803D; border-bottom: 2px solid #16A34A; padding-bottom: 5px;\">Step 1: Install Required Libraries</h2>\n",
        "  <p style=\"color:gray; margin-top:10px;\">\n",
        "    This first code cell sets up the necessary Python environment for the travel recommender agent. It performs two main actions:\n",
        "  </p>\n",
        "  <ol style=\"background-color:#ECFDF5; padding:10px 10px 10px 30px; border-radius:6px; border:1px solid #D1FAE5; margin-top:10px;\">\n",
        "    <li style=\"color:#065F46; margin-bottom:8px;\">\n",
        "      <strong>Uninstall Conflicting Packages:</strong> Uses <code>pip uninstall -qqy</code> to silently remove potentially pre-installed versions of certain libraries (like <code>google-generativeai</code>) within the Kaggle environment. This helps prevent version conflicts with the specific versions we need.\n",
        "    </li>\n",
        "    <li style=\"color:#065F46;\">\n",
        "      <strong>Install Core Dependencies:</strong> Uses <code>pip install -qU</code> to quietly install or upgrade the essential packages:\n",
        "      <ul style=\"margin-top: 5px; list-style-type: disc; padding-left: 20px;\">\n",
        "        <li><code>google-genai</code>: The official Google SDK for interacting with the Gemini API.</li>\n",
        "        <li><code>langgraph</code>: The library for building stateful, multi-actor applications like our conversational agent.</li>\n",
        "        <li><code>langchain-google-genai</code>: Provides LangChain integrations for Google's Generative AI models (used for <code>ChatGoogleGenerativeAI</code>).</li>\n",
        "        <li><code>chromadb</code>: The vector database client used for storing and querying Wikivoyage POI embeddings for RAG.</li>\n",
        "        <li><code>requests</code>: A standard library for making HTTP requests, needed by the Unsplash and OpenWeatherMap tools.</li>\n",
        "        <li><code>Pillow</code>: The Python Imaging Library, often required for image processing tasks or displaying images (like the graph visualization).</li>\n",
        "      </ul>\n",
        "    </li>\n",
        "  </ol>\n",
        "</div>"
      ],
      "metadata": {
        "id": "qhugA_WYrLY7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -qqy google-generativeai kfp jupyterlab-lsp jupyterlab\n",
        "\n",
        "!pip install -qU \\\n",
        "    'google-genai==1.7.0' \\\n",
        "    'langgraph==0.3.21' \\\n",
        "    'langchain-google-genai==2.1.2' \\\n",
        "    'chromadb==0.6.3' \\\n",
        "    'requests' \\\n",
        "    'Pillow' \\\n",
        "\n",
        "print(\"Required packages installed.\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-21T05:06:29.548849Z",
          "iopub.execute_input": "2025-04-21T05:06:29.549156Z",
          "iopub.status.idle": "2025-04-21T05:07:04.63238Z",
          "shell.execute_reply.started": "2025-04-21T05:06:29.549133Z",
          "shell.execute_reply": "2025-04-21T05:07:04.631596Z"
        },
        "id": "6h325ohGrLY8"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color:#F0FDF4; padding:15px; border-radius:8px; margin-top:20px; border:1px dashed #22C55E;\">\n",
        "  <h2 style=\"color:#15803D; border-bottom: 2px solid #16A34A; padding-bottom: 5px;\">Step 2: Import Libraries & Configure API Keys</h2>\n",
        "  <p style=\"color:gray; margin-top:10px;\">\n",
        "    With the required packages installed, this cell imports necessary libraries and attempts to configure the API keys needed for the agent's functionality, designed to run even if keys are missing. It also introduces the `INTERACTIVE_MODE` flag.\n",
        "  </p>\n",
        "  <ul style=\"background-color:#ECFDF5; padding:10px 10px 10px 30px; border-radius:6px; border:1px solid #D1FAE5; margin-top:10px; list-style-type: square;\">\n",
        "    <li style=\"color:#065F46; margin-bottom:8px;\">\n",
        "      <strong>Interaction Mode Flag:</strong> Defines `INTERACTIVE_MODE`. Set this to `False` for the non-interactive demo run required for Kaggle evaluation, or `True` for live interaction.\n",
        "    </li>\n",
        "    <li style=\"color:#065F46; margin-bottom:8px;\">\n",
        "      <strong>Core Imports:</strong> Imports standard libraries like <code>os</code>, <code>sys</code>, <code>traceback</code>, along with key components from <code>google.genai</code>, <code>kaggle_secrets</code>, and Google API core modules.\n",
        "    </li>\n",
        "    <li style=\"color:#065F46; margin-bottom:8px;\">\n",
        "      <strong>API Key Loading Strategy:</strong> Detects whether the notebook is running in a Kaggle environment (using <code>kaggle_secrets</code>) or potentially locally (falling back to <code>os.environ.get</code>).\n",
        "    </li>\n",
        "    <li style=\"color:#065F46; margin-bottom:8px;\">\n",
        "      <strong>Google API Key (Handled Gracefully):</strong>\n",
        "        <ul>\n",
        "            <li>Attempts to retrieve the <code>GOOGLE_API_KEY</code>.</li>\n",
        "            <li><strong>If the key is NOT found:</strong> Prints a warning and sets the <code>api_keys_loaded_successfully</code> flag to <code>False</code>. <strong>Execution continues</strong>, but the <code>genai.Client</code> (<code>client</code>) will remain <code>None</code>.</li>\n",
        "            <li><strong>If the key IS found:</strong> Attempts to initialize the <code>genai.Client</code>. If initialization succeeds, <code>api_keys_loaded_successfully</code> is set to <code>True</code>. If initialization fails (e.g., invalid key), an error is printed, and the flag remains <code>False</code>.</li>\n",
        "        </ul>\n",
        "    </li>\n",
        "     <li style=\"color:#065F46; margin-bottom:8px;\">\n",
        "      <strong>Optional API Keys (Weather & Images):</strong>\n",
        "        <ul>\n",
        "            <li>Attempts to retrieve <code>OPENWEATHERMAP_API_KEY</code> and <code>UNSPLASH_ACCESS_KEY</code>.</li>\n",
        "            <li>If these keys are <strong>not</strong> found, it prints an informational message, and the respective tools will use placeholder data later. Execution continues normally.</li>\n",
        "            <li>If found, the keys are set as environment variables.</li>\n",
        "        </ul>\n",
        "    </li>\n",
        "    <li style=\"color:#065F46; margin-bottom:8px;\">\n",
        "      <strong>Status Tracking:</strong> The <code>api_keys_loaded_successfully</code> flag accurately tracks if the Google key was found *and* the client initialized successfully. A final check prints a critical warning if this flag is <code>False</code>, alerting the user that core features will be unavailable.\n",
        "    </li>\n",
        "    <li style=\"color:#065F46;\">\n",
        "      <strong>Retry Predicate:</strong> Defines common Google API errors and a helper function <code>is_retriable_google_sdk</code> for potential use with retry mechanisms on API calls later.\n",
        "    </li>\n",
        "  </ul>\n",
        "  <p style=\"color:gray; margin-top:10px; font-style: italic;\">\n",
        "    This cell ensures the notebook attempts to load all keys but <strong>will not halt</strong> if the essential Google API key is missing. Subsequent code relying on the Gemini LLM must check if the <code>client</code> object is valid or if <code>api_keys_loaded_successfully</code> is <code>True</code> before proceeding.\n",
        "  </p>\n",
        "</div>"
      ],
      "metadata": {
        "id": "czyAV37frLY8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import traceback\n",
        "from kaggle_secrets import UserSecretsClient\n",
        "import google.genai as genai\n",
        "from google.genai import types as genai_types\n",
        "import google.api_core.exceptions\n",
        "from google.api_core import retry\n",
        "\n",
        "INTERACTIVE_MODE = False\n",
        "print(f\"Running in {'INTERACTIVE' if INTERACTIVE_MODE else 'DEMO'} mode.\")\n",
        "\n",
        "api_keys_loaded_successfully = False\n",
        "client = None\n",
        "\n",
        "try:\n",
        "    if 'kaggle_secrets' in sys.modules:\n",
        "        print(\"Using Kaggle secrets.\")\n",
        "        secrets_client = UserSecretsClient()\n",
        "        get_secret = secrets_client.get_secret\n",
        "    else:\n",
        "        print(\"Using environment variables (or Kaggle secrets fallback).\")\n",
        "        get_secret = os.environ.get\n",
        "\n",
        "    GOOGLE_API_KEY = get_secret(\"GOOGLE_API_KEY\")\n",
        "    if GOOGLE_API_KEY:\n",
        "        os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
        "        try:\n",
        "            client = genai.Client(api_key=GOOGLE_API_KEY)\n",
        "            print(\"‚úÖ Google API Key configured and Client initialized.\")\n",
        "            api_keys_loaded_successfully = True\n",
        "        except Exception as client_err:\n",
        "            print(f\"‚ùå ERROR: Google API Key found, but failed to initialize Client: {client_err}\")\n",
        "            print(\"   Check if the key is valid or if there are connection issues.\")\n",
        "            api_keys_loaded_successfully = False\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è WARNING: 'GOOGLE_API_KEY' not found.\")\n",
        "        print(\"   Core LLM features (generation, grounding, RAG embeddings) will NOT function.\")\n",
        "        api_keys_loaded_successfully = False\n",
        "\n",
        "    OPENWEATHERMAP_API_KEY = get_secret(\"OPENWEATHERMAP_API_KEY\")\n",
        "    if OPENWEATHERMAP_API_KEY:\n",
        "        os.environ[\"OPENWEATHERMAP_API_KEY\"] = OPENWEATHERMAP_API_KEY\n",
        "        print(\"‚úÖ OpenWeatherMap API Key configured.\")\n",
        "    else:\n",
        "        print(\"‚ÑπÔ∏è INFO: 'OPENWEATHERMAP_API_KEY' secret not found. Weather tool will use placeholder data.\")\n",
        "        os.environ[\"OPENWEATHERMAP_API_KEY\"] = \"\"\n",
        "\n",
        "    UNSPLASH_ACCESS_KEY = get_secret(\"UNSPLASH_ACCESS_KEY\")\n",
        "    if UNSPLASH_ACCESS_KEY:\n",
        "        os.environ[\"UNSPLASH_ACCESS_KEY\"] = UNSPLASH_ACCESS_KEY\n",
        "        print(\"‚úÖ Unsplash Access Key configured.\")\n",
        "    else:\n",
        "        print(\"‚ÑπÔ∏è INFO: 'UNSPLASH_ACCESS_KEY' secret not found. Image tool will use placeholder images.\")\n",
        "        os.environ[\"UNSPLASH_ACCESS_KEY\"] = \"\"\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå ERROR during API Key setup: {e}\")\n",
        "    api_keys_loaded_successfully = False\n",
        "\n",
        "retryable_errors = (\n",
        "    google.api_core.exceptions.ResourceExhausted,\n",
        "    google.api_core.exceptions.ServiceUnavailable,\n",
        "    google.api_core.exceptions.InternalServerError,\n",
        "    google.api_core.exceptions.DeadlineExceeded,\n",
        ")\n",
        "is_retriable_google_sdk = lambda e: isinstance(e, retryable_errors)\n",
        "print(\"Retry predicate for Google API calls defined.\")\n",
        "\n",
        "if not api_keys_loaded_successfully:\n",
        "     print(\"\\n‚ÄºÔ∏è CRITICAL WARNING: Google API Key setup failed or key not found.\")\n",
        "     print(\"‚ÄºÔ∏è Most features involving the Gemini LLM will likely fail or be skipped.\")\n",
        "     print(\"‚ÄºÔ∏è Please ensure 'GOOGLE_API_KEY' is available (as Kaggle Secret or env variable) for full functionality.\")\n",
        "else:\n",
        "    print(\"\\nEnvironment and API keys configured successfully (Google key present).\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "YPonisqIrLY8"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color:#F0FDF4; padding:15px; border-radius:8px; margin-top:20px; border:1px dashed #22C55E;\">\n",
        "  <h2 style=\"color:#15803D; border-bottom: 2px solid #16A34A; padding-bottom: 5px;\">Step 3: Consolidate Core Imports</h2>\n",
        "  <p style=\"color:gray; margin-top:10px;\">\n",
        "    This cell centralizes the import statements for various libraries and components used throughout the notebook. Grouping imports here improves organization and readability.\n",
        "  </p>\n",
        "  <ul style=\"background-color:#ECFDF5; padding:10px 10px 10px 30px; border-radius:6px; border:1px solid #D1FAE5; margin-top:10px; list-style-type: square;\">\n",
        "    <li style=\"color:#065F46; margin-bottom:8px;\">\n",
        "      <strong>Data Handling:</strong> Imports <code>pandas</code> and <code>numpy</code> for data manipulation.\n",
        "    </li>\n",
        "    <li style=\"color:#065F46; margin-bottom:8px;\">\n",
        "      <strong>Vector Database:</strong> Imports <code>chromadb</code> and specific types needed for custom embedding functions.\n",
        "    </li>\n",
        "    <li style=\"color:#065F46; margin-bottom:8px;\">\n",
        "      <strong>Networking & Utilities:</strong> Imports <code>requests</code>, <code>json</code>, <code>uuid</code>, <code>datetime</code>, <code>random</code>, and <code>enum</code> for API calls and general utility functions.\n",
        "    </li>\n",
        "     <li style=\"color:#065F46; margin-bottom:8px;\">\n",
        "      <strong>Display & Typing:</strong> Imports components from <code>IPython.display</code> for rich output (Markdown, HTML, Images) and extensive use of <code>typing</code> for defining data structures (TypedDict, Optional, etc.) and type hints.\n",
        "    </li>\n",
        "     <li style=\"color:#065F46; margin-bottom:8px;\">\n",
        "      <strong>LangChain & LangGraph Core:</strong> Imports core message types (AIMessage, HumanMessage, etc.), Pydantic models for structured output, ToolNode, StateGraph, and other essential building blocks from <code>langchain_core</code>, <code>langgraph</code>, and <code>langchain_google_genai</code>.\n",
        "    </li>\n",
        "  </ul>\n",
        "  <p style=\"color:gray; margin-top:10px; font-style: italic;\">\n",
        "    Subsequent cells will use these imported modules and classes to define agent components and execute the workflow.\n",
        "  </p>\n",
        "</div>"
      ],
      "metadata": {
        "id": "413gavaLrLY9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import chromadb\n",
        "import requests\n",
        "import json\n",
        "import uuid\n",
        "import datetime\n",
        "import random\n",
        "import enum\n",
        "\n",
        "from IPython.display import display, Markdown, Image, HTML\n",
        "from typing import Annotated, List, Dict, Optional, Any, Literal\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "\n",
        "from chromadb import Documents, EmbeddingFunction, Embeddings as ChromaEmbeddings\n",
        "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage, ToolMessage\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "from langgraph.prebuilt import ToolNode\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.tools import tool"
      ],
      "metadata": {
        "trusted": true,
        "id": "yRCIjk2rrLY9"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color:#FFFBEB; padding:15px; border-radius:8px; margin-top:20px; border:1px dashed #F59E0B;\">\n",
        "  <h2 style=\"color:#B45309; border-bottom: 2px solid #D97706; padding-bottom: 5px;\">Step 4: Data Loading and Initial Exploration</h2>\n",
        "  <p style=\"color:gray; margin-top:10px;\">In this step, we load the core dataset for our travel agent: the Wikivoyage Points of Interest (POI) listings. We will download the English CSV directly from its source on GitHub and load it into a Pandas DataFrame.</p>\n",
        "  <p style=\"color:gray; margin-top:10px;\">Following the loading, we'll perform a brief initial exploration to understand the structure, columns, data types, and the number of unique cities present in the dataset. This helps inform our subsequent processing steps.</p>\n",
        "</div>"
      ],
      "metadata": {
        "id": "7DOZSNr1rLY9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# URL for the Wikivoyage English listings CSV\n",
        "csv_url = \"https://github.com/wikivoyage/wikivoyage.github.io/blob/master/wikivoyage-listings-en.csv?raw=true\"\n",
        "\n",
        "# Load the dataset into a Pandas DataFrame\n",
        "try:\n",
        "    df_wikivoyage_raw = pd.read_csv(csv_url)\n",
        "    print(f\"Successfully loaded data from URL. Shape: {df_wikivoyage_raw.shape}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading data from URL: {e}\")\n",
        "    print(\"Please check the URL or your internet connection.\")\n",
        "\n",
        "if not df_wikivoyage_raw.empty:\n",
        "    print(\"\\nDataset Information:\")\n",
        "    df_wikivoyage_raw.info()"
      ],
      "metadata": {
        "trusted": true,
        "id": "B_hprYSCrLY9"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color:#FFFBEB; padding:15px; border-radius:8px; margin-top:20px; border:1px dashed #F59E0B;\">\n",
        "  <h2 style=\"color:#B45309; border-bottom: 2px solid #D97706; padding-bottom: 5px;\">Step 4.1: Data Cleaning and Preprocessing</h2>\n",
        "  <p style=\"color:gray; margin-top:10px;\">Now that the raw data is loaded, we preprocess it to make it suitable for our agent. This involves several key steps:</p>\n",
        "  <ul style=\"color:gray; margin-top:10px; list-style-type: disc; margin-left: 20px;\">\n",
        "    <li><strong>Selecting & Renaming Columns:</strong> We isolate the columns relevant to our project needs (city, POI name, type, description, address, alt) and rename them for clarity (e.g., <code>article</code> -> <code>city</code>, <code>title</code> -> <code>name</code>).</li>\n",
        "    <li><strong>Handling Missing Values:</strong> Critical text columns (like name, description, city) have missing values (NaN) filled with empty strings (<code>\"\"</code>) to prevent errors in later text processing and embedding steps.</li>\n",
        "    <li><strong>Creating Combined Content for RAG:</strong> A new column, <code>content_for_rag</code>, is generated by concatenating the text from <code>name</code>, <code>poi_type</code>, <code>description</code>, <code>address</code>, and <code>alt</code>. This combined field provides richer context for the RAG system's retrieval process. Descriptive labels (e.g., \"Name:\", \"Type:\") are added within the text.</li>\n",
        "    <li><strong>Cleaning Text:</strong> Excessive whitespace is removed from the combined content field for consistency.</li>\n",
        "    <li><strong>Filtering Empty Rows:</strong> Rows where essential identifiers like <code>city</code> or <code>name</code> are empty after cleaning are removed to improve data quality.</li>\n",
        "    <li><strong>Extracting Unique Cities:</strong> The list of unique city names present in the dataset is extracted and stored in the <code>list_of_unique_cities</code> variable. This list is crucial for the \"Recommendation Verification\" step later in the agent's workflow.</li>\n",
        "  </ul>\n",
        "  <p style=\"color:gray; margin-top:10px;\">This preprocessing results in the <code>df_processed</code> DataFrame, which is now cleaner and structured for the subsequent stages of building our travel recommender.</p>\n",
        "</div>"
      ],
      "metadata": {
        "id": "iMFbTg6trLY-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Starting Data Cleaning and Preprocessing...\")\n",
        "\n",
        "relevant_columns = {\n",
        "    'article': 'city',\n",
        "    'title': 'name',\n",
        "    'type': 'poi_type',\n",
        "    'description': 'description',\n",
        "    'address': 'address',\n",
        "    'alt': 'alt'\n",
        "}\n",
        "\n",
        "# Select and rename relevant columns\n",
        "df_processed = df_wikivoyage_raw[list(relevant_columns.keys())].rename(columns=relevant_columns)\n",
        "\n",
        "text_cols_to_fill = ['name', 'poi_type', 'description', 'address', 'alt', 'city']\n",
        "for col in text_cols_to_fill:\n",
        "    df_processed[col] = df_processed[col].fillna(\"\").astype(str)\n",
        "\n",
        "# Create the combined 'content_for_rag' column\n",
        "df_processed['content_for_rag'] = (\n",
        "    \"Name: \" + df_processed['name'] + \"; \" +\n",
        "    \"Type: \" + df_processed['poi_type'] + \"; \" +\n",
        "    \"Description: \" + df_processed['description'] + \"; \" +\n",
        "    \"Address: \" + df_processed['address'] + \"; \" +\n",
        "    \"Alternate Name: \" + df_processed['alt']\n",
        ")\n",
        "\n",
        "# Clean excessive whitespace from the combined content\n",
        "df_processed['content_for_rag'] = df_processed['content_for_rag'].str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
        "\n",
        "df_processed = df_processed[df_processed['city'] != \"\"]\n",
        "df_processed = df_processed[df_processed['name'] != \"\"]\n",
        "\n",
        "\n",
        "print(f\"Data cleaned. New shape: {df_processed.shape}\")\n",
        "print(\"\\nFirst 5 rows of processed data:\")\n",
        "display(df_processed.head())\n",
        "\n",
        "print(\"\\nChecking for remaining NaN values in key columns:\")\n",
        "print(df_processed[['city', 'name', 'poi_type', 'description', 'address', 'alt', 'content_for_rag']].isnull().sum())\n",
        "\n",
        "print(\"\\nUnique city count:\")\n",
        "unique_cities = df_processed['city'].unique()\n",
        "print(f\"Found {len(unique_cities)} unique cities in the dataset.\")\n",
        "\n",
        "list_of_unique_cities = unique_cities.tolist()\n",
        "print(\"List of unique city names created for verification.\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "jZCubchrrLY-"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color:#EFF6FF; padding:15px; border-radius:8px; margin-top:20px; border:1px dashed #3B82F6;\">\n",
        "  <h2 style=\"color:#1E40AF; border-bottom: 2px solid #2563EB; padding-bottom: 5px;\">Step 5: Define Agent State & Data Structures</h2>\n",
        "  <p style=\"color:gray; margin-top:10px;\">\n",
        "    Before building the agent's workflow graph, we need to define the structure of the information it will manage during the conversation. This is achieved using Python's <code>TypedDict</code> for clear, type-hinted state management within LangGraph.\n",
        "  </p>\n",
        "  <ul style=\"background-color:#DBEAFE; padding:10px 10px 10px 30px; border-radius:6px; border:1px solid #BFDBFE; margin-top:10px; list-style-type: square;\">\n",
        "    <li style=\"color:#1E3A8A; margin-bottom:8px;\">\n",
        "      <strong><code>Recommendation</code> TypedDict:</strong> Defines the schema for a fully processed recommendation, including city, country, description, justification, the fetched image URL, and a boolean flag (<code>has_data</code>) indicating if detailed POI information is available in our Wikivoyage dataset for this city.\n",
        "    </li>\n",
        "    <li style=\"color:#1E3A8A; margin-bottom:8px;\">\n",
        "      <strong><code>POISuggestion</code> TypedDict:</strong> Defines the structure for individual Point of Interest details, likely intended for use in Phase 2 when displaying POIs for the selected city.\n",
        "    </li>\n",
        "    <li style=\"color:#1E3A8A; margin-bottom:8px;\">\n",
        "      <strong><code>SuggestionState</code> TypedDict (Core State):</strong> This is the primary state object passed between nodes in the <strong>Phase 1 (Suggestion)</strong> part of the agent graph. It holds:\n",
        "      <ul>\n",
        "        <li><code>messages</code>: The history of the conversation (using LangGraph's special <code>Annotated[..., add_messages]</code> to ensure new messages are appended).</li>\n",
        "        <li><code>user_preferences</code>: A dictionary storing the preferences collected from the user (vibe, activities, etc.).</li>\n",
        "        <li><code>text_recommendations</code>: The initial list of recommendations (as dictionaries) generated by the LLM before image fetching and verification.</li>\n",
        "        <li><code>recommendations</code>: The final list of processed recommendations (matching the <code>Recommendation</code> structure) after image fetching and verification.</li>\n",
        "        <li><code>cities_with_data</code>: A helper list containing names of recommended cities found in our dataset.</li>\n",
        "        <li><code>error_message</code>: Stores potential error messages during graph execution.</li>\n",
        "        <li><code>is_finished</code>: A flag to signal when the Phase 1 conversation should end (e.g., user quits or selection is made).</li>\n",
        "        <li><code>selected_city_for_phase_2</code>: Stores the name of the city the user selects to explore further, triggering the transition to Phase 2.</li>\n",
        "      </ul>\n",
        "    </li>\n",
        "  </ul>\n",
        "  <p style=\"color:gray; margin-top:10px; font-style: italic;\">\n",
        "    Defining this state structure upfront allows LangGraph to manage the flow of information consistently and provides type safety benefits during development.\n",
        "  </p>\n",
        "</div>"
      ],
      "metadata": {
        "id": "s91FnERCrLY-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Recommendation(TypedDict):\n",
        "    city: str\n",
        "    country: str\n",
        "    description: str\n",
        "    justification: str\n",
        "    image_url: Optional[str]\n",
        "    has_data: bool # Flag indicating if city exists in our Wikivoyage dataset\n",
        "\n",
        "class POISuggestion(TypedDict):\n",
        "    \"\"\"Structure for Point-of-Interest suggestions.\"\"\"\n",
        "    name: str\n",
        "    type: str\n",
        "    description: str\n",
        "    address: Optional[str]\n",
        "\n",
        "class SuggestionState(TypedDict):\n",
        "    \"\"\"State for the suggestion-gathering phase (Structured Approach).\"\"\"\n",
        "    messages: Annotated[List[Any], add_messages]\n",
        "    user_preferences: Dict[str, Any]\n",
        "    text_recommendations: Optional[List[Dict]]\n",
        "    recommendations: List[Recommendation]\n",
        "\n",
        "    # Helper fields\n",
        "    cities_with_data: List[str]\n",
        "    error_message: Optional[str]\n",
        "    is_finished: bool\n",
        "    selected_city_for_phase_2: Optional[str]\n",
        "\n",
        "print(\"Recommendation, POISuggestion, SuggestionState defined.\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "6bOOvkx9rLY-"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color:#F0FDF4; padding:15px; border-radius:8px; margin-top:20px; border:1px dashed #22C55E;\">\n",
        "  <h2 style=\"color:#15803D; border-bottom: 2px solid #16A34A; padding-bottom: 5px;\">Step 6: Setup Vector Database (ChromaDB) for RAG</h2>\n",
        "  <p style=\"color:gray; margin-top:10px;\">\n",
        "    This crucial step configures the vector database (ChromaDB) which powers the Retrieval-Augmented Generation (RAG) capabilities of our agent. It involves defining how text data (Wikivoyage POIs) is converted into embeddings and stored for efficient similarity search.\n",
        "  </p>\n",
        "  <ol style=\"background-color:#ECFDF5; padding:10px 10px 10px 30px; border-radius:6px; border:1px solid #D1FAE5; margin-top:10px;\">\n",
        "    <li style=\"color:#065F46; margin-bottom:8px;\">\n",
        "      <strong>Configuration Constants:</strong> Defines key settings:\n",
        "      <ul>\n",
        "        <li><code>embedding_model_name</code>: Specifies the Google Gemini model (`models/text-embedding-004`) used for generating vector representations of text.</li>\n",
        "        <li><code>collection_name</code>: Sets the name for the ChromaDB collection where POI embeddings will be stored.</li>\n",
        "        <li><code>CHROMA_CACHE_DIR</code>: Specifies the local directory for persisting the ChromaDB database, allowing data to be reused across notebook runs.</li>\n",
        "      </ul>\n",
        "    </li>\n",
        "     <li style=\"color:#065F46; margin-bottom:8px;\">\n",
        "      <strong>Prerequisite Check:</strong> Ensures the <code>df_processed</code> DataFrame and the essential <code>content_for_rag</code> column exist before proceeding.\n",
        "    </li>\n",
        "    <li style=\"color:#065F46; margin-bottom:8px;\">\n",
        "      <strong>Custom Gemini Embedding Function (<code>GeminiEmbeddingFunctionChroma</code>):</strong>\n",
        "      <ul>\n",
        "        <li>Defines a class inheriting from ChromaDB's <code>EmbeddingFunction</code>.</li>\n",
        "        <li>This class interfaces directly with the initialized Google API <code>client</code> (from Step 2) to call the <code>embed_content</code> method of the specified Gemini embedding model.</li>\n",
        "        <li>It handles different embedding <code>task_type</code>s required by ChromaDB/Gemini ('retrieval_document' for indexing, 'retrieval_query' for searching).</li>\n",
        "        <li>Integrates the <code>is_retriable_google_sdk</code> logic defined earlier to automatically retry API calls on specific transient errors (e.g., rate limits).</li>\n",
        "        <li>Includes robust checks for input types and extracts the embedding values correctly from the API response.</li>\n",
        "        <li><strong>Dependency:</strong> This function relies on the <code>client</code> being successfully initialized in Step 2. If the Google API key was missing, initialization of this embedder will fail.</li>\n",
        "      </ul>\n",
        "    </li>\n",
        "    <li style=\"color:#065F46; margin-bottom:8px;\">\n",
        "      <strong>Initialize Persistent ChromaDB Client:</strong>\n",
        "        <ul>\n",
        "            <li>Creates the cache directory if it doesn't exist.</li>\n",
        "            <li>Initializes a <code>chromadb.PersistentClient</code> pointing to the specified <code>CHROMA_CACHE_DIR</code>. This ensures that the created database and its indexed data are saved to disk.</li>\n",
        "        </ul>\n",
        "    </li>\n",
        "     <li style=\"color:#065F46; margin-bottom:8px;\">\n",
        "      <strong>Get or Create Collection & Index Data:</strong>\n",
        "        <ul>\n",
        "            <li>Instantiates the custom embedding function for document indexing (`task_type=\"retrieval_document\"`).</li>\n",
        "            <li>Uses <code>chroma_client.get_or_create_collection</code> to either load an existing collection from the cache directory or create a new one. The custom embedder is passed here.</li>\n",
        "            <li><strong>Caching Logic:</strong> It compares the number of documents expected (from the processed DataFrame) with the count in the existing persistent collection. If a sufficient number of documents (~98%) are already present, it skips the time-consuming embedding and indexing step, loading directly from the cache.</li>\n",
        "            <li><strong>Indexing Process (if needed):</strong> If the cache is empty or insufficient, it extracts the <code>content_for_rag</code> text, relevant metadata (city, name, type), and generates unique IDs. It then adds these documents to the collection in batches (e.g., 100 at a time) to manage memory and API rate limits. Errors during batch addition are caught and reported.</li>\n",
        "        </ul>\n",
        "    </li>\n",
        "    <li style=\"color:#065F46;\">\n",
        "      <strong>Initialize Query Embedder:</strong> If the collection setup was successful, it creates a separate instance of <code>GeminiEmbeddingFunctionChroma</code> specifically for embedding user queries (`task_type=\"retrieval_query\"`). This instance will be used later during RAG retrieval.\n",
        "    </li>\n",
        "     <li style=\"color:#065F46;\">\n",
        "      <strong>Error Handling:</strong> Includes comprehensive <code>try...except</code> blocks around client initialization and collection setup/indexing to catch potential errors and print informative messages, preventing the entire notebook from crashing if RAG setup fails (though RAG functionality would be lost).\n",
        "    </li>\n",
        "  </ol>\n",
        "  <p style=\"color:gray; margin-top:10px; font-style: italic;\">\n",
        "    After this cell, the <code>poi_collection</code> object should be ready for querying, and <code>gemini_embedder_query</code> should be available to embed search queries, enabling the RAG functionality in Phase 2 and the Q&A section. The use of persistence significantly speeds up subsequent runs after the initial indexing.\n",
        "  </p>\n",
        "</div>"
      ],
      "metadata": {
        "id": "bHELXcEcrLY-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_model_name = \"models/text-embedding-004\"\n",
        "collection_name = \"wikivoyage_pois_gemini_v1\"\n",
        "CHROMA_CACHE_DIR = \"./chroma_db_persistent_cache\"\n",
        "\n",
        "print(f\"Using Embedding model: {embedding_model_name}\")\n",
        "print(f\"ChromaDB collection name: {collection_name}\")\n",
        "print(f\"ChromaDB persistence directory: {CHROMA_CACHE_DIR}\")\n",
        "\n",
        "if 'df_processed' not in globals() or not isinstance(df_processed, pd.DataFrame) or df_processed.empty:\n",
        "     raise ValueError(\"'df_processed' DataFrame not found or empty. Please run Step 2.1 first.\")\n",
        "if 'content_for_rag' not in df_processed.columns:\n",
        "     raise ValueError(\"'content_for_rag' column missing in df_processed.\")\n",
        "\n",
        "class GeminiEmbeddingFunctionChroma(EmbeddingFunction):\n",
        "    \"\"\"Custom embedding function for ChromaDB using the Gemini API (client.models.embed_content).\"\"\"\n",
        "    def __init__(self, model_name: str = embedding_model_name, task_type: str = \"retrieval_document\"):\n",
        "        self._model_name = model_name\n",
        "        self._task_type = task_type\n",
        "        if 'client' not in globals() or client is None: raise NameError(\"'client' (google.genai.Client) not found or is None.\")\n",
        "        self._client = client\n",
        "        if 'is_retriable_google_sdk' not in globals() or not callable(is_retriable_google_sdk): raise NameError(\"'is_retriable_google_sdk' predicate not found or not callable.\")\n",
        "        self._embed_content_with_retry = retry.Retry(predicate=is_retriable_google_sdk)(self._client.models.embed_content)\n",
        "        print(f\"GeminiEmbeddingFunctionChroma initialized for task: {self._task_type}\")\n",
        "\n",
        "    def __call__(self, input_texts: Documents) -> ChromaEmbeddings:\n",
        "        \"\"\"Embeds a list of text documents using client.models.embed_content.\"\"\"\n",
        "        if not input_texts: return []\n",
        "        if not isinstance(input_texts, list):\n",
        "             print(f\"Embedder Input Error: input_texts is not a list (type: {type(input_texts)}).\")\n",
        "             return [[] for _ in range(len(input_texts) if hasattr(input_texts, '__len__') else 1)]\n",
        "        if not all(isinstance(text, str) for text in input_texts):\n",
        "             print(f\"Embedder Input Error: Not all items in input_texts are strings.\")\n",
        "             problem_indices = [i for i, x in enumerate(input_texts) if not isinstance(x, str)]\n",
        "             print(f\"  -> Indices with non-string types: {problem_indices[:5]}\")\n",
        "             return [[] for _ in range(len(input_texts))]\n",
        "\n",
        "        try:\n",
        "            response = self._embed_content_with_retry(\n",
        "                model=self._model_name,\n",
        "                contents=input_texts,\n",
        "                config=genai_types.EmbedContentConfig(task_type=self._task_type)\n",
        "            )\n",
        "\n",
        "            if hasattr(response, 'embeddings') and isinstance(response.embeddings, list):\n",
        "                embeddings_list = []\n",
        "                valid_embeddings_count = 0\n",
        "                for i, emb_obj in enumerate(response.embeddings):\n",
        "                    if hasattr(emb_obj, 'values') and isinstance(emb_obj.values, list) and emb_obj.values:\n",
        "                        embeddings_list.append(list(map(float, emb_obj.values)))\n",
        "                        valid_embeddings_count += 1\n",
        "                    else:\n",
        "                        print(f\"DEBUG EMBED: WARNING - Item {i} missing/invalid 'values'. Type: {type(emb_obj)}\")\n",
        "                        embeddings_list.append([])\n",
        "\n",
        "                if valid_embeddings_count == len(input_texts):\n",
        "                    return embeddings_list\n",
        "                else:\n",
        "                    print(f\"DEBUG EMBED: WARNING - Mismatch. Input: {len(input_texts)}, Valid Extracted: {valid_embeddings_count}.\")\n",
        "                    if valid_embeddings_count > 0:\n",
        "                         print(\"DEBUG EMBED: Returning list with potential gaps (empty lists).\")\n",
        "                         return embeddings_list\n",
        "                    else:\n",
        "                         print(\"DEBUG EMBED: ERROR - No valid embeddings extracted.\")\n",
        "                         return [[] for _ in range(len(input_texts))]\n",
        "            else:\n",
        "                print(f\"DEBUG EMBED: ERROR - Response object missing 'embeddings' list.\")\n",
        "                print(f\"  -> Response content sample: {str(response)[:500]}\")\n",
        "                return [[] for _ in range(len(input_texts))]\n",
        "\n",
        "        except google.api_core.exceptions.GoogleAPIError as api_err:\n",
        "             print(f\"DEBUG EMBED: ERROR - Google API Error (Task: '{self._task_type}'). Details: {api_err}\")\n",
        "             return [[] for _ in range(len(input_texts))]\n",
        "        except Exception as e:\n",
        "            print(f\"DEBUG EMBED: ERROR - Unexpected error (Task: '{self._task_type}'). Details: {e}\")\n",
        "            traceback.print_exc()\n",
        "            return [[] for _ in range(len(input_texts))]\n",
        "\n",
        "\n",
        "try:\n",
        "    if not os.path.exists(CHROMA_CACHE_DIR):\n",
        "        os.makedirs(CHROMA_CACHE_DIR)\n",
        "        print(f\"Created ChromaDB cache directory: {CHROMA_CACHE_DIR}\")\n",
        "\n",
        "    chroma_client = chromadb.PersistentClient(path=CHROMA_CACHE_DIR)\n",
        "    print(f\"ChromaDB PersistentClient initialized. Data will be saved/loaded from: {CHROMA_CACHE_DIR}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n‚ùå An error occurred initializing the persistent ChromaDB client:\")\n",
        "    traceback.print_exc()\n",
        "    raise RuntimeError(f\"Failed to initialize ChromaDB PersistentClient at {CHROMA_CACHE_DIR}\") from e\n",
        "\n",
        "\n",
        "print(f\"\\n--- Setting up ChromaDB Collection: '{collection_name}' ---\")\n",
        "poi_collection = None\n",
        "\n",
        "try:\n",
        "    gemini_embedder_docs = GeminiEmbeddingFunctionChroma(task_type=\"retrieval_document\")\n",
        "    poi_collection = chroma_client.get_or_create_collection(\n",
        "        name=collection_name,\n",
        "        embedding_function=gemini_embedder_docs,\n",
        "        metadata={\"hnsw:space\": \"cosine\"}\n",
        "    )\n",
        "    print(f\"Collection '{poi_collection.name}' retrieved or created in persistent storage.\")\n",
        "\n",
        "    df_filtered = df_processed.dropna(subset=['content_for_rag', 'city', 'name'])\n",
        "    df_filtered = df_filtered[df_filtered['content_for_rag'].str.strip() != \"\"]\n",
        "    expected_count = len(df_filtered)\n",
        "    existing_count = poi_collection.count()\n",
        "    print(f\"Expected documents based on current DataFrame: {expected_count}\")\n",
        "    print(f\"Documents currently in persistent collection '{collection_name}': {existing_count}\")\n",
        "\n",
        "    count_threshold = 0.98\n",
        "\n",
        "    if existing_count >= (expected_count * count_threshold) and existing_count > 0:\n",
        "        print(f\"‚úÖ Collection appears to contain sufficient data ({existing_count} >= {int(expected_count * count_threshold)}).\")\n",
        "        print(f\"   Loading from cache at '{CHROMA_CACHE_DIR}'. Skipping embedding and indexing.\")\n",
        "\n",
        "    elif expected_count == 0:\n",
        "         print(\"‚ö†Ô∏è Warning: No processable documents found in the DataFrame after filtering. Collection will be empty.\")\n",
        "    else:\n",
        "        print(f\"‚ÑπÔ∏è Collection has {existing_count} documents, expecting {expected_count}.\")\n",
        "        print(\"   Proceeding with embedding and indexing (this may take a long time)...\")\n",
        "\n",
        "        documents_to_index = df_filtered['content_for_rag'].tolist()\n",
        "        metadatas_to_index = df_filtered[['city', 'name', 'poi_type']].astype(str).to_dict('records')\n",
        "\n",
        "        ids_to_index = [f\"poi_{uuid.uuid4()}\" for _ in range(len(documents_to_index))]\n",
        "\n",
        "        batch_size = 100\n",
        "        added_count = 0\n",
        "        total_batches = (len(documents_to_index) + batch_size - 1) // batch_size\n",
        "        print(f\"Adding {len(documents_to_index)} documents in {total_batches} batches of size {batch_size}...\")\n",
        "\n",
        "        for i in range(0, len(documents_to_index), batch_size):\n",
        "            batch_docs = documents_to_index[i:i+batch_size]\n",
        "            batch_metadatas = metadatas_to_index[i:i+batch_size]\n",
        "            batch_ids = ids_to_index[i:i+batch_size]\n",
        "            current_batch_num = (i // batch_size) + 1\n",
        "\n",
        "            print(f\"  Adding batch {current_batch_num}/{total_batches} ({len(batch_docs)} documents)...\")\n",
        "\n",
        "            try:\n",
        "                poi_collection.add(\n",
        "                    documents=batch_docs,\n",
        "                    metadatas=batch_metadatas,\n",
        "                    ids=batch_ids\n",
        "                )\n",
        "                added_count += len(batch_docs)\n",
        "                print(f\"  Batch {current_batch_num} added successfully.\")\n",
        "            except Exception as add_err:\n",
        "                 print(f\"  ‚ùå Error adding Batch {current_batch_num}: {add_err}\")\n",
        "                 print(f\"     Skipping this batch due to error. Check API key, rate limits, or data content.\")\n",
        "\n",
        "        print(f\"\\n‚úÖ Indexing complete.\")\n",
        "        print(f\"   Attempted to add {len(documents_to_index)} documents.\")\n",
        "        print(f\"   Successfully added ~{added_count} documents in this run.\")\n",
        "        final_count = poi_collection.count()\n",
        "        print(f\"   Collection '{collection_name}' now contains {final_count} documents.\")\n",
        "        if final_count < expected_count * count_threshold :\n",
        "             print(f\"   ‚ö†Ô∏è Warning: Final count ({final_count}) is lower than expected ({expected_count}). Check for errors during batch processing.\")\n",
        "\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n‚ùå An error occurred during ChromaDB setup or indexing:\")\n",
        "    traceback.print_exc()\n",
        "    poi_collection = None\n",
        "    print(\"\\n--- CRITICAL WARNING: ChromaDB setup failed. RAG steps will likely fail. ---\")\n",
        "\n",
        "\n",
        "gemini_embedder_query = None\n",
        "if poi_collection is not None:\n",
        "    try:\n",
        "        gemini_embedder_query = GeminiEmbeddingFunctionChroma(task_type=\"retrieval_query\")\n",
        "        print(\"\\nGeminiEmbeddingFunctionChroma instance created for RAG queries.\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ùå Error initializing query embedder: {e}\")\n",
        "        print(\"   RAG query embedding will likely fail.\")\n",
        "else:\n",
        "    print(\"\\n--- Skipping query embedder initialization because collection setup failed. ---\")\n",
        "\n",
        "\n",
        "print(\"\\n--- ChromaDB Persistence & RAG Setup Cell Finished ---\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "XSUyVakorLY-"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color:#EFF6FF; padding:15px; border-radius:8px; margin-top:20px; border:1px dashed #3B82F6;\">\n",
        "  <h2 style=\"color:#1E40AF; border-bottom: 2px solid #2563EB; padding-bottom: 5px;\">Step 7: Define Image Fetching Tool (Unsplash)</h2>\n",
        "  <p style=\"color:gray; margin-top:10px;\">\n",
        "    To make the travel recommendations more engaging, we define a tool that can fetch relevant images for the suggested cities. This tool utilizes the Unsplash API.\n",
        "  </p>\n",
        "  <ul style=\"background-color:#DBEAFE; padding:10px 10px 10px 30px; border-radius:6px; border:1px solid #BFDBFE; margin-top:10px; list-style-type: square;\">\n",
        "    <li style=\"color:#1E3A8A; margin-bottom:8px;\">\n",
        "      <strong>Placeholder URL:</strong> A constant <code>PLACEHOLDER_IMAGE_URL</code> is defined to be used as a fallback if image fetching fails or the API key is unavailable.\n",
        "    </li>\n",
        "    <li style=\"color:#1E3A8A; margin-bottom:8px;\">\n",
        "      <strong><code>unsplash_get_image</code> Function (@tool):</strong>\n",
        "        <ul>\n",
        "            <li>The core function is decorated with LangChain's <code>@tool</code> decorator, making it recognizable and callable by the LangGraph agent framework (specifically via a <code>ToolNode</code>).</li>\n",
        "            <li>It accepts the <code>city</code> and optional <code>country</code> as arguments.</li>\n",
        "            <li>It checks for the <code>UNSPLASH_ACCESS_KEY</code> in the environment variables (set up in Step 2).</li>\n",
        "            <li>If the key is missing, it immediately returns the <code>PLACEHOLDER_IMAGE_URL</code>.</li>\n",
        "            <li>If the key exists, it constructs a search query (e.g., \"Paris France scenic\") and calls the Unsplash API's search endpoint.</li>\n",
        "            <li>It includes error handling for network timeouts, request errors, and other exceptions, returning the placeholder URL in case of any failure.</li>\n",
        "            <li>If successful, it attempts to extract a suitable image URL ('regular' or 'small') from the first search result. If no results are found, it also falls back to the placeholder.</li>\n",
        "        </ul>\n",
        "    </li>\n",
        "     <li style=\"color:#1E3A8A; margin-bottom:8px;\">\n",
        "      <strong>Tool Registration:</strong> The defined <code>unsplash_get_image</code> tool is added to the <code>suggestion_tools</code> list. This list will be used later when configuring the <code>ToolNode</code> in the LangGraph graph for Phase 1.\n",
        "    </li>\n",
        "     <li style=\"color:#1E3A8A;\">\n",
        "      <strong>Tool Name Variable:</strong> The specific name of the tool (<code>unsplash_get_image.name</code>) is stored in the <code>UNSPLASH_TOOL_NAME</code> variable for easier and more robust reference within other parts of the agent's logic (like the node that constructs the tool calls).\n",
        "    </li>\n",
        "  </ul>\n",
        "  <p style=\"color:gray; margin-top:10px; font-style: italic;\">\n",
        "    This setup ensures that the agent can attempt to fetch relevant images using Function Calling in Phase 1, while gracefully handling missing API keys or network errors by providing a default image.\n",
        "  </p>\n",
        "</div>"
      ],
      "metadata": {
        "id": "WPCJyxsQrLY_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Placeholder outside function for clarity if key is missing or fetch fails\n",
        "PLACEHOLDER_IMAGE_URL = \"https://images.unsplash.com/photo-1500835556837-99ac94a94552?q=80&w=800&auto=format&fit=crop&ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D\"\n",
        "\n",
        "@tool\n",
        "def unsplash_get_image(city: str, country: Optional[str] = None) -> str:\n",
        "    \"\"\"\n",
        "    Fetches a relevant image URL from Unsplash for a given city and optional country.\n",
        "    Use this tool ONCE for EACH recommended city to get an illustrative image.\n",
        "    Returns a single image URL string. Falls back to a placeholder if the API key is missing,\n",
        "    the search fails, or an error occurs.\n",
        "    Example call: unsplash_get_image(city=\"Paris\", country=\"France\")\n",
        "    \"\"\"\n",
        "    # print(f\"\\n--- DEBUG: unsplash_get_image called with city='{city}', country='{country}' ---\")\n",
        "\n",
        "    access_key = os.environ.get(\"UNSPLASH_ACCESS_KEY\")\n",
        "\n",
        "    if not access_key:\n",
        "        # print(\"DEBUG: Unsplash API Key not found in environment. Using placeholder.\")\n",
        "        return PLACEHOLDER_IMAGE_URL\n",
        "\n",
        "    try:\n",
        "        search_query = f\"{city}\"\n",
        "        if country:\n",
        "            search_query += f\" {country}\"\n",
        "        search_query += \" scenic\"\n",
        "\n",
        "        # print(f\"DEBUG: Using Unsplash query: '{search_query}'\")\n",
        "\n",
        "        search_url = \"https://api.unsplash.com/search/photos\"\n",
        "        headers = {\"Authorization\": f\"Client-ID {access_key}\"}\n",
        "        params = {\n",
        "            'query': search_query,\n",
        "            'per_page': 1,\n",
        "            'orientation': 'landscape',\n",
        "            'order_by': 'relevant'\n",
        "        }\n",
        "\n",
        "        response = requests.get(search_url, headers=headers, params=params, timeout=10)\n",
        "        # print(f\"DEBUG: Unsplash API Status Code for '{search_query}': {response.status_code}\")\n",
        "        response.raise_for_status()\n",
        "        results = response.json()\n",
        "\n",
        "\n",
        "        if results.get('results'):\n",
        "            image_data = results['results'][0]\n",
        "            image_url = image_data.get('urls', {}).get('regular', image_data.get('urls', {}).get('small'))\n",
        "\n",
        "            # print(f\"DEBUG: Found URL for '{search_query}': {image_url}\")\n",
        "\n",
        "            if image_url:\n",
        "                return image_url\n",
        "\n",
        "        # print(f\"DEBUG: No suitable image URL found in results for '{search_query}'. Using placeholder.\")\n",
        "        return PLACEHOLDER_IMAGE_URL\n",
        "\n",
        "    except requests.exceptions.Timeout:\n",
        "         print(f\"DEBUG: Timeout connecting to Unsplash for '{search_query}'. Using placeholder.\")\n",
        "         return PLACEHOLDER_IMAGE_URL\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"DEBUG: Unsplash API request error for '{search_query}': {e}. Using placeholder.\")\n",
        "        return PLACEHOLDER_IMAGE_URL\n",
        "    except Exception as e:\n",
        "        import traceback\n",
        "        print(f\"DEBUG: Unexpected error fetching Unsplash image for '{search_query}': {e}.\")\n",
        "        traceback.print_exc()\n",
        "        return PLACEHOLDER_IMAGE_URL\n",
        "\n",
        "suggestion_tools = [unsplash_get_image]\n",
        "print(f\"Tool '{suggestion_tools[0].name}' defined.\")\n",
        "\n",
        "UNSPLASH_TOOL_NAME = suggestion_tools[0].name\n",
        "print(f\"Tool name variable UNSPLASH_TOOL_NAME set to: '{UNSPLASH_TOOL_NAME}'\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "GYDOD2_CrLY_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color:#EFF6FF; padding:15px; border-radius:8px; margin-top:20px; border:1px dashed #3B82F6;\">\n",
        "  <h2 style=\"color:#1E40AF; border-bottom: 2px solid #2563EB; padding-bottom: 5px;\">Step 8: Initialize Suggestion LLM & Define Core Interaction Nodes</h2>\n",
        "  <p style=\"color:gray; margin-top:10px;\">\n",
        "    This cell sets up the core components for the first phase of the conversation: gathering user preferences. It initializes the Large Language Model (LLM) that will formulate questions and defines the fundamental LangGraph nodes for the agent's turn and the user's turn.\n",
        "  </p>\n",
        "  <ul style=\"background-color:#DBEAFE; padding:10px 10px 10px 30px; border-radius:6px; border:1px solid #BFDBFE; margin-top:10px; list-style-type: square;\">\n",
        "    <li style=\"color:#1E3A8A; margin-bottom:8px;\">\n",
        "      <strong>LLM Initialization (Phase 1):</strong>\n",
        "        <ul>\n",
        "            <li>Sets the model name (e.g., <code>gemini-2.0-flash</code>) for the suggestion phase.</li>\n",
        "            <li>Initializes <code>suggestion_llm</code> using <code>ChatGoogleGenerativeAI</code>. This instance will be used specifically for generating the agent's questions during preference gathering. (Requires the Google API client from Step 2 to be initialized).</li>\n",
        "            <li>Initializes <code>suggestion_llm_with_tools</code> by binding the <code>unsplash_get_image</code> tool (defined in Step 7) to the LLM instance. While not used directly by the immediate nodes below, this prepares an LLM variant capable of calling the image tool if needed later in the graph.</li>\n",
        "        </ul>\n",
        "    </li>\n",
        "     <li style=\"color:#1E3A8A; margin-bottom:8px;\">\n",
        "        <strong>System Prompt for Asking Questions (<code>ASK_QUESTION_SYSTEM_PROMPT</code>):</strong>\n",
        "        <ul>\n",
        "            <li>Defines the instructions for the LLM when its task is to ask the *next* preference question.</li>\n",
        "            <li>Guides the LLM (\"Nomad\") to be conversational, check conversation history, ask about missing preferences ('vibe', 'activities', 'weather', 'budget') in order, provide examples, and avoid suggesting destinations prematurely.</li>\n",
        "        </ul>\n",
        "    </li>\n",
        "     <li style=\"color:#1E3A8A; margin-bottom:8px;\">\n",
        "      <strong>Question Asking Node (<code>ask_question_node</code>):</strong>\n",
        "      <ul>\n",
        "          <li>A LangGraph node function that takes the current agent state.</li>\n",
        "          <li>Constructs the input for the <code>suggestion_llm</code> by combining the system prompt and the current message history from the state.</li>\n",
        "          <li>Invokes the LLM to generate the next question.</li>\n",
        "          <li>Returns the updated state containing the AI's response (the question). Includes error handling for the LLM call.</li>\n",
        "       </ul>\n",
        "    </li>\n",
        "      <li style=\"color:#1E3A8A;\">\n",
        "      <strong>Human Input Node (<code>human_input_node</code>):</strong>\n",
        "      <ul>\n",
        "          <li>A LangGraph node function responsible for capturing the user's response.</li>\n",
        "          <li>Prints the last message from the agent (the question).</li>\n",
        "          <li><strong>Crucially, this is where the <code>INTERACTIVE_MODE</code> flag (defined in Step 2) should be implemented.</strong>\n",
        "              <ul>\n",
        "                  <li>If <code>INTERACTIVE_MODE</code> is <code>True</code>, it will use the <code>input()</code> function to pause and wait for the user to type a response in the console.</li>\n",
        "                  <li>If <code>INTERACTIVE_MODE</code> is <code>False</code>, it will retrieve a predefined response from a demo list (this logic needs to be added to the function) to simulate user input for automated runs.</li>\n",
        "              </ul>\n",
        "          </li>\n",
        "           <li>Handles 'quit' commands to signal the end of the conversation, setting the <code>is_finished</code> flag in the state.</li>\n",
        "          <li>Returns the updated state containing the new <code>HumanMessage</code>.</li>\n",
        "       </ul>\n",
        "    </li>\n",
        "  </ul>\n",
        "  <p style=\"color:gray; margin-top:10px; font-style: italic;\">\n",
        "   These components form the basic conversational turn-taking loop for gathering preferences within the LangGraph framework. The <code>human_input_node</code> requires modification to incorporate the `INTERACTIVE_MODE` logic.\n",
        "  </p>\n",
        "</div>"
      ],
      "metadata": {
        "id": "hKP4avoXrLY_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SUGGESTION_AGENT_MODEL = \"gemini-2.0-flash\"\n",
        "suggestion_llm = None\n",
        "suggestion_llm_with_tools = None\n",
        "\n",
        "try:\n",
        "    # Instantiate the base LLM\n",
        "    suggestion_llm = ChatGoogleGenerativeAI(\n",
        "        model=SUGGESTION_AGENT_MODEL,\n",
        "        temperature=0.7\n",
        "    )\n",
        "    print(f\"Initialized base LLM: {SUGGESTION_AGENT_MODEL}\")\n",
        "\n",
        "    suggestion_llm_with_tools = suggestion_llm.bind_tools(suggestion_tools)\n",
        "    print(f\"Bound tool '{suggestion_tools[0].name}' to the LLM.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"ERROR initializing LLM or binding tools: {e}\")\n",
        "\n",
        "\n",
        "# System Prompt for Asking Questions\n",
        "ASK_QUESTION_SYSTEM_PROMPT = \"\"\"You are 'Nomad,' a friendly AI travel assistant. Your current goal is ONLY to ask the *next* relevant question to understand the user's travel preferences.\n",
        "Analyze the conversation history. Identify which core preferences ('vibe', 'activities', 'weather', 'budget') have ALREADY been discussed.\n",
        "Ask ONE clear, concise question about the NEXT logical preference category that has NOT been discussed yet.\n",
        "Start with 'vibe', then 'activities', then 'weather', then 'budget'.\n",
        "**When asking a question, provide a few diverse examples in parentheses to help the user.**\n",
        "If the user provides information about multiple preferences at once, acknowledge it briefly and ask about the next *required* category they *didn't* cover.\n",
        "DO NOT suggest destinations. DO NOT ask for information you already have. Keep the conversation flowing naturally. Start the very first turn by asking about the 'vibe'.\n",
        "\n",
        "Example History (Vibe asked):\n",
        "[...]\n",
        "User: I want a relaxing beach vacation.\n",
        "You: Sounds lovely! What kind of activities do you enjoy on a relaxing trip? (e.g., spa treatments, reading by the pool, gentle walks, exploring local cafes?)\n",
        "\n",
        "Example History (Activities asked):\n",
        "[...]\n",
        "User: Hiking sounds fun. I prefer cool weather.\n",
        "You: Hiking in cool weather, got it! And what's your general budget looking like for this trip? (e.g., budget-friendly, mid-range, luxury?)\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# --- Node for Asking the Next Question ---\n",
        "def ask_question_node(state: SuggestionState) -> Dict[str, Any]:\n",
        "    \"\"\"Invokes the LLM to ask the next preference question.\"\"\"\n",
        "    if suggestion_llm is None:\n",
        "         print(\"Error: LLM for asking questions not available.\")\n",
        "         return {\"messages\": [AIMessage(content=\"My question module is offline.\")],\"error_message\": \"Question LLM not initialized.\"}\n",
        "\n",
        "    messages_for_llm = [SystemMessage(content=ASK_QUESTION_SYSTEM_PROMPT)] + state[\"messages\"]\n",
        "\n",
        "    try:\n",
        "        ai_response = suggestion_llm.invoke(messages_for_llm)\n",
        "        return {\"messages\": [ai_response]}\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error calling Question LLM: {type(e).__name__} - {e}\")\n",
        "        return {\n",
        "            \"messages\": [AIMessage(content=\"I seem to be having trouble formulating my question. Could you perhaps tell me about the vibe you're looking for?\")],\n",
        "            \"error_message\": f\"Failed to generate next question: {e}\"\n",
        "        }\n",
        "\n",
        "print(\"Question asking node ('ask_question_node') defined.\")\n",
        "\n",
        "\n",
        "# --- Node for Human Input ---\n",
        "demo_preference_answers = [\n",
        "    \"I'm looking for a relaxing vibe, maybe somewhere quiet.\",\n",
        "    \"Mainly spa treatments and maybe some light reading by a pool.\",\n",
        "    \"I definitely prefer warm and sunny weather.\",\n",
        "    \"Let's go with mid-range to luxury.\",\n",
        "    \"Marrakech\"\n",
        "]\n",
        "demo_answer_index = 0\n",
        "\n",
        "def human_input_node(state: SuggestionState) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Gets input from the user via the console OR uses predefined demo answers\n",
        "    based on INTERACTIVE_MODE. Sets 'is_finished' on exit.\n",
        "    \"\"\"\n",
        "    global demo_answer_index\n",
        "\n",
        "    if state.get(\"is_finished\"):\n",
        "        return {}\n",
        "\n",
        "    last_message = state[\"messages\"][-1]\n",
        "    if isinstance(last_message, AIMessage):\n",
        "        print(f\"\\nü§ñ Nomad: {last_message.content}\")\n",
        "\n",
        "        user_input = \"\"\n",
        "        if INTERACTIVE_MODE:\n",
        "            try:\n",
        "                user_input = input(\"üë§ You: \")\n",
        "            except EOFError:\n",
        "                user_input = \"quit\"\n",
        "        else:\n",
        "            if demo_answer_index < len(demo_preference_answers):\n",
        "                user_input = demo_preference_answers[demo_answer_index]\n",
        "                print(f\"üë§ You (Demo Input): {user_input}\")\n",
        "                demo_answer_index += 1\n",
        "            else:\n",
        "                print(\"‚ö†Ô∏è Demo Mode: Ran out of predefined preference answers. Using 'quit'.\")\n",
        "                user_input = \"quit\"\n",
        "\n",
        "        if user_input.strip().lower() in [\"q\", \"quit\", \"exit\", \"bye\"]:\n",
        "             return {\"messages\": [HumanMessage(content=user_input)], \"is_finished\": True}\n",
        "        else:\n",
        "             return {\"messages\": [HumanMessage(content=user_input)]}\n",
        "    else:\n",
        "        print(\"Warning: human_input_node called without preceding AIMessage.\")\n",
        "        return {}\n",
        "\n",
        "print(\"Human input node ('human_input_node') defined with INTERACTIVE_MODE logic.\")\n",
        "\n",
        "print(\"Human input node ('human_input_node') defined.\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "lcsj7Hr6rLY_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color:#EFF6FF; padding:15px; border-radius:8px; margin-top:20px; border:1px dashed #3B82F6;\">\n",
        "  <h2 style=\"color:#1E40AF; border-bottom: 2px solid #2563EB; padding-bottom: 5px;\">Step 9: Define Preference Parsing Components</h2>\n",
        "  <p style=\"color:gray; margin-top:10px;\">\n",
        "    After the user provides input (captured by <code>human_input_node</code>), the agent needs to understand and extract the specific preference mentioned. This cell defines the components responsible for this parsing task, utilizing structured output for reliability.\n",
        "  </p>\n",
        "  <ul style=\"background-color:#DBEAFE; padding:10px 10px 10px 30px; border-radius:6px; border:1px solid #BFDBFE; margin-top:10px; list-style-type: square;\">\n",
        "    <li style=\"color:#1E3A8A; margin-bottom:8px;\">\n",
        "      <strong>Parsing Schema (<code>ParsedPreference</code>):</strong> Defines a Pydantic <code>BaseModel</code> specifying the desired output structure for the parsing LLM. It includes fields for the identified <code>preference_key</code> and the corresponding <code>preference_value</code> extracted from the user's text, allowing for <code>null</code> if no clear preference is stated.\n",
        "    </li>\n",
        "    <li style=\"color:#1E3A8A; margin-bottom:8px;\">\n",
        "      <strong>Dedicated Parser LLM Initialization:</strong>\n",
        "        <ul>\n",
        "          <li>Initializes a separate <code>ChatGoogleGenerativeAI</code> instance (<code>parser_llm</code>) specifically for parsing.</li>\n",
        "          <li>Sets <code>temperature=0.0</code> to encourage deterministic and consistent output suitable for parsing tasks.</li>\n",
        "          <li>Creates <code>structured_parser_llm</code> by applying LangChain's <code>.with_structured_output(ParsedPreference)</code> method. This configures the LLM to specifically attempt to return JSON conforming to the <code>ParsedPreference</code> schema.</li>\n",
        "        </ul>\n",
        "    </li>\n",
        "    <li style=\"color:#1E3A8A; margin-bottom:8px;\">\n",
        "      <strong>System Prompt for Parsing (<code>PREFERENCE_PARSING_SYSTEM_PROMPT</code>):</strong>\n",
        "        <ul>\n",
        "          <li>Provides clear instructions and examples to the parsing LLM.</li>\n",
        "          <li>Guides it to analyze the last agent question and user response, extract the relevant category and value, and output *only* the JSON matching the schema.</li>\n",
        "          <li>Includes examples for handling cases where the user provides a preference and where they don't.</li>\n",
        "        </ul>\n",
        "    </li>\n",
        "    <li style=\"color:#1E3A8A;\">\n",
        "      <strong>Preference Parsing Node (<code>parse_preference_node</code>):</strong>\n",
        "      <ul>\n",
        "        <li>A LangGraph node function that takes the current agent state.</li>\n",
        "        <li>Extracts the last user message and the preceding AI question from the state's message history.</li>\n",
        "        <li>Constructs a prompt using these messages and the dedicated system prompt.</li>\n",
        "        <li>Invokes the <code>structured_parser_llm</code> to get the parsed preference in the defined JSON structure.</li>\n",
        "        <li>If parsing is successful and returns a valid key/value pair, it updates the <code>user_preferences</code> dictionary within the agent state.</li>\n",
        "        <li>Returns the updated state. Includes checks for the LLM's availability and handles potential errors during the LLM call.</li>\n",
        "      </ul>\n",
        "    </li>\n",
        "  </ul>\n",
        "  <p style=\"color:gray; margin-top:10px; font-style: italic;\">\n",
        "    Using a dedicated, low-temperature LLM call configured for structured output significantly improves the reliability of extracting user preferences compared to trying to parse within a more complex, generative step. This node updates the agent's memory with the understood preference.\n",
        "  </p>\n",
        "</div>"
      ],
      "metadata": {
        "id": "wS0e6qdLrLY_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ParsedPreference(BaseModel):\n",
        "    preference_key: Optional[str] = Field(description=\"Category: 'vibe', 'activities', 'weather', 'budget', or null.\")\n",
        "    preference_value: Optional[str] = Field(description=\"User's stated preference, or null.\")\n",
        "\n",
        "# --- Dedicated LLM for Parsing ---\n",
        "parser_llm = None\n",
        "structured_parser_llm = None\n",
        "try:\n",
        "    # Using the same model but low temperature for parsing consistency\n",
        "    parser_llm = ChatGoogleGenerativeAI(model=SUGGESTION_AGENT_MODEL, temperature=0.0)\n",
        "    structured_parser_llm = parser_llm.with_structured_output(ParsedPreference)\n",
        "    print(\"Initialized structured LLM for preference parsing.\")\n",
        "except Exception as e:\n",
        "    print(f\"ERROR initializing parser LLM: {e}\")\n",
        "\n",
        "# --- System Prompt for Parsing ---\n",
        "PREFERENCE_PARSING_SYSTEM_PROMPT = \"\"\"Analyze the last user message in the context of the preceding agent question.\n",
        "Extract the preference category ('vibe', 'activities', 'weather', 'budget', or null) and the user's stated preference value.\n",
        "Output ONLY JSON matching the 'ParsedPreference' schema.\n",
        "If the user's message doesn't clearly state a preference for the asked category, set both preference_key and preference_value to null.\n",
        "Agent Question: What kind of vibe are you hoping for?\n",
        "User Response: I want something really relaxing and quiet.\n",
        "JSON Output: {\"preference_key\": \"vibe\", \"preference_value\": \"relaxing and quiet\"}\n",
        "Agent Question: What kind of weather do you prefer?\n",
        "User Response: Doesn't matter much.\n",
        "JSON Output: {\"preference_key\": \"weather\", \"preference_value\": null}\"\"\"\n",
        "\n",
        "def parse_preference_node(state: SuggestionState) -> Dict[str, Any]:\n",
        "    \"\"\"Parses the last user message and updates user_preferences in the state.\"\"\"\n",
        "    if structured_parser_llm is None:\n",
        "        print(\"Error: Structured Parser LLM not available.\")\n",
        "        return {\"error_message\": \"Parser LLM not initialized.\"}\n",
        "\n",
        "    messages = state.get('messages', [])\n",
        "    if len(messages) < 2: return {}\n",
        "\n",
        "    last_human_message = messages[-1]\n",
        "    last_ai_message = messages[-2]\n",
        "\n",
        "    if not isinstance(last_human_message, HumanMessage) or not isinstance(last_ai_message, AIMessage):\n",
        "        return {}\n",
        "\n",
        "    parsing_prompt_content = f\"\"\"Agent Question: {last_ai_message.content}\n",
        "User Response: {last_human_message.content}\"\"\"\n",
        "\n",
        "    messages_for_llm = [\n",
        "        SystemMessage(content=PREFERENCE_PARSING_SYSTEM_PROMPT),\n",
        "        HumanMessage(content=parsing_prompt_content)\n",
        "    ]\n",
        "\n",
        "    try:\n",
        "        parsed_result: ParsedPreference = structured_parser_llm.invoke(messages_for_llm)\n",
        "\n",
        "        current_preferences = state.get('user_preferences', {}).copy()\n",
        "\n",
        "        if isinstance(parsed_result, ParsedPreference) and parsed_result.preference_key and parsed_result.preference_value:\n",
        "            key = parsed_result.preference_key\n",
        "            value = parsed_result.preference_value\n",
        "            if key in ['vibe', 'activities', 'weather', 'budget']:\n",
        "                current_preferences[key] = value\n",
        "                return {\"user_preferences\": current_preferences}\n",
        "            else:\n",
        "                 return {}\n",
        "        else:\n",
        "             return {}\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error calling structured parser LLM: {type(e).__name__} - {e}\")\n",
        "        return {\"error_message\": f\"Failed to parse user preference: {e}\"}\n",
        "\n",
        "print(\"Explicit preference parsing node defined.\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "-nRDHROcrLZA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color:#F0FDF4; padding:15px; border-radius:8px; margin-top:20px; border:1px dashed #22C55E;\">\n",
        "  <h2 style=\"color:#15803D; border-bottom: 2px solid #16A34A; padding-bottom: 5px;\">Step 10: Define Recommendation Generation Components</h2>\n",
        "  <p style=\"color:gray; margin-top:10px;\">\n",
        "    Once all necessary user preferences ('vibe', 'activities', 'weather', 'budget') have been collected and parsed, the agent needs to generate initial city suggestions. This cell defines the Pydantic models for the output structure, the LLM configuration, the prompt, and the LangGraph node responsible for generating these text-based recommendations.\n",
        "  </p>\n",
        "  <ul style=\"background-color:#ECFDF5; padding:10px 10px 10px 30px; border-radius:6px; border:1px solid #D1FAE5; margin-top:10px; list-style-type: square;\">\n",
        "    <li style=\"color:#065F46; margin-bottom:8px;\">\n",
        "      <strong>Recommendation Schemas (Pydantic):</strong>\n",
        "        <ul>\n",
        "            <li><code>RecommendationPydantic</code>: Defines the structure for a single text-only recommendation, including city, country, description, and justification. This focuses only on the content generated by the LLM at this stage.</li>\n",
        "            <li><code>CityRecommendationsList</code>: Defines the overall structure the LLM should return ‚Äì a list containing multiple <code>RecommendationPydantic</code> objects.</li>\n",
        "        </ul>\n",
        "    </li>\n",
        "    <li style=\"color:#065F46; margin-bottom:8px;\">\n",
        "      <strong>Recommender LLM Initialization:</strong>\n",
        "        <ul>\n",
        "            <li>Initializes a <code>ChatGoogleGenerativeAI</code> instance (<code>recommender_llm</code>) using the specified model (<code>SUGGESTION_AGENT_MODEL</code>) and a moderate temperature (<code>0.7</code>) suitable for creative suggestions.</li>\n",
        "            <li>Creates <code>structured_recommender_llm</code> by binding the LLM to the desired output schema using <code>.with_structured_output(CityRecommendationsList)</code>. This instructs the LLM to generate JSON conforming to our list structure.</li>\n",
        "            <li>Includes error handling for initialization (depends on Google API client from Step 2).</li>\n",
        "        </ul>\n",
        "    </li>\n",
        "     <li style=\"color:#065F46; margin-bottom:8px;\">\n",
        "      <strong>Recommendation Prompt Template (<code>RECOMMENDATION_PROMPT_TEMPLATE</code>):</strong>\n",
        "        <ul>\n",
        "            <li>Defines the instructions for the recommendation LLM.</li>\n",
        "            <li>Takes the collected user preferences as input.</li>\n",
        "            <li>Instructs the LLM to recommend 3-5 diverse global cities, providing specific details (city, country, description, justification) for each.</li>\n",
        "            <li>Explicitly tells the LLM to output *only* the JSON matching the <code>CityRecommendationsList</code> schema, without any extra conversational text.</li>\n",
        "        </ul>\n",
        "    </li>\n",
        "    <li style=\"color:#065F46;\">\n",
        "      <strong>Recommendation Generation Node (<code>generate_recommendations_node</code>):</strong>\n",
        "      <ul>\n",
        "          <li>A LangGraph node function triggered when all preferences are available.</li>\n",
        "          <li>Checks if the required preferences exist in the agent state.</li>\n",
        "          <li>Formats the <code>RECOMMENDATION_PROMPT_TEMPLATE</code> with the actual user preferences from the state.</li>\n",
        "          <li>Invokes the <code>structured_recommender_llm</code> to generate the structured list of recommendations.</li>\n",
        "          <li>If successful, extracts the recommendation dictionaries from the parsed Pydantic object and stores them in the <code>text_recommendations</code> field of the agent state.</li>\n",
        "          <li>Includes checks for LLM availability and error handling for the LLM call and response parsing.</li>\n",
        "      </ul>\n",
        "    </li>\n",
        "  </ul>\n",
        "  <p style=\"color:gray; margin-top:10px; font-style: italic;\">\n",
        "    This node represents a core reasoning step where the agent synthesizes user input into actionable suggestions, leveraging structured output for consistency before further enrichment (like adding images).\n",
        "  </p>\n",
        "</div>"
      ],
      "metadata": {
        "id": "Zcq-mu3mrLZA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RecommendationPydantic(BaseModel):\n",
        "    \"\"\"Pydantic model for a single recommendation.\"\"\"\n",
        "    city: str = Field(description=\"Name of the recommended city.\")\n",
        "    country: str = Field(description=\"Country where the city is located.\")\n",
        "    description: str = Field(description=\"A brief, engaging description (~2-3 sentences).\")\n",
        "    justification: str = Field(description=\"Specific reason (~1-2 sentences) linking to user preferences.\")\n",
        "\n",
        "class CityRecommendationsList(BaseModel):\n",
        "    \"\"\"Pydantic model for the list of text-only recommendations.\"\"\"\n",
        "    recommendations: List[RecommendationPydantic] = Field(description=\"A list of 3-5 diverse city recommendations.\")\n",
        "\n",
        "recommender_llm = None\n",
        "structured_recommender_llm = None\n",
        "try:\n",
        "    recommender_llm = ChatGoogleGenerativeAI(model=SUGGESTION_AGENT_MODEL, temperature=0.7)\n",
        "    structured_recommender_llm = recommender_llm.with_structured_output(CityRecommendationsList)\n",
        "    print(\"Initialized structured LLM for recommendation generation.\")\n",
        "except Exception as e:\n",
        "    print(f\"ERROR initializing recommender LLM: {e}\")\n",
        "\n",
        "# --- Prompt Template for Recommendation Generation ---\n",
        "RECOMMENDATION_PROMPT_TEMPLATE = \"\"\"\n",
        "Based ONLY on the following user travel preferences:\n",
        "Vibe: {vibe}\n",
        "Activities: {activities}\n",
        "Weather: {weather}\n",
        "Budget Indication: {budget}\n",
        "\n",
        "Recommend 3-5 diverse global cities that fit well.\n",
        "For each city, provide: city name, country, a brief compelling description (~2-3 sentences), and a specific justification (~1-2 sentences) explaining the match.\n",
        "Return ONLY the recommendations in the specified JSON format matching the 'CityRecommendationsList' schema. Do NOT add any introductory text or other commentary.\n",
        "\"\"\"\n",
        "\n",
        "# --- Recommendation Generation Node ---\n",
        "def generate_recommendations_node(state: SuggestionState) -> Dict[str, Any]:\n",
        "    \"\"\"Generates text-only recommendations based on parsed preferences.\"\"\"\n",
        "    if structured_recommender_llm is None:\n",
        "         print(\"Error: Structured Recommender LLM not available.\")\n",
        "         return {\"error_message\": \"Recommender LLM not initialized.\"}\n",
        "\n",
        "    prefs = state.get('user_preferences')\n",
        "    required_keys = ['vibe', 'activities', 'weather', 'budget']\n",
        "    if not prefs or not all(key in prefs for key in required_keys):\n",
        "        missing = [key for key in required_keys if key not in prefs]\n",
        "        print(f\"Error: Cannot generate recommendations, missing preferences: {missing}\")\n",
        "        return {\"error_message\": f\"Cannot generate recommendations: Missing {', '.join(missing)} preference.\"}\n",
        "\n",
        "    prompt_content = RECOMMENDATION_PROMPT_TEMPLATE.format(\n",
        "         vibe=prefs.get('vibe', 'not specified'),\n",
        "         activities=prefs.get('activities', 'not specified'),\n",
        "         weather=prefs.get('weather', 'not specified'),\n",
        "         budget=prefs.get('budget', 'not specified')\n",
        "    )\n",
        "    messages_for_llm = [HumanMessage(content=prompt_content)]\n",
        "\n",
        "    try:\n",
        "        parsed_response: CityRecommendationsList = structured_recommender_llm.invoke(messages_for_llm)\n",
        "\n",
        "        text_recs_list = []\n",
        "        if isinstance(parsed_response, CityRecommendationsList) and parsed_response.recommendations:\n",
        "            for rec_pydantic in parsed_response.recommendations:\n",
        "                 text_recs_list.append(rec_pydantic.dict())\n",
        "            return {\"text_recommendations\": text_recs_list}\n",
        "        else:\n",
        "             print(\"Warning: Structured recommender returned invalid or empty response.\")\n",
        "             return {\"error_message\": \"Failed to get structured recommendations from LLM.\"}\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error invoking structured recommender LLM: {type(e).__name__} - {e}\")\n",
        "        return {\"error_message\": f\"Failed to generate recommendations: {e}\"}\n",
        "\n",
        "print(\"Structured recommendation generation node defined.\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "gx0XCitErLZA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color:#F0FDF4; padding:15px; border-radius:8px; margin-top:20px; border:1px dashed #22C55E;\">\n",
        "  <h2 style=\"color:#15803D; border-bottom: 2px solid #16A34A; padding-bottom: 5px;\">Step 11: Define Recommendation Verification Node</h2>\n",
        "  <p style=\"color:gray; margin-top:10px;\">\n",
        "    After the LLM generates city recommendations, we need to determine which of these suggestions correspond to cities for which we actually have detailed Point of Interest (POI) data in our loaded Wikivoyage dataset. This verification step is crucial for guiding the user towards selections where we can provide richer information later.\n",
        "  </p>\n",
        "  <ul style=\"background-color:#ECFDF5; padding:10px 10px 10px 30px; border-radius:6px; border:1px solid #D1FAE5; margin-top:10px; list-style-type: square;\">\n",
        "    <li style=\"color:#065F46; margin-bottom:8px;\">\n",
        "      <strong>Prepare Verification Data:</strong>\n",
        "        <ul>\n",
        "            <li>Checks if the <code>list_of_unique_cities</code> (extracted during data preprocessing in Step 4.1) exists.</li>\n",
        "            <li>If it exists, it creates <code>unique_cities_lower</code>, a Python <code>set</code> containing all unique city names from our dataset converted to lowercase. Using a set provides highly efficient (average O(1)) lookups.</li>\n",
        "            <li>If the list is missing, it prints an error and creates an empty set to prevent runtime errors, although verification will effectively fail.</li>\n",
        "        </ul>\n",
        "    </li>\n",
        "    <li style=\"color:#065F46;\">\n",
        "      <strong>Verification Node (<code>verify_recommendations_node</code>):</strong>\n",
        "      <ul>\n",
        "          <li>A LangGraph node function that takes the current agent state.</li>\n",
        "          <li>Retrieves the list of generated <code>text_recommendations</code> from the state.</li>\n",
        "          <li>Iterates through each recommended city dictionary.</li>\n",
        "          <li>Performs a case-insensitive check by converting the recommended city name to lowercase and seeing if it exists in the <code>unique_cities_lower</code> set.</li>\n",
        "          <li>Creates a copy of the original recommendation dictionary and adds a new boolean key, <code>has_data</code>, indicating the result of the check (<code>True</code> if found in our dataset, <code>False</code> otherwise).</li>\n",
        "          <li>Builds a new list (<code>updated_text_recs</code>) containing these enriched dictionaries.</li>\n",
        "          <li>Also builds a simple list (<code>cities_with_data</code>) containing the names of only those cities that were found in our dataset.</li>\n",
        "          <li>Returns the updated state, overwriting <code>text_recommendations</code> with the list now containing the <code>has_data</code> flag, and populating the <code>cities_with_data</code> list.</li>\n",
        "          <li>Includes checks for missing input recommendations or the verification set.</li>\n",
        "      </ul>\n",
        "    </li>\n",
        "  </ul>\n",
        "  <p style=\"color:gray; margin-top:10px; font-style: italic;\">\n",
        "    This node acts as a bridge between the LLM's creative suggestions and the structured data we possess. The <code>has_data</code> flag added here will be used in the final presentation to the user, clearly marking which cities can be explored in more detail in Phase 2.\n",
        "  </p>\n",
        "</div>"
      ],
      "metadata": {
        "id": "YKR_rlQUrLZA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "\n",
        "if 'list_of_unique_cities' in globals():\n",
        "    unique_cities_lower = {city.lower() for city in list_of_unique_cities}\n",
        "    print(f\"Verification node ready. Using {len(unique_cities_lower)} unique lowercase city names from dataset.\")\n",
        "else:\n",
        "    print(\"ERROR: 'list_of_unique_cities' not found. Verification node cannot run.\")\n",
        "    unique_cities_lower = set()\n",
        "\n",
        "def verify_recommendations_node(state: SuggestionState) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Checks generated text recommendations against the loaded dataset cities.\n",
        "    Adds 'has_data' flag to each recommendation in 'text_recommendations'.\n",
        "    Populates 'cities_with_data' list.\n",
        "    \"\"\"\n",
        "    text_recs = state.get('text_recommendations', [])\n",
        "\n",
        "    if not text_recs:\n",
        "        print(\"Warning: No text recommendations found in state to verify.\")\n",
        "        return {\"cities_with_data\": []}\n",
        "\n",
        "    # Check prerequisites\n",
        "    if not unique_cities_lower:\n",
        "         print(\"Error: Cannot verify recommendations, city dataset list is empty.\")\n",
        "         return {\"error_message\": \"Verification failed: City dataset list unavailable.\"}\n",
        "\n",
        "    updated_text_recs = []\n",
        "    cities_found_in_data = []\n",
        "\n",
        "    for rec in text_recs:\n",
        "        if not isinstance(rec, dict):\n",
        "            print(f\"Warning: Skipping invalid item in text_recommendations: {rec}\")\n",
        "            continue\n",
        "\n",
        "        city_name = rec.get('city', '')\n",
        "        city_name_lower = city_name.lower()\n",
        "\n",
        "        has_data = city_name_lower in unique_cities_lower\n",
        "\n",
        "        updated_rec = rec.copy()\n",
        "        updated_rec['has_data'] = has_data\n",
        "        updated_text_recs.append(updated_rec)\n",
        "\n",
        "        if has_data:\n",
        "            cities_found_in_data.append(city_name)\n",
        "\n",
        "    return {\n",
        "        \"text_recommendations\": updated_text_recs,\n",
        "        \"cities_with_data\": cities_found_in_data\n",
        "    }"
      ],
      "metadata": {
        "trusted": true,
        "id": "42vp2Q94rLZA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color:#EFF6FF; padding:15px; border-radius:8px; margin-top:20px; border:1px dashed #3B82F6;\">\n",
        "  <h2 style=\"color:#1E40AF; border-bottom: 2px solid #2563EB; padding-bottom: 5px;\">Step 12: Define Image Tool Trigger & Final Output Formatting Nodes</h2>\n",
        "  <p style=\"color:gray; margin-top:10px;\">\n",
        "    After verifying the recommendations, the next steps involve fetching visual enhancements (images) using the previously defined tool and then presenting the final, enriched recommendations to the user. This cell defines the LangGraph nodes responsible for these actions.\n",
        "  </p>\n",
        "  <ul style=\"background-color:#DBEAFE; padding:10px 10px 10px 30px; border-radius:6px; border:1px solid #BFDBFE; margin-top:10px; list-style-type: square;\">\n",
        "    <li style=\"color:#1E3A8A; margin-bottom:8px;\">\n",
        "      <strong>Image Tool Trigger Node (<code>call_image_tool_node</code>):</strong>\n",
        "        <ul>\n",
        "            <li>Purpose: To construct and return an <code>AIMessage</code> that explicitly requests the execution of the <code>unsplash_get_image</code> tool for each recommendation.</li>\n",
        "            <li>Retrieves the verified <code>text_recommendations</code> list from the state.</li>\n",
        "            <li>Iterates through the recommendations and creates a structured tool call specification (including name, arguments like city/country, and a unique ID) for each one, using the predefined <code>UNSPLASH_TOOL_NAME</code>.</li>\n",
        "            <li>Bundles these tool calls into the <code>tool_calls</code> attribute of an <code>AIMessage</code>. This message signals to LangGraph that the next step should be the <code>ToolNode</code> responsible for executing these calls.</li>\n",
        "            <li>Includes checks for missing recommendations or tool name configuration.</li>\n",
        "        </ul>\n",
        "    </li>\n",
        "    <li style=\"color:#1E3A8A;\">\n",
        "      <strong>Final Output Formatting Node (<code>format_final_output_node</code>):</strong>\n",
        "      <ul>\n",
        "          <li>Purpose: To combine the text information for each recommendation with the image URLs obtained from the executed tool calls, and present everything to the user in a rich HTML format. This node runs *after* the <code>ToolNode</code> has executed the image fetches.</li>\n",
        "          <li>Retrieves the <code>text_recommendations</code> (which include the <code>has_data</code> flag) and the full message history from the state.</li>\n",
        "          <li>Parses the message history backwards to find the results (image URLs or placeholder/error strings) returned in <code>ToolMessage</code> objects, matching them to the original tool call IDs generated in the previous node.</li>\n",
        "          <li>Constructs an HTML string containing styled cards for each recommendation.</li>\n",
        "          <li>Each card displays the city, country, fetched (or placeholder) image, description, justification, and a status indicator (‚úÖ/‚ÑπÔ∏è) based on the <code>has_data</code> flag.</li>\n",
        "          <li>Uses IPython's <code>display(HTML(...))</code> to render the formatted output directly in the notebook.</li>\n",
        "          <li>Updates the agent state by populating the <code>recommendations</code> field with a list of dictionaries containing the *final* combined data (including the resolved image URLs).</li>\n",
        "          <li>Includes checks for missing recommendations or the placeholder URL constant.</li>\n",
        "       </ul>\n",
        "    </li>\n",
        "  </ul>\n",
        "</div>"
      ],
      "metadata": {
        "id": "go29R2p7rLZA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def call_image_tool_node(state: SuggestionState) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Constructs the AIMessage with tool calls for Unsplash images based on\n",
        "    the verified text recommendations stored in the state.\n",
        "    \"\"\"\n",
        "    text_recommendations = state.get(\"text_recommendations\")\n",
        "\n",
        "    if not text_recommendations:\n",
        "        print(\"Error: No text recommendations found in state to trigger image fetching.\")\n",
        "        return {\"messages\": [AIMessage(content=\"Sorry, I couldn't generate recommendations to get images for.\")], \"is_finished\": True}\n",
        "\n",
        "    tool_calls = []\n",
        "    if 'UNSPLASH_TOOL_NAME' not in globals():\n",
        "         print(\"ERROR: UNSPLASH_TOOL_NAME not found.\")\n",
        "         return {\"error_message\": \"Tool name configuration missing.\", \"is_finished\": True}\n",
        "\n",
        "    for i, rec in enumerate(text_recommendations):\n",
        "        city = rec.get(\"city\")\n",
        "        country = rec.get(\"country\")\n",
        "        if city:\n",
        "            call_id = f\"{UNSPLASH_TOOL_NAME}_{i}_{city.replace(' ','_')}\"\n",
        "            tool_calls.append({\n",
        "                \"name\": UNSPLASH_TOOL_NAME,\n",
        "                \"args\": {\"city\": city, \"country\": country},\n",
        "                \"id\": call_id\n",
        "            })\n",
        "\n",
        "    if not tool_calls:\n",
        "         print(\"Warning: No tool calls could be generated for images.\")\n",
        "         ai_message_content = \"I have the recommendations, but couldn't prepare image requests.\"\n",
        "         return {\"messages\": [AIMessage(content=ai_message_content)]}\n",
        "\n",
        "\n",
        "    ai_message_with_calls = AIMessage(\n",
        "        content=\"Okay, I've generated recommendations based on your preferences. Let me quickly fetch some images...\",\n",
        "        tool_calls=tool_calls\n",
        "    )\n",
        "\n",
        "    return {\"messages\": [ai_message_with_calls]}\n",
        "\n",
        "def format_final_output_node(state: SuggestionState) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Formats the final response combining text recommendations and image URLs received\n",
        "    from the ToolNode. Uses HTML for presentation.\n",
        "    \"\"\"\n",
        "    text_recommendations = state.get(\"text_recommendations\")\n",
        "    messages = state.get(\"messages\", [])\n",
        "\n",
        "    if 'PLACEHOLDER_IMAGE_URL' not in globals():\n",
        "         print(\"ERROR: PLACEHOLDER_IMAGE_URL not found.\")\n",
        "         return {\"error_message\": \"Placeholder URL configuration missing.\", \"is_finished\": True}\n",
        "\n",
        "    final_recommendations_list = []\n",
        "\n",
        "    if not text_recommendations:\n",
        "        print(\"Error: Cannot format final output, text recommendations missing in state.\")\n",
        "        return {\"messages\": [AIMessage(content=\"Sorry, something went wrong, I seem to have lost the recommendations list.\")], \"is_finished\": True}\n",
        "\n",
        "    tool_results = {}\n",
        "\n",
        "    for msg in reversed(messages):\n",
        "        if isinstance(msg, ToolMessage):\n",
        "            tool_results[msg.tool_call_id] = msg.content\n",
        "        elif isinstance(msg, AIMessage) and msg.tool_calls:\n",
        "            break\n",
        "        elif isinstance(msg, AIMessage) and not msg.tool_calls:\n",
        "            pass\n",
        "\n",
        "    display_html = '<div style=\"font-family: sans-serif; line-height: 1.6;\">'\n",
        "    display_html += '<h3 style=\"color: #1a237e;\">‚úàÔ∏è Here are your personalized travel recommendations! üåç</h3>'\n",
        "    display_html += '<div style=\"display: flex; flex-wrap: wrap; gap: 20px; justify-content: flex-start;\">'\n",
        "\n",
        "    for i, rec in enumerate(text_recommendations):\n",
        "        city = rec.get('city', 'N/A')\n",
        "        country = rec.get('country', '')\n",
        "        description = rec.get('description', 'No description available.')\n",
        "        justification = rec.get('justification', '')\n",
        "        has_data = rec.get('has_data', False)\n",
        "\n",
        "        if 'UNSPLASH_TOOL_NAME' not in globals():\n",
        "             print(\"ERROR: UNSPLASH_TOOL_NAME not defined in format_final_output_node.\")\n",
        "             image_url = PLACEHOLDER_IMAGE_URL\n",
        "        else:\n",
        "             expected_call_id = f\"{UNSPLASH_TOOL_NAME}_{i}_{city.replace(' ','_')}\"\n",
        "             image_url = tool_results.get(expected_call_id, PLACEHOLDER_IMAGE_URL)\n",
        "\n",
        "        if not isinstance(image_url, str) or \"Error:\" in image_url or \"Not found.\" in image_url:\n",
        "             final_image_url = PLACEHOLDER_IMAGE_URL\n",
        "        else:\n",
        "             final_image_url = image_url\n",
        "\n",
        "        card_style = (\n",
        "            'border: 1px solid #ccc; border-radius: 8px; padding: 15px; '\n",
        "            'background-color: #f9f9f9; '\n",
        "            'width: calc(50% - 10px); '\n",
        "            'box-sizing: border-box; '\n",
        "            'box-shadow: 2px 2px 5px rgba(0,0,0,0.1); margin-bottom: 20px; '\n",
        "            'display: flex; flex-direction: column; justify-content: space-between;'\n",
        "        )\n",
        "        text_style = 'color: #333; font-size: 0.95em; margin-bottom: 8px;'\n",
        "        title_style = 'margin-top: 0; color: #3f51b5; margin-bottom: 10px; font-size: 1.2em;'\n",
        "        img_style = 'max-width: 100%; height: 180px; border-radius: 4px; margin-bottom: 10px; object-fit: cover;'\n",
        "        status_style = 'margin-top: 10px; padding-top: 10px; border-top: 1px solid #eee; font-weight: bold; font-size: 0.9em;'\n",
        "\n",
        "        display_html += f'<div style=\"{card_style}\">'\n",
        "        display_html += f'<div>'\n",
        "        display_html += f'<h4 style=\"{title_style}\">{i+1}. {city}, {country}</h4>'\n",
        "        if final_image_url:\n",
        "             if final_image_url.startswith(\"http\"):\n",
        "                  display_html += f'<img src=\"{final_image_url}\" alt=\"Image of {city}\" style=\"{img_style}\">'\n",
        "             else:\n",
        "                  display_html += f'<p style=\"{text_style}\">(Placeholder: {final_image_url})</p>'\n",
        "\n",
        "        display_html += f'<p style=\"{text_style}\"><strong>Description:</strong> {description}</p>'\n",
        "        display_html += f'<p style=\"{text_style}\"><strong>Why it fits:</strong> {justification}</p>'\n",
        "        display_html += f'</div>'\n",
        "\n",
        "        if has_data:\n",
        "            display_html += f'<div style=\"{status_style} color: #27ae60;\">‚úÖ Details Available - Type \"{city}\" to explore</div>'\n",
        "        else:\n",
        "            display_html += f'<div style=\"{status_style} color: #e67e22;\">‚ÑπÔ∏è Basic info only</div>'\n",
        "        display_html += f'</div>'\n",
        "\n",
        "\n",
        "        final_recommendations_list.append({\n",
        "             \"city\": city, \"country\": country, \"description\": description,\n",
        "             \"justification\": justification, \"image_url\": final_image_url,\n",
        "             \"has_data\": has_data\n",
        "        })\n",
        "\n",
        "    display_html += \"</div>\"\n",
        "    display_html += '<p style=\"margin-top: 20px; color: #555;\">Let me know if any of these catch your eye! You can type the city name with the ‚úÖ to get more details.</p>'\n",
        "    display_html += \"</div>\"\n",
        "\n",
        "    display(HTML(display_html))\n",
        "\n",
        "    return {\n",
        "        \"messages\": [AIMessage(content=\"Please review the recommendations above.\")],\n",
        "        \"recommendations\": final_recommendations_list\n",
        "        }\n",
        "\n",
        "print(\"Nodes for triggering image tool calls ('call_image_tool_node') and formatting final output ('format_final_output_node') defined.\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "451MsOdfrLZB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color:#EFF6FF; padding:15px; border-radius:8px; margin-top:20px; border:1px dashed #3B82F6;\">\n",
        "  <h2 style=\"color:#1E40AF; border-bottom: 2px solid #2563EB; padding-bottom: 5px;\">Step 13: Define User City Selection Node</h2>\n",
        "  <p style=\"color:gray; margin-top:10px;\">\n",
        "    After presenting the enriched recommendations, the agent needs to prompt the user to choose one of the cities for which detailed information is available (marked with ‚úÖ). This node handles that interaction and determines whether to proceed to Phase 2 or end the session.\n",
        "  </p>\n",
        "  <ul style=\"background-color:#DBEAFE; padding:10px 10px 10px 30px; border-radius:6px; border:1px solid #BFDBFE; margin-top:10px; list-style-type: square;\">\n",
        "    <li style=\"color:#1E3A8A; margin-bottom:8px;\">\n",
        "      <strong>Node Logic (<code>get_selection_node</code>):</strong>\n",
        "        <ul>\n",
        "            <li>Retrieves the final <code>recommendations</code> list (containing image URLs and <code>has_data</code> flags) from the state.</li>\n",
        "            <li>Filters this list to identify only the cities where <code>has_data</code> is <code>True</code>. These become the valid choices for the user.</li>\n",
        "            <li>Checks if any valid choices exist. If not (e.g., no recommendations had data), it ends the session with an error message.</li>\n",
        "            <li>Constructs a prompt message listing the valid city options and the 'quit' command.</li>\n",
        "            <li><strong>Handles Interaction Mode (<code>INTERACTIVE_MODE</code>):</strong>\n",
        "                <ul>\n",
        "                  <li>If <code>INTERACTIVE_MODE</code> is <code>True</code>: Enters a loop that uses <code>input()</code> to get the user's typed choice. It validates the input against the valid city names (case-insensitive) or 'quit'. It re-prompts if the input is invalid.</li>\n",
        "                  <li>If <code>INTERACTIVE_MODE</code> is <code>False</code>: Skips the <code>input()</code> prompt. It should automatically select the *first* city from the list of valid choices to simulate a selection for the demo run. If there are no valid choices, it should behave like 'quit'.</li>\n",
        "                </ul>\n",
        "            </li>\n",
        "             <li><strong>State Update:</strong> Based on the valid input (real or demo):\n",
        "                <ul>\n",
        "                    <li>If 'quit' is chosen (or no valid cities in demo mode), it sets <code>is_finished=True</code> and <code>selected_city_for_phase_2=None</code>.</li>\n",
        "                    <li>If a valid city is chosen, it sets <code>is_finished=True</code> and stores the selected city name (preserving original casing) in <code>selected_city_for_phase_2</code>.</li>\n",
        "                </ul>\n",
        "            </li>\n",
        "            <li>Includes error handling for potential issues during input processing.</li>\n",
        "        </ul>\n",
        "    </li>\n",
        "  </ul>\n",
        "  <p style=\"color:gray; margin-top:10px; font-style: italic;\">\n",
        "    Modification is required for the <code>INTERACTIVE_MODE</code> logic.\n",
        "  </p>\n",
        "</div>"
      ],
      "metadata": {
        "id": "v-fpnapYrLZB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_selection_node(state: SuggestionState) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Prompts the user to select a city OR automatically selects one in demo mode.\n",
        "    Updates the state with the selection or signals exit.\n",
        "    This node always transitions to END for Phase 1 graph.\n",
        "    \"\"\"\n",
        "    recommendations = state.get('recommendations', [])\n",
        "    if not recommendations:\n",
        "        print(\"Error: No recommendations available to select from.\")\n",
        "        return {\"is_finished\": True, \"error_message\": \"Selection error: No recommendations found.\", \"selected_city_for_phase_2\": None}\n",
        "\n",
        "    valid_choices_map = {\n",
        "        rec['city'].lower(): rec['city']\n",
        "        for rec in recommendations if isinstance(rec, dict) and rec.get('has_data') and rec.get('city')\n",
        "    }\n",
        "    valid_cities_original_case = list(valid_choices_map.values())\n",
        "\n",
        "    if not valid_choices_map:\n",
        "        print(\"None of the recommendations have detailed data available in our system.\")\n",
        "        return {\"is_finished\": True, \"error_message\": \"No recommendations with details available.\", \"selected_city_for_phase_2\": None}\n",
        "\n",
        "    selected_city_original_case = None\n",
        "\n",
        "    if INTERACTIVE_MODE:\n",
        "        prompt_message = \"\\nPlease enter the name of a city with '‚úÖ Details Available' to explore further.\"\n",
        "        prompt_message += f\"\\nValid options: {', '.join(valid_cities_original_case)}\"\n",
        "        prompt_message += \"\\nOr 'quit' to exit: \"\n",
        "\n",
        "        while True:\n",
        "            try:\n",
        "                user_input_raw = input(prompt_message)\n",
        "                user_input_clean = user_input_raw.strip().lower()\n",
        "\n",
        "                if user_input_clean == 'quit':\n",
        "                    print(\"Exiting.\")\n",
        "                    selected_city_original_case = None\n",
        "                    break\n",
        "\n",
        "                elif user_input_clean in valid_choices_map:\n",
        "                     selected_city_original_case = valid_choices_map[user_input_clean]\n",
        "                     print(f\"Great! Preparing to explore {selected_city_original_case}...\")\n",
        "                     break\n",
        "                else:\n",
        "                    print(f\"'{user_input_raw}' is not a valid option or does not have details available.\")\n",
        "\n",
        "            except EOFError:\n",
        "                print(\"\\nEOFError detected, treating as quit.\")\n",
        "                selected_city_original_case = None\n",
        "                break\n",
        "            except Exception as e:\n",
        "                print(f\"An error occurred during input: {e}. Exiting.\")\n",
        "                return {\"is_finished\": True, \"error_message\": f\"Input error: {e}\", \"selected_city_for_phase_2\": None}\n",
        "\n",
        "    else:\n",
        "        if valid_cities_original_case:\n",
        "            selected_city_original_case = valid_cities_original_case[0]\n",
        "            print(f\"ü§ñ Demo Mode: Automatically selecting first valid city: {selected_city_original_case}\")\n",
        "        else:\n",
        "            print(\"ü§ñ Demo Mode: No valid cities found to auto-select. Treating as quit.\")\n",
        "            selected_city_original_case = None\n",
        "\n",
        "    return {\"is_finished\": True, \"selected_city_for_phase_2\": selected_city_original_case}\n",
        "\n",
        "\n",
        "print(\"User selection node ('get_selection_node') defined.\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "BIexe75KrLZB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color:#EFF6FF; padding:15px; border-radius:8px; margin-top:20px; border:1px dashed #3B82F6;\">\n",
        "  <h2 style=\"color:#1E40AF; border-bottom: 2px solid #2563EB; padding-bottom: 5px;\">Step 14: Define Conditional Edge Logic</h2>\n",
        "  <p style=\"color:gray; margin-top:10px;\">\n",
        "    LangGraph allows for dynamic conversational flows using conditional edges. These functions examine the current agent state and return the name of the next node to execute, enabling branching and looping within the graph.\n",
        "  </p>\n",
        "  <ul style=\"background-color:#DBEAFE; padding:10px 10px 10px 30px; border-radius:6px; border:1px solid #BFDBFE; margin-top:10px; list-style-type: square;\">\n",
        "    <li style=\"color:#1E3A8A; margin-bottom:8px;\">\n",
        "      <strong><code>check_preferences_complete</code> Function:</strong>\n",
        "        <ul>\n",
        "            <li>Purpose: To control the preference gathering loop. This function is called after the <code>parse_preference_node</code>.</li>\n",
        "            <li>Checks if the <code>is_finished</code> flag is set in the state (e.g., user typed 'quit'). If so, it routes to the special <code>END</code> node, terminating the graph execution.</li>\n",
        "            <li>Checks if all required preference keys ('vibe', 'activities', 'weather', 'budget') are present in the <code>state['user_preferences']</code> dictionary.</li>\n",
        "            <li>If all preferences are collected, it returns the string <code>\"generate_recommendations\"</code>, directing the graph to the node that generates city suggestions.</li>\n",
        "            <li>If any preferences are missing, it returns the string <code>\"ask_question\"</code>, directing the graph back to the node that asks the next question, thus continuing the loop.</li>\n",
        "        </ul>\n",
        "    </li>\n",
        "    <li style=\"color:#1E3A8A;\">\n",
        "      <strong><code>route_after_tool_trigger</code> Function:</strong>\n",
        "      <ul>\n",
        "          <li>Purpose: To decide whether to execute the tool node or skip it. This function is called after the <code>call_image_tool_node</code>.</li>\n",
        "          <li>Examines the last message added to the state (which should be the <code>AIMessage</code> created by <code>call_image_tool_node</code>).</li>\n",
        "          <li>Checks if this message has a <code>tool_calls</code> attribute and if it's populated (i.e., if the previous node actually requested tool execution).</li>\n",
        "          <li>If tool calls exist, it returns the string <code>\"image_tool_executor\"</code>, routing the graph to the <code>ToolNode</code> responsible for running the Unsplash image tool.</li>\n",
        "          <li>If no tool calls exist (e.g., if something went wrong in the previous node), it returns <code>\"format_output\"</code>, skipping the tool execution step and going directly to formatting the final output (which will likely use placeholders).</li>\n",
        "      </ul>\n",
        "    </li>\n",
        "  </ul>\n",
        "</div>"
      ],
      "metadata": {
        "id": "SeFSgNDqrLZB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check_preferences_complete(state: SuggestionState) -> Literal[\"ask_question\", \"generate_recommendations\", END]:\n",
        "    \"\"\"\n",
        "    Checks if all required preferences are collected or if the user quit.\n",
        "    Routes to 'generate_recommendations' if complete, 'ask_question' if not, or END if user quit.\n",
        "    \"\"\"\n",
        "    if state.get('is_finished'):\n",
        "        return END\n",
        "\n",
        "    required_preferences = ['vibe', 'activities', 'weather', 'budget']\n",
        "    collected_prefs = state.get('user_preferences', {}).keys()\n",
        "\n",
        "    if all(pref in collected_prefs for pref in required_preferences):\n",
        "        return \"generate_recommendations\"\n",
        "    else:\n",
        "        missing = [p for p in required_preferences if p not in collected_prefs]\n",
        "        return \"ask_question\"\n",
        "\n",
        "\n",
        "def route_after_tool_trigger(state: SuggestionState) -> Literal[\"image_tool_executor\", \"format_output\"]:\n",
        "    \"\"\"\n",
        "    Checks the last message for tool calls.\n",
        "    Routes to 'image_tool_executor' if calls exist, otherwise skips to 'format_output'.\n",
        "    \"\"\"\n",
        "    last_message = state[\"messages\"][-1]\n",
        "\n",
        "    if hasattr(last_message, \"tool_calls\") and last_message.tool_calls:\n",
        "        return \"image_tool_executor\"\n",
        "    else:\n",
        "        return \"format_output\"\n",
        "\n",
        "print(\"Conditional routing functions ('check_preferences_complete', 'route_after_tool_trigger') defined.\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "gRnlq76lrLZB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color:#EFF6FF; padding:15px; border-radius:8px; margin-top:20px; border:1px dashed #3B82F6;\">\n",
        "  <h2 style=\"color:#1E40AF; border-bottom: 2px solid #2563EB; padding-bottom: 5px;\">Step 15: Build and Compile the Suggestion Agent Graph (Phase 1)</h2>\n",
        "  <p style=\"color:gray; margin-top:10px;\">\n",
        "    Now we assemble the components defined in the previous steps into a coherent conversational workflow using LangGraph. This graph defines the structure and logic for Phase 1: gathering preferences and presenting initial recommendations.\n",
        "  </p>\n",
        "  <ol style=\"background-color:#DBEAFE; padding:10px 10px 10px 30px; border-radius:6px; border:1px solid #BFDBFE; margin-top:10px; list-style-type: decimal;\">\n",
        "    <li style=\"color:#1E3A8A; margin-bottom:8px;\">\n",
        "      <strong>Instantiate Graph Builder:</strong> Creates an instance of <code>StateGraph</code>, associating it with the <code>SuggestionState</code> TypedDict defined earlier. This tells LangGraph the structure of the state that will be passed between nodes.\n",
        "    </li>\n",
        "    <li style=\"color:#1E3A8A; margin-bottom:8px;\">\n",
        "      <strong>Add Nodes:</strong> Each previously defined function representing a step in the conversation (<code>ask_question_node</code>, <code>human_input_node</code>, <code>parse_preference_node</code>, <code>generate_recommendations_node</code>, <code>verify_recommendations_node</code>, <code>call_image_tool_node</code>, <code>format_final_output_node</code>, <code>get_selection_node</code>) is registered as a node in the graph using <code>graph_builder.add_node()</code>.\n",
        "    </li>\n",
        "     <li style=\"color:#1E3A8A; margin-bottom:8px;\">\n",
        "      <strong>Add Tool Executor Node:</strong> A special <code>ToolNode</code> is added, configured with the <code>suggestion_tools</code> list (containing the <code>unsplash_get_image</code> tool). This node is responsible for actually executing the tool calls prepared by <code>call_image_tool_node</code>.\n",
        "    </li>\n",
        "    <li style=\"color:#1E3A8A; margin-bottom:8px;\">\n",
        "      <strong>Set Entry Point:</strong> Defines <code>\"ask_question\"</code> as the starting node for any new conversation using <code>graph_builder.set_entry_point()</code>.\n",
        "    </li>\n",
        "    <li style=\"color:#1E3A8A; margin-bottom:8px;\">\n",
        "      <strong>Define Edges (Transitions):</strong> Connects the nodes to define the flow:\n",
        "        <ul>\n",
        "            <li>Sets up the main preference gathering loop: <code>ask_question</code> -> <code>get_user_input</code> -> <code>parse_preference</code>.</li>\n",
        "            <li>Uses <code>add_conditional_edges</code> after <code>parse_preference</code>, linking it to the <code>check_preferences_complete</code> function. Based on the function's return value, the graph transitions back to <code>ask_question</code> (loop), proceeds to <code>generate_recommendations</code> (complete), or goes to <code>END</code> (quit).</li>\n",
        "            <li>Defines the recommendation processing flow: <code>generate_recommendations</code> -> <code>verify_recommendations</code> -> <code>call_image_tool</code>.</li>\n",
        "            <li>Uses <code>add_conditional_edges</code> after <code>call_image_tool</code>, linking it to <code>route_after_tool_trigger</code>. Based on whether tool calls were generated, it routes to <code>image_tool_executor</code> or directly to <code>format_output</code>.</li>\n",
        "            <li>Connects the tool executor back to the output formatter: <code>image_tool_executor</code> -> <code>format_output</code>.</li>\n",
        "            <li>Connects the output formatter to the user selection step: <code>format_output</code> -> <code>get_selection</code>.</li>\n",
        "            <li>Defines the final transition from user selection to the end of the Phase 1 graph: <code>get_selection</code> -> <code>END</code>.</li>\n",
        "        </ul>\n",
        "    </li>\n",
        "     <li style=\"color:#1E3A8A; margin-bottom:8px;\">\n",
        "      <strong>Compile Graph:</strong> Calls <code>graph_builder.compile()</code> to finalize the graph structure, creating an executable LangGraph object (<code>final_suggestion_graph</code>).\n",
        "    </li>\n",
        "     <li style=\"color:#1E3A8A;\">\n",
        "      <strong>Visualize Graph:</strong> Attempts to generate and display a visual representation of the compiled graph topology using <code>.draw_mermaid_png()</code>. This requires `playwright` to be installed in the environment. Includes error handling if visualization fails.\n",
        "    </li>\n",
        "  </ul>\n",
        "  <p style=\"color:gray; margin-top:10px; font-style: italic;\">\n",
        "    This compiled graph encapsulates the entire logic for the suggestion phase, ready to be invoked with an initial state to start the conversation.\n",
        "  </p>\n",
        "</div>"
      ],
      "metadata": {
        "id": "lIPXcW5frLZB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "graph_builder = StateGraph(SuggestionState)\n",
        "\n",
        "graph_builder.add_node(\"ask_question\", ask_question_node)\n",
        "graph_builder.add_node(\"get_user_input\", human_input_node)\n",
        "graph_builder.add_node(\"parse_preference\", parse_preference_node)\n",
        "graph_builder.add_node(\"generate_recommendations\", generate_recommendations_node)\n",
        "graph_builder.add_node(\"verify_recommendations\", verify_recommendations_node)\n",
        "graph_builder.add_node(\"call_image_tool\", call_image_tool_node)\n",
        "graph_builder.add_node(\"image_tool_executor\", ToolNode(suggestion_tools))\n",
        "graph_builder.add_node(\"format_output\", format_final_output_node)\n",
        "graph_builder.add_node(\"get_selection\", get_selection_node)\n",
        "\n",
        "graph_builder.set_entry_point(\"ask_question\")\n",
        "\n",
        "graph_builder.add_edge(\"ask_question\", \"get_user_input\")\n",
        "graph_builder.add_edge(\"get_user_input\", \"parse_preference\")\n",
        "graph_builder.add_conditional_edges(\n",
        "    \"parse_preference\",\n",
        "    check_preferences_complete,\n",
        "    {\"ask_question\": \"ask_question\", \"generate_recommendations\": \"generate_recommendations\", END: END}\n",
        ")\n",
        "\n",
        "graph_builder.add_edge(\"generate_recommendations\", \"verify_recommendations\")\n",
        "graph_builder.add_edge(\"verify_recommendations\", \"call_image_tool\")\n",
        "graph_builder.add_conditional_edges(\n",
        "    \"call_image_tool\",\n",
        "    route_after_tool_trigger,\n",
        "    {\"image_tool_executor\": \"image_tool_executor\", \"format_output\": \"format_output\"}\n",
        ")\n",
        "graph_builder.add_edge(\"image_tool_executor\", \"format_output\")\n",
        "\n",
        "\n",
        "graph_builder.add_edge(\"format_output\", \"get_selection\")\n",
        "\n",
        "graph_builder.add_edge(\"get_selection\", END)\n",
        "\n",
        "final_suggestion_graph = graph_builder.compile()\n",
        "print(\"‚úÖ Suggestion agent graph with integrated selection node compiled successfully.\")\n",
        "\n",
        "try:\n",
        "    graph_image_bytes = final_suggestion_graph.get_graph().draw_mermaid_png()\n",
        "    if graph_image_bytes:\n",
        "        display(Image(graph_image_bytes))\n",
        "    else:\n",
        "        print(\"Graph visualization did not produce an image.\")\n",
        "except Exception as e:\n",
        "    print(f\"\\n‚ÑπÔ∏è Graph visualization failed. Ensure playwright is installed. Error: {e}\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "aARn9SfPrLZB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color:#FFFBEB; padding:15px; border-radius:8px; margin-top:20px; border:1px dashed #F59E0B;\">\n",
        "  <h2 style=\"color:#B45309; border-bottom: 2px solid #D97706; padding-bottom: 5px;\">Step 16: Run the Suggestion Agent Graph (Phase 1)</h2>\n",
        "  <p style=\"color:gray; margin-top:10px;\">\n",
        "    With the Phase 1 graph compiled, this cell executes the conversational flow for gathering preferences and providing recommendations. The behavior (interactive vs. demo) depends on the <code>INTERACTIVE_MODE</code> flag set in Step 2 and implemented within the graph's nodes (Steps 8 & 13).\n",
        "  </p>\n",
        "  <ol style=\"background-color:#FEFCE8; padding:10px 10px 10px 30px; border-radius:6px; border:1px solid #FEF9C3; margin-top:10px; list-style-type: decimal;\">\n",
        "    <li style=\"color:#713F12; margin-bottom:8px;\">\n",
        "      <strong>Prerequisite Check:</strong> Verifies that the <code>final_suggestion_graph</code> object exists and is compiled.\n",
        "    </li>\n",
        "    <li style=\"color:#713F12; margin-bottom:8px;\">\n",
        "      <strong>User Instructions:</strong> Prints messages explaining the upcoming interaction (primarily relevant in interactive mode).\n",
        "    </li>\n",
        "    <li style=\"color:#713F12; margin-bottom:8px;\">\n",
        "      <strong>Initial State Definition:</strong> Creates the starting <code>initial_state</code> dictionary for the graph, conforming to the <code>SuggestionState</code> TypedDict. It includes a starting human message to kick off the conversation.\n",
        "    </li>\n",
        "     <li style=\"color:#713F12; margin-bottom:8px;\">\n",
        "      <strong>Configuration:</strong> Sets a <code>recursion_limit</code> to prevent infinite loops in the graph execution.\n",
        "    </li>\n",
        "     <li style=\"color:#713F12; margin-bottom:8px;\">\n",
        "      <strong>Invoke Graph:</strong> Calls <code>final_suggestion_graph.invoke(initial_state, config=config)</code>. This starts the execution at the entry point (\"ask_question\") and runs through the nodes and edges defined previously until an <code>END</code> state is reached (either by user quitting/selecting or an error). <strong>This is where the actual conversation/demo run occurs.</strong>\n",
        "    </li>\n",
        "     <li style=\"color:#713F12; margin-bottom:8px;\">\n",
        "      <strong>Error Handling:</strong> Wraps the invocation in a <code>try...except</code> block to catch potential errors during graph execution, including <code>GraphRecursionError</code> if the step limit is exceeded.\n",
        "    </li>\n",
        "     <li style=\"color:#713F12; margin-bottom:8px;\">\n",
        "      <strong>Final State Summary:</strong> After the graph finishes, it prints a summary of the returned <code>final_state</code>, including:\n",
        "        <ul>\n",
        "            <li>Whether the graph finished naturally (<code>is_finished</code>).</li>\n",
        "            <li>Any captured error messages.</li>\n",
        "            <li>The final dictionary of collected <code>user_preferences</code>.</li>\n",
        "            <li>Whether a city was selected for Phase 2 (<code>selected_city_for_phase_2</code>).</li>\n",
        "            <li>A summary of the final recommendations generated.</li>\n",
        "            <li>A snippet of the last few messages exchanged.</li>\n",
        "        </ul>\n",
        "    </li>\n",
        "     <li style=\"color:#713F12;\">\n",
        "      <strong>Prepare for Phase 2:</strong> Extracts the value of <code>selected_city_for_phase_2</code> from the final state into a variable. Prints a message indicating whether the agent is ready to proceed to Phase 2 based on whether a city was successfully selected.\n",
        "    </li>\n",
        "  </ol>\n",
        "  <p style=\"color:gray; margin-top:10px; font-style: italic;\">\n",
        "   Executing this cell runs the entire Phase 1 process. The output will show the agent's questions, simulated or real user inputs, the final recommendations (including images), and the outcome of the user's selection (or automatic selection in demo mode). The <code>selected_city_for_phase_2</code> variable carries the essential information needed to potentially start Phase 2.\n",
        "  </p>\n",
        "</div>"
      ],
      "metadata": {
        "id": "x0RbzomlrLZC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if 'final_suggestion_graph' not in globals() or final_suggestion_graph is None:\n",
        "    print(\"ERROR: The 'final_suggestion_graph' is not compiled. Please run the graph definition cell.\")\n",
        "else:\n",
        "    print(\"\\n--- Starting Travel Suggestion Agent (Structured Flow) ---\")\n",
        "    print(\"I will ask you about your preferences (vibe, activities, weather, budget).\")\n",
        "    print(\"Recommendations will be shown, and you will be prompted to select one.\")\n",
        "    print(\"Type 'q', 'quit', or 'exit' anytime to end.\")\n",
        "\n",
        "    # --- RESET DEMO INDEX BEFORE EACH RUN ---\n",
        "    if not INTERACTIVE_MODE:\n",
        "        global demo_answer_index # Declare intention to modify the global variable\n",
        "        demo_answer_index = 0\n",
        "        print(\"üîÑ Demo answer index reset to 0 for new run.\")\n",
        "    # --- END RESET ---\n",
        "\n",
        "    # Initial state\n",
        "    initial_state = SuggestionState(\n",
        "        messages=[HumanMessage(content=\"Hi, I'd like to plan a trip.\")],\n",
        "        user_preferences={},\n",
        "        text_recommendations=None,\n",
        "        recommendations=[],\n",
        "        cities_with_data=[],\n",
        "        error_message=None,\n",
        "        is_finished=False,\n",
        "        selected_city_for_phase_2=None\n",
        "    )\n",
        "\n",
        "    config = {\"recursion_limit\": 150}\n",
        "    final_state = None\n",
        "\n",
        "    try:\n",
        "        # --- Graph Invocation ---\n",
        "        final_state = final_suggestion_graph.invoke(initial_state, config=config)\n",
        "        # --- End Invocation ---\n",
        "\n",
        "        print(\"\\n--- Graph Execution Complete ---\")\n",
        "\n",
        "        if final_state:\n",
        "             print(\"\\nFinal State Summary:\")\n",
        "             print(f\"  - Finished: {final_state.get('is_finished')}\")\n",
        "             print(f\"  - Error Message: {final_state.get('error_message')}\")\n",
        "             print(f\"  - Collected Preferences: {final_state.get('user_preferences')}\")\n",
        "\n",
        "             # Explicitly show the selection made\n",
        "             selected_city = final_state.get('selected_city_for_phase_2')\n",
        "             if selected_city:\n",
        "                  print(f\"  >>> User Selected City for Phase 2: {selected_city} <<<\")\n",
        "             else:\n",
        "                  print(\"  >>> User did not select a city (chose quit/refine or error occurred). <<<\")\n",
        "\n",
        "             final_recs = final_state.get('recommendations')\n",
        "             if final_recs:\n",
        "                  print(f\"  - Displayed {len(final_recs)} Recommendations (check output above).\")\n",
        "             else:\n",
        "                  print(\"  - No recommendations generated or stored.\")\n",
        "\n",
        "             final_messages = final_state.get('messages', [])\n",
        "             if final_messages:\n",
        "                 print(\"\\nLast few messages in history:\")\n",
        "                 for msg in final_messages[-5:]:\n",
        "                      if isinstance(msg, AIMessage): print(f\"  ü§ñ Nomad: {msg.content} {f'(Tool Calls: {msg.tool_calls})' if msg.tool_calls else ''}\")\n",
        "                      elif isinstance(msg, HumanMessage): print(f\"  üë§ You: {msg.content}\")\n",
        "                      elif isinstance(msg, ToolMessage): print(f\"  üõ†Ô∏è Tool Result ({msg.name}): {msg.content}\")\n",
        "                      else: print(f\"  System/Other: {type(msg)}\")\n",
        "        else:\n",
        "             print(\"Graph execution did not return a final state.\")\n",
        "\n",
        "    except GraphRecursionError:\n",
        "         print(\"\\n--- ERROR: Conversation ended due to reaching recursion limit ---\")\n",
        "         print(f\"The graph exceeded the maximum number of steps ({config['recursion_limit']}).\")\n",
        "         print(\"This might happen in very long conversations or if there's an unexpected loop.\")\n",
        "    except Exception as e:\n",
        "        import traceback\n",
        "        print(f\"\\n--- An unexpected error occurred during graph execution: {type(e).__name__} ---\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "    selected_city_for_phase_2 = None\n",
        "    if final_state and final_state.get('selected_city_for_phase_2'):\n",
        "        selected_city_for_phase_2 = final_state['selected_city_for_phase_2']\n",
        "        print(f\"\\n\\n‚û°Ô∏è Ready to proceed to Phase 2 with city: {selected_city_for_phase_2}\")\n",
        "    else:\n",
        "        print(\"\\n\\n‚èπÔ∏è Phase 1 ended without a city selection for Phase 2.\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "ZNA14Ef8rLZC"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color:#EFF6FF; padding:15px; border-radius:8px; margin-top:20px; border:1px dashed #3B82F6;\">\n",
        "  <h2 style=\"color:#1E40AF; border-bottom: 2px solid #2563EB; padding-bottom: 5px;\">Step 17: Define Weather Fetching Tool (OpenWeatherMap)</h2>\n",
        "  <p style=\"color:gray; margin-top:10px;\">\n",
        "    To provide current conditions for the user's selected city in Phase 2, we define a tool to fetch live weather data. This uses the OpenWeatherMap API and includes a robust fallback mechanism.\n",
        "  </p>\n",
        "  <ul style=\"background-color:#DBEAFE; padding:10px 10px 10px 30px; border-radius:6px; border:1px solid #BFDBFE; margin-top:10px; list-style-type: square;\">\n",
        "    <li style=\"color:#1E3A8A; margin-bottom:8px;\">\n",
        "      <strong>Placeholder Function (<code>get_placeholder_weather</code>):</strong>\n",
        "        <ul>\n",
        "            <li>Defines a helper function that generates randomized, clearly marked placeholder weather data (temperature, condition, humidity).</li>\n",
        "            <li>This function is called by the main tool if the API key is missing or if any error occurs during the live API call, ensuring the agent can always provide some weather-related information.</li>\n",
        "        </ul>\n",
        "    </li>\n",
        "    <li style=\"color:#1E3A8A; margin-bottom:8px;\">\n",
        "      <strong>Weather Tool Function (<code>get_weather</code> @tool):</strong>\n",
        "        <ul>\n",
        "            <li>The main function, decorated with LangChain's <code>@tool</code> decorator, making it a callable tool within the LangChain ecosystem (even though it's called directly in the current Phase 2 implementation).</li>\n",
        "            <li>Accepts <code>city</code> and optional <code>country</code> arguments.</li>\n",
        "            <li>Retrieves the <code>OPENWEATHERMAP_API_KEY</code> from environment variables (set in Step 2).</li>\n",
        "            <li>If the key is missing, it prints a debug message and immediately returns data from <code>get_placeholder_weather</code>.</li>\n",
        "            <li>If the key exists, it constructs the API request URL for OpenWeatherMap's current weather endpoint, including the city/country query and metric units.</li>\n",
        "            <li>Uses the <code>requests</code> library to make the API call with a timeout.</li>\n",
        "            <li>Includes comprehensive error handling for timeouts, HTTP errors (like 404 Not Found, 401 Invalid Key), general request exceptions, and unexpected errors. In all error cases, it falls back to returning placeholder data.</li>\n",
        "            <li>If the API call is successful (HTTP 200) and returns valid data, it parses the JSON response, extracts relevant fields (location, temperature, condition, humidity, etc.), filters out any null values, and returns the weather information as a dictionary.</li>\n",
        "        </ul>\n",
        "    </li>\n",
        "     <li style=\"color:#1E3A8A;\">\n",
        "      <strong>Tool List for Phase 2 (<code>phase2_tools</code>):</strong>\n",
        "        <ul>\n",
        "            <li>The <code>get_weather</code> tool is added to a list named <code>phase2_tools</code>. While the current Phase 2 implementation calls this tool directly via Python code rather than through LLM-triggered function calling, this list structure is maintained, potentially for future flexibility or reflecting an earlier design iteration.</li>\n",
        "        </ul>\n",
        "    </li>\n",
        "  </ul>\n",
        "</div>"
      ],
      "metadata": {
        "id": "tjjCXXberLZC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_placeholder_weather(city: str, country: Optional[str] = \"Unknown\") -> Dict[str, Any]:\n",
        "     \"\"\"Generates random placeholder weather data.\"\"\"\n",
        "     return {\n",
        "        \"location\": f\"{city}, {country or 'Unknown'} (Placeholder)\",\n",
        "        \"temperature_celsius\": round(random.uniform(5, 30), 1),\n",
        "        \"condition\": random.choice([\"Sunny\", \"Partly Cloudy\", \"Cloudy\", \"Light Rain\", \"Clear Sky\"]),\n",
        "        \"humidity_percent\": random.randint(30, 85),\n",
        "        \"comment\": \"Weather data is placeholder.\",\n",
        "        \"fetched_at\": datetime.datetime.now().isoformat()\n",
        "    }\n",
        "\n",
        "@tool\n",
        "def get_weather(city: str, country: Optional[str] = None) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Fetches the current weather for a given city using the OpenWeatherMap API.\n",
        "    Country is optional but helps accuracy. Returns placeholder data if API key is missing or call fails.\n",
        "    Example: get_weather(city='London', country='UK')\n",
        "    \"\"\"\n",
        "    api_key = os.environ.get(\"OPENWEATHERMAP_API_KEY\")\n",
        "\n",
        "    # print(f\"\\n--- DEBUG: get_weather called with city='{city}', country='{country}' ---\")\n",
        "\n",
        "    if not api_key:\n",
        "        print(\"DEBUG: OpenWeatherMap API Key not found in environment. Returning placeholder.\")\n",
        "        return get_placeholder_weather(city, country)\n",
        "\n",
        "    try:\n",
        "        base_url = \"http://api.openweathermap.org/data/2.5/weather?\"\n",
        "        query_param = city\n",
        "        if country:\n",
        "             query_param += f\",{country}\"\n",
        "\n",
        "        complete_url = f\"{base_url}appid={api_key}&q={query_param}&units=metric\"\n",
        "\n",
        "        response = requests.get(complete_url, timeout=10)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "\n",
        "        if data.get(\"cod\") == 200:\n",
        "            main = data.get(\"main\", {})\n",
        "            weather_desc = data.get(\"weather\", [{}])[0].get(\"description\", \"N/A\")\n",
        "            weather_info = {\n",
        "                \"location\": f\"{data.get('name', city)}, {data.get('sys', {}).get('country', country or 'N/A')}\",\n",
        "                \"temperature_celsius\": main.get(\"temp\"),\n",
        "                \"feels_like_celsius\": main.get(\"feels_like\"),\n",
        "                \"humidity_percent\": main.get(\"humidity\"),\n",
        "                \"condition\": weather_desc.capitalize(),\n",
        "                \"wind_speed_mps\": data.get(\"wind\", {}).get(\"speed\"),\n",
        "                \"fetched_at\": datetime.datetime.now().isoformat()\n",
        "            }\n",
        "            weather_info_filtered = {k: v for k, v in weather_info.items() if v is not None}\n",
        "            return weather_info_filtered\n",
        "        else:\n",
        "            error_message = data.get(\"message\", \"Unknown API error\")\n",
        "            return get_placeholder_weather(city, country)\n",
        "\n",
        "    except requests.exceptions.Timeout:\n",
        "         print(f\"DEBUG: Timeout connecting to OpenWeatherMap for '{query_param}'. Returning placeholder.\")\n",
        "         return get_placeholder_weather(city, country)\n",
        "    except requests.exceptions.HTTPError as http_err:\n",
        "         print(f\"DEBUG: HTTP error during OpenWeatherMap call for '{query_param}': {http_err}. Returning placeholder.\")\n",
        "         return get_placeholder_weather(city, country)\n",
        "    except requests.exceptions.RequestException as req_err:\n",
        "        print(f\"DEBUG: Network error during OpenWeatherMap call for '{query_param}': {req_err}. Returning placeholder.\")\n",
        "        return get_placeholder_weather(city, country)\n",
        "    except Exception as e:\n",
        "        import traceback\n",
        "        print(f\"DEBUG: Unexpected error fetching weather for '{query_param}': {e}.\")\n",
        "        traceback.print_exc()\n",
        "        return get_placeholder_weather(city, country)\n",
        "\n",
        "phase2_tools = [get_weather]\n",
        "print(f\"Weather tool '{get_weather.name}' defined and ready for Phase 2.\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "RTmt4gOSrLZC"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color:#F0FDF4; padding:15px; border-radius:8px; margin-top:20px; border:1px dashed #22C55E;\">\n",
        "  <h2 style=\"color:#15803D; border-bottom: 2px solid #16A34A; padding-bottom: 5px;\">Step 18: Define RAG Document Retrieval Function</h2>\n",
        "  <p style=\"color:gray; margin-top:10px;\">\n",
        "    This function encapsulates the core logic for the Retrieval-Augmented Generation (RAG) process. It takes a city name and user preferences and retrieves the most relevant Point of Interest (POI) documents from the ChromaDB vector store prepared earlier.\n",
        "  </p>\n",
        "  <ul style=\"background-color:#ECFDF5; padding:10px 10px 10px 30px; border-radius:6px; border:1px solid #D1FAE5; margin-top:10px; list-style-type: square;\">\n",
        "    <li style=\"color:#065F46; margin-bottom:8px;\">\n",
        "      <strong>Function Signature:</strong> Accepts the target <code>city</code>, a dictionary of <code>preferences</code> (which can also contain the user's question during Q&A), the ChromaDB <code>collection</code> object, the query <code>embedder</code> function instance, and the desired number of results (<code>n_results</code>).\n",
        "    </li>\n",
        "    <li style=\"color:#065F46; margin-bottom:8px;\">\n",
        "      <strong>Input Validation:</strong> Performs initial checks to ensure the embedder, collection, city, and preferences are provided and valid, returning an empty list if not.\n",
        "    </li>\n",
        "     <li style=\"color:#065F46; margin-bottom:8px;\">\n",
        "        <strong>Query Construction:</strong> Creates a natural language query string (<code>query_text</code>) combining the city and the user's preferences/question (e.g., \"Points of interest in Marrakech suitable for someone interested in [vibe: relaxing, activities: spa]\").\n",
        "    </li>\n",
        "    <li style=\"color:#065F46; margin-bottom:8px;\">\n",
        "      <strong>Query Embedding:</strong>\n",
        "        <ul>\n",
        "            <li>Calls the provided <code>embedder</code> function (the <code>GeminiEmbeddingFunctionChroma</code> instance with <code>task_type=\"retrieval_query\"</code>) to convert the <code>query_text</code> into a vector embedding using the Gemini API.</li>\n",
        "            <li>Includes checks to ensure the embedder returns a valid list containing a non-empty embedding vector.</li>\n",
        "             <li>Handles potential NumPy array format from some embedders by converting to a standard list of floats.</li>\n",
        "        </ul>\n",
        "    </li>\n",
        "     <li style=\"color:#065F46; margin-bottom:8px;\">\n",
        "      <strong>ChromaDB Query:</strong>\n",
        "        <ul>\n",
        "            <li>Calls the <code>collection.query()</code> method of the ChromaDB collection object.</li>\n",
        "            <li>Passes the generated <code>query_vector</code> to find documents with similar embeddings.</li>\n",
        "            <li>Specifies <code>n_results</code> to limit the number of documents returned.</li>\n",
        "            <li>Crucially, uses a <code>where={\"city\": city}</code> filter. This ensures that the similarity search is restricted *only* to documents belonging to the specified city, preventing irrelevant results from other locations even if their descriptions are similar.</li>\n",
        "        </ul>\n",
        "    </li>\n",
        "      <li style=\"color:#065F46; margin-bottom:8px;\">\n",
        "      <strong>Result Extraction:</strong> Extracts the actual document text content from the <code>'documents'</code> field of the ChromaDB query response.\n",
        "    </li>\n",
        "     <li style=\"color:#065F46;\">\n",
        "      <strong>Error Handling:</strong> Wraps the embedding and query process in a <code>try...except</code> block to catch potential errors during API calls or database interaction, returning an empty list upon failure.\n",
        "    </li>\n",
        "  </ul>\n",
        "  <p style=\"color:gray; margin-top:10px; font-style: italic;\">\n",
        "    This function is called during Phase 2 to fetch relevant POI context before generating the detailed city description, and again during the Q&A loop to find context relevant to the user's specific questions. The quality of the RAG results heavily depends on the effectiveness of the query embedding and the content of the indexed documents.\n",
        "  </p>\n",
        "</div>"
      ],
      "metadata": {
        "id": "FeGLArF9rLZC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_rag_documents(\n",
        "    city: str,\n",
        "    preferences: Dict[str, Any],\n",
        "    collection: Optional[chromadb.Collection],\n",
        "    embedder: Optional[EmbeddingFunction],\n",
        "    n_results: int = 5\n",
        ") -> List[str]:\n",
        "    \"\"\"\n",
        "    Retrieves relevant POI documents from the ChromaDB collection based on city and preferences.\n",
        "    Handles potential numpy array embeddings and provides more robust checks.\n",
        "    \"\"\"\n",
        "\n",
        "    if embedder is None:\n",
        "        print(\"RAG Error: Query embedding function (embedder) is not available.\")\n",
        "        return []\n",
        "    if collection is None:\n",
        "        print(\"RAG Error: ChromaDB collection is not available.\")\n",
        "        return []\n",
        "    if not city or not isinstance(city, str):\n",
        "        print(f\"RAG Error: Invalid city provided: {city}\")\n",
        "        return []\n",
        "    if not preferences or not isinstance(preferences, dict):\n",
        "         print(f\"RAG Error: Invalid preferences provided: {preferences}\")\n",
        "         return []\n",
        "\n",
        "    pref_list = [f\"{k}: {v}\" for k, v in preferences.items() if v]\n",
        "    pref_string = \", \".join(pref_list)\n",
        "    query_text = f\"Points of interest in {city} suitable for someone interested in [{pref_string}]\"\n",
        "\n",
        "    try:\n",
        "        query_embedding_list = embedder([query_text])\n",
        "        if not isinstance(query_embedding_list, list) or len(query_embedding_list) < 1:\n",
        "            print(f\"RAG Error: Embedder returned invalid result type or empty list. Result: {query_embedding_list}\")\n",
        "            return []\n",
        "\n",
        "        query_vector_obj = query_embedding_list[0]\n",
        "        if not hasattr(query_vector_obj, '__len__') or len(query_vector_obj) == 0:\n",
        "             print(f\"RAG Error: Extracted embedding vector is invalid or empty. Vector Type: {type(query_vector_obj)}. Vector: {query_vector_obj}\")\n",
        "             return []\n",
        "\n",
        "        if isinstance(query_vector_obj, np.ndarray):\n",
        "            query_vector = [float(x) for x in query_vector_obj]\n",
        "        else:\n",
        "            query_vector = [float(x) for x in query_vector_obj]\n",
        "\n",
        "        results = collection.query(\n",
        "            query_embeddings=[query_vector],\n",
        "            n_results=n_results,\n",
        "            where={\"city\": city},\n",
        "        )\n",
        "\n",
        "        retrieved_docs = []\n",
        "        if results and isinstance(results.get('documents'), list) and len(results['documents']) > 0:\n",
        "            retrieved_docs = results['documents'][0]\n",
        "\n",
        "        return retrieved_docs\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during RAG retrieval or embedding check: {e}\")\n",
        "        traceback.print_exc()\n",
        "        return []\n",
        "\n",
        "print(\"Function 'retrieve_rag_documents' defined.\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "kC9wU2MUrLZF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color:#F0FDF4; padding:15px; border-radius:8px; margin-top:20px; border:1px dashed #22C55E;\">\n",
        "  <h2 style=\"color:#15803D; border-bottom: 2px solid #16A34A; padding-bottom: 5px;\">Step 19: Define Phase 2 LLM, Data Structures & Config</h2>\n",
        "  <p style=\"color:gray; margin-top:10px;\">\n",
        "    This cell sets up the core configurations for Phase 2, where the agent provides detailed city information. It defines the specific Gemini model, the Pydantic data structures for the output, and the Grounding tool configuration for the Phase 2 LLM.\n",
        "  </p>\n",
        "  <ul style=\"background-color:#ECFDF5; padding:10px 10px 10px 30px; border-radius:6px; border:1px solid #D1FAE5; margin-top:10px; list-style-type: square;\">\n",
        "    <li style=\"color:#065F46; margin-bottom:8px;\">\n",
        "      <strong>Phase 2 Model Name:</strong> Sets the <code>PHASE2_MODEL_NAME</code> variable, specifying the LLM to be used for generating the detailed city overview.\n",
        "    </li>\n",
        "    <li style=\"color:#065F46; margin-bottom:8px;\">\n",
        "      <strong>Phase 2 Data Models (Pydantic):</strong> Defines the schemas for the structured output:\n",
        "        <ul>\n",
        "            <li><code>PointOfInterest</code>: Structure for POIs (description generated via RAG context).</li>\n",
        "            <li><code>CityEvent</code>: Structure for events (found via Grounding).</li>\n",
        "            <li><code>CityInformation</code>: The main model aggregating city info, POIs, events, and a weather placeholder.</li>\n",
        "        </ul>\n",
        "    </li>\n",
        "     <li style=\"color:#065F46; margin-bottom:8px;\">\n",
        "        <strong>Configure Grounding Tool (Google Search):</strong>\n",
        "        <ul>\n",
        "            <li>Creates the <code>search_tool</code> and adds it to the <code>phase2_tools_genai</code> list. This enables the Phase 2 LLM to use Google Search internally for event discovery.</li>\n",
        "        </ul>\n",
        "    </li>\n",
        "    <li style=\"color:#065F46;\">\n",
        "      <strong>Define Target Output Schema:</strong>\n",
        "        <ul>\n",
        "            <li>Generates the <code>phase2_output_schema</code> JSON string from the <code>CityInformation</code> model. This schema instructs the LLM on the desired output format (excluding weather). Includes error handling.</li>\n",
        "        </ul>\n",
        "    </li>\n",
        "  </ul>\n",
        "  <p style=\"color:gray; margin-top:10px; font-style: italic;\">\n",
        "    With the model, output structures, and Grounding tool configured, the next step is to define the system prompt that will guide this Phase 2 LLM.\n",
        "  </p>\n",
        "</div>"
      ],
      "metadata": {
        "id": "LiyiSDWLrLZF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PHASE2_MODEL_NAME = \"gemini-2.0-flash\"\n",
        "print(f\"Phase 2 Model Name set to: {PHASE2_MODEL_NAME}\")\n",
        "\n",
        "class PointOfInterest(BaseModel):\n",
        "    name: str = Field(description=\"Name of the Point of Interest.\")\n",
        "    type: str = Field(description=\"Category or type of the POI (e.g., Museum, Park, Restaurant, Temple, Market).\")\n",
        "    description: str = Field(description=\"A brief (1-2 sentence) description of the POI, highlighting its relevance to user preferences based on provided context.\")\n",
        "\n",
        "class CityEvent(BaseModel):\n",
        "    name: str = Field(description=\"Name of the event.\")\n",
        "    summary: str = Field(description=\"A short (1 sentence) summary of the event.\")\n",
        "\n",
        "class CityInformation(BaseModel):\n",
        "    city_name: str = Field(description=\"The name of the selected city.\")\n",
        "    country_name: str = Field(description=\"The name of the country.\")\n",
        "    general_summary: str = Field(description=\"A general introductory paragraph (2-4 sentences) about the city, tailored to the user's vibe/preferences.\")\n",
        "    weather_summary: str = Field(description=\"A concise summary (1-2 sentences) of the current weather. This will be added *after* the LLM call.\")\n",
        "    points_of_interest: List[PointOfInterest] = Field(description=\"A list of 3-5 relevant Points of Interest based on RAG context and user preferences.\")\n",
        "    events: List[CityEvent] = Field(description=\"A list of 2-4 current or upcoming events found via grounding.\")\n",
        "\n",
        "search_tool = genai_types.Tool(google_search=genai_types.GoogleSearch())\n",
        "phase2_tools_genai = [search_tool]\n",
        "print(f\"Defined google.genai tools for Phase 2: Grounding ONLY\")\n",
        "\n",
        "phase2_output_schema = None\n",
        "try:\n",
        "    if 'CityInformation' not in globals(): raise NameError(\"CityInformation Pydantic model not defined.\")\n",
        "    print(f\"Phase 2 LLM will be prompted to output JSON conforming to '{CityInformation.__name__}' schema (excluding weather initially).\")\n",
        "    phase2_output_schema = CityInformation.schema_json(indent=2)\n",
        "except NameError as ne:\n",
        "     print(f\"ERROR: Cannot prepare output schema - {ne}. Structured output may fail.\")\n",
        "except Exception as e:\n",
        "     print(f\"ERROR preparing output schema: {e}\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "MINeYX77rLZF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color:#EFF6FF; padding:15px; border-radius:8px; margin-top:20px; border:1px dashed #3B82F6;\">\n",
        "  <h2 style=\"color:#1E40AF; border-bottom: 2px solid #2563EB; padding-bottom: 5px;\">Step 20: Define Phase 2 System Prompt</h2>\n",
        "  <p style=\"color:gray; margin-top:10px;\">\n",
        "    This cell constructs the detailed system prompt that will guide the Gemini LLM during Phase 2 when it generates the structured city information. This prompt is critical for ensuring the LLM understands its role, inputs, tasks, and output requirements.\n",
        "  </p>\n",
        "  <ul style=\"background-color:#DBEAFE; padding:10px 10px 10px 30px; border-radius:6px; border:1px solid #BFDBFE; margin-top:10px; list-style-type: square;\">\n",
        "    <li style=\"color:#1E3A8A; margin-bottom:8px;\">\n",
        "      <strong>Prerequisite Check:</strong> Ensures the <code>phase2_output_schema</code> string (generated in the previous step) is available before constructing the prompt that embeds it.\n",
        "    </li>\n",
        "    <li style=\"color:#1E3A8A; margin-bottom:8px;\">\n",
        "      <strong>LLM Role & Goal:</strong> Clearly defines the LLM's persona (\"specialized travel information assistant\") and its objective (provide a detailed overview based on preferences, RAG, and grounding).\n",
        "    </li>\n",
        "     <li style=\"color:#1E3A8A; margin-bottom:8px;\">\n",
        "        <strong>Expected Inputs:</strong> Explicitly tells the LLM what information it will receive: selected city, user preferences summary, and the retrieved RAG context (POI data).\n",
        "    </li>\n",
        "     <li style=\"color:#1E3A8A; margin-bottom:8px;\">\n",
        "        <strong>Tasks Defined:</strong> Breaks down the LLM's responsibilities:\n",
        "        <ul>\n",
        "            <li>Use <strong>Grounding</strong> (Google Search) to find 2-4 notable current/upcoming events.</li>\n",
        "            <li>Analyze the provided <strong>RAG context</strong> to select 3-5 relevant POIs matching user preferences.</li>\n",
        "            <li>Synthesize this information into the specified JSON structure.</li>\n",
        "            <li>Explicitly instructs the LLM **not** to include weather information itself.</li>\n",
        "        </ul>\n",
        "    </li>\n",
        "    <li style=\"color:#1E3A8A; margin-bottom:8px;\">\n",
        "      <strong>Strict Output Requirements:</strong>\n",
        "        <ul>\n",
        "            <li>Emphasizes that the output MUST be **only** a single, valid JSON object conforming exactly to the provided schema.</li>\n",
        "            <li>Injects the <code>phase2_output_schema</code> string directly into the prompt so the LLM knows the target structure.</li>\n",
        "            <li>Provides field-level guidance (e.g., write a compelling summary, use RAG context for POI descriptions, use grounding for events, OMIT weather_summary).</li>\n",
        "        </ul>\n",
        "    </li>\n",
        "      <li style=\"color:#1E3A8A;\">\n",
        "      <strong>Example Thought Process:</strong> Includes a brief example to illustrate how the LLM should internally plan its actions (use grounding, select from RAG, construct JSON without weather).\n",
        "    </li>\n",
        "  </ul>\n",
        "</div>"
      ],
      "metadata": {
        "id": "zJhjZuaUrLZF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if 'phase2_output_schema' not in globals() or phase2_output_schema is None:\n",
        "    print(\"ERROR: 'phase2_output_schema' not found. Cannot define prompt correctly.\")\n",
        "    phase2_system_prompt = \"ERROR: Schema missing.\"\n",
        "else:\n",
        "    phase2_system_prompt = f\"\"\"You are a specialized travel information assistant. Your goal is to provide a detailed, helpful, and engaging overview of a selected city based on user preferences, retrieved local Points of Interest (POIs), and recent events found via grounding.\n",
        "\n",
        "**User Input:**\n",
        "You will receive:\n",
        "1. The selected city name.\n",
        "2. A summary of the user's preferences (vibe, activities, weather, budget).\n",
        "3. Context containing relevant Points of Interest (POIs) retrieved from a database for the selected city.\n",
        "\n",
        "**Your Tasks:**\n",
        "\n",
        "1.  **Events:** Use your grounding capabilities (Google Search) to find 2-4 relevant current or upcoming notable events (like festivals, major concerts, exhibitions, significant local happenings) in the `selected city`. Do NOT just list generic activities.\n",
        "2.  **RAG POI Selection:** Analyze the provided `Context POIs`. Select 3-5 diverse POIs that BEST match the user's `preferences`. Prioritize POIs mentioned in the context.\n",
        "3.  **Generate Content:** Synthesize the gathered information (preferences, RAG POIs, grounded events) into a structured JSON output. **DO NOT include weather information in your response.**\n",
        "\n",
        "**Output Requirements:**\n",
        "\n",
        "*   **Strict JSON:** You MUST output ONLY a single, valid JSON object conforming exactly to the following schema, **excluding the 'weather_summary' field**. Do NOT include any introductory text, explanations, apologies, or closing remarks outside the JSON structure.\n",
        "*   **Schema (Target Structure - You will omit weather_summary):**\n",
        "    ```json\n",
        "    {phase2_output_schema}\n",
        "    ```\n",
        "*   **Field Details:**\n",
        "    *   `city_name`, `country_name`: Fill accurately based on input.\n",
        "    *   `general_summary`: Write a compelling 2-4 sentence paragraph introducing the city, connecting it to the user's general `vibe` and `preferences`.\n",
        "    *   `weather_summary`: **<<< OMIT THIS FIELD FROM YOUR JSON OUTPUT >>>**\n",
        "    *   `points_of_interest`: Populate the list using the POIs you selected from the `RAG context` that match user `preferences`. Ensure the `name`, `type`, and `description` fields are filled based *only* on the provided RAG context. The description should briefly mention why it fits the preferences.\n",
        "    *   `events`: Populate the list using the current/upcoming events found via `grounding`. Provide a concise name and summary for each.\n",
        "\n",
        "**Example Internal Thought Process:**\n",
        "1. Receive Input: City=\"Paris\", Prefs={{'vibe':'romantic', 'activities':'museums', 'budget':'mid-range'}}, RAG Context=[POI data...].\n",
        "2. Tool Call Planning: Need to use grounding for events. *No weather tool call needed*.\n",
        "3. Generate Final Response (using Grounding internally for events): Construct the JSON output (WITHOUT weather_summary), selecting relevant museums from RAG context for the POI list, finding events like \"Louvre Late Nights\" via grounding for the events list, and writing the summary paragraphs.\n",
        "\"\"\"\n",
        "print(\"Phase 2 System Prompt updated.\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "R8l9AqVirLZF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color:#EFF6FF; padding:15px; border-radius:8px; margin-top:20px; border:1px dashed #3B82F6;\">\n",
        "  <h2 style=\"color:#1E40AF; border-bottom: 2px solid #2563EB; padding-bottom: 5px;\">Step 21: Define Phase 2 Orchestration Function</h2>\n",
        "  <p style=\"color:gray; margin-top:10px;\">\n",
        "    This function, <code>execute_phase2</code>, orchestrates the entire process of gathering and synthesizing detailed information for the user's selected city. It brings together RAG, external tool calls (weather), and a Grounding-enabled LLM call to generate the final structured output.\n",
        "  </p>\n",
        "  <ol style=\"background-color:#DBEAFE; padding:10px 10px 10px 30px; border-radius:6px; border:1px solid #BFDBFE; margin-top:10px; list-style-type: decimal;\">\n",
        "    <li style=\"color:#1E3A8A; margin-bottom:8px;\">\n",
        "      <strong>Inputs:</strong> Takes the <code>selected_city</code> name, the dictionary of user <code>preferences</code>, and the optional <code>country</code> name.\n",
        "    </li>\n",
        "     <li style=\"color:#1E3A8A; margin-bottom:8px;\">\n",
        "        <strong>Prerequisite Checks:</strong> Performs extensive checks at the beginning to ensure all required global variables and functions (like the Gemini <code>client</code>, ChromaDB <code>poi_collection</code>, RAG/Weather functions, system prompt, Pydantic model, etc.) are available and valid. This prevents runtime errors if setup steps failed or were skipped. Crucially checks if the Gemini <code>client</code> was initialized (dependent on the API key).\n",
        "    </li>\n",
        "    <li style=\"color:#1E3A8A; margin-bottom:8px;\">\n",
        "      <strong>Step 1: RAG Retrieval:</strong> Calls the <code>retrieve_rag_documents</code> function (defined in Step 19) to fetch relevant POI documents from ChromaDB based on the city and user preferences. Formats these documents into a <code>rag_context</code> string to be included in the LLM prompt. Handles potential errors during retrieval.\n",
        "    </li>\n",
        "     <li style=\"color:#1E3A8A; margin-bottom:8px;\">\n",
        "      <strong>Step 2: Fetch Weather Data:</strong> Calls the <code>get_weather</code> tool function (defined in Step 17) directly using Python code (<code>get_weather.invoke(...)</code>). This fetches live weather data (or placeholder data if the API key/call fails) *before* calling the main LLM. Parses the result into a user-friendly <code>weather_summary_str</code>.\n",
        "    </li>\n",
        "     <li style=\"color:#1E3A8A; margin-bottom:8px;\">\n",
        "      <strong>Step 3: Construct LLM Input:</strong> Assembles the input for the Phase 2 LLM:\n",
        "        <ul>\n",
        "            <li>Creates a summary of user preferences.</li>\n",
        "            <li>Constructs the main user request content, including the selected city, preference summary, and the retrieved <code>rag_context</code>.</li>\n",
        "            <li>Combines the detailed <code>phase2_system_prompt</code> (from Step 20) with this user request content into the format expected by the <code>client.models.generate_content</code> method.</li>\n",
        "        </ul>\n",
        "    </li>\n",
        "    <li style=\"color:#1E3A8A; margin-bottom:8px;\">\n",
        "      <strong>Step 4: Call Phase 2 LLM (with Grounding):</strong>\n",
        "        <ul>\n",
        "            <li>Invokes the Gemini LLM using <code>client.models.generate_content</code>.</li>\n",
        "            <li>Passes the constructed input history and the <code>PHASE2_MODEL_NAME</code>.</li>\n",
        "            <li>Crucially, enables Grounding by providing the <code>phase2_tools_genai</code> list (containing the Google Search tool) in the <code>GenerateContentConfig</code>. The LLM uses this internally to find events.</li>\n",
        "            <li>Includes error handling for Google API errors during the call.</li>\n",
        "        </ul>\n",
        "    </li>\n",
        "     <li style=\"color:#1E3A8A; margin-bottom:8px;\">\n",
        "      <strong>Step 5: Process LLM Response:</strong> Extracts the generated text content from the LLM's response. Includes checks for missing candidates or text parts.\n",
        "    </li>\n",
        "     <li style=\"color:#1E3A8A;\">\n",
        "      <strong>Step 6: Parse JSON, Add Weather, & Validate:</strong>\n",
        "        <ul>\n",
        "            <li>Cleans the extracted LLM text (removing potential markdown code fences).</li>\n",
        "            <li>Parses the cleaned text as JSON, expecting it to match the <code>CityInformation</code> structure (minus weather).</li>\n",
        "            <li>If parsing is successful, it **injects** the previously fetched <code>weather_summary_str</code> into the parsed dictionary.</li>\n",
        "            <li>Attempts to validate the combined dictionary against the full <code>CityInformation</code> Pydantic model for final verification. If validation fails, it prints a warning but still returns the parsed (but unvalidated) dictionary.</li>\n",
        "            <li>Returns the final, validated (or partially validated) dictionary containing all city details. Includes error handling for JSON parsing and validation.</li>\n",
        "        </ul>\n",
        "    </li>\n",
        "  </ul>\n",
        "  <p style=\"color:gray; margin-top:10px; font-style: italic;\">\n",
        "    This function acts as the main engine for Phase 2, coordinating data retrieval (RAG, weather tool) and generative synthesis (LLM with Grounding) to produce a rich, structured overview of the selected travel destination.\n",
        "  </p>\n",
        "</div>"
      ],
      "metadata": {
        "id": "tgLnz09BrLZG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def execute_phase2(\n",
        "    selected_city: str,\n",
        "    preferences: Dict[str, Any],\n",
        "    country: Optional[str] = None\n",
        "    ) -> Optional[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Orchestrates Phase 2: Retrieves RAG context, calls the Phase 2 LLM\n",
        "    with grounding ONLY, calls weather\n",
        "    tool separately, parses the structured JSON response, adds weather, and returns\n",
        "    the final city information dictionary.\n",
        "    \"\"\"\n",
        "\n",
        "    if not selected_city:\n",
        "        print(\"Phase 2 Error: No city was selected.\")\n",
        "        return None\n",
        "    required_globals = {\n",
        "        'client': client,\n",
        "        'poi_collection': poi_collection,\n",
        "        'gemini_embedder_query': gemini_embedder_query,\n",
        "        'phase2_tools_genai': phase2_tools_genai,\n",
        "        'phase2_system_prompt': phase2_system_prompt,\n",
        "        'get_weather': get_weather,\n",
        "        'PHASE2_MODEL_NAME': PHASE2_MODEL_NAME,\n",
        "        'retrieve_rag_documents': retrieve_rag_documents,\n",
        "        'CityInformation': CityInformation\n",
        "    }\n",
        "    for req_var_name, req_var_value in required_globals.items():\n",
        "         if req_var_name not in globals() or req_var_value is None:\n",
        "              print(f\"Phase 2 Error: Required component '{req_var_name}' is not available or is None.\")\n",
        "              return None\n",
        "         if req_var_name in ['get_weather', 'retrieve_rag_documents'] and not callable(req_var_value):\n",
        "             print(f\"Phase 2 Error: Required function '{req_var_name}' is not callable.\")\n",
        "             return None\n",
        "         if req_var_name == 'CityInformation' and not issubclass(req_var_value, BaseModel):\n",
        "             print(f\"Phase 2 Error: Required Pydantic model '{req_var_name}' is not valid.\")\n",
        "             return None\n",
        "\n",
        "\n",
        "    # 1. RAG Retrieval\n",
        "    rag_docs = []\n",
        "    try:\n",
        "        rag_docs = retrieve_rag_documents(\n",
        "            city=selected_city,\n",
        "            preferences=preferences,\n",
        "            collection=poi_collection,\n",
        "            embedder=gemini_embedder_query,\n",
        "            n_results=5\n",
        "        )\n",
        "        if rag_docs:\n",
        "            rag_context = \"\\n\\n\".join([f\"Context POI {i+1}:\\n{doc}\" for i, doc in enumerate(rag_docs)])\n",
        "        else:\n",
        "            rag_context = \"No relevant Points of Interest found in the database for this city and preferences.\"\n",
        "            print(\"Phase 2 RAG: No documents retrieved (or function returned empty).\")\n",
        "    except Exception as rag_err:\n",
        "        print(f\"Phase 2 RAG: Error during retrieval: {rag_err}\")\n",
        "        traceback.print_exc()\n",
        "        rag_context = \"Error retrieving Points of Interest from the database.\"\n",
        "\n",
        "\n",
        "    # 2. Call Weather Tool Separately\n",
        "    weather_summary_str = \"Weather information currently unavailable.\"\n",
        "    try:\n",
        "        weather_input = {\"city\": selected_city}\n",
        "        if country:\n",
        "            weather_input[\"country\"] = country\n",
        "        weather_data = get_weather.invoke(weather_input)\n",
        "\n",
        "        if weather_data and isinstance(weather_data, dict):\n",
        "             temp = weather_data.get('temperature_celsius')\n",
        "             cond = weather_data.get('condition', 'N/A')\n",
        "             loc = weather_data.get('location', selected_city)\n",
        "             feels = weather_data.get('feels_like_celsius')\n",
        "\n",
        "             weather_parts = []\n",
        "             if temp is not None: weather_parts.append(f\"{temp}¬∞C\")\n",
        "             if cond != 'N/A': weather_parts.append(f\"{cond}\")\n",
        "             summary_core = \" and \".join(filter(None, weather_parts))\n",
        "             if not summary_core: summary_core = \"condition unavailable\"\n",
        "\n",
        "             weather_summary_str = f\"Currently it is {summary_core} in {loc}.\"\n",
        "             if feels is not None:\n",
        "                 weather_summary_str += f\" Feels like {feels}¬∞C.\"\n",
        "        else:\n",
        "             print(\"Phase 2 Weather: Tool returned no data or unexpected format.\")\n",
        "\n",
        "    except Exception as weather_e:\n",
        "        print(f\"Phase 2 Weather: Error calling get_weather tool: {weather_e}\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "\n",
        "    #  3. Construct Input History for LLM\n",
        "    pref_summary = \", \".join([f\"{k}: {v}\" for k, v in preferences.items() if v])\n",
        "    user_content = f\"\"\"\n",
        "Selected City: {selected_city} {f\"({country})\" if country else \"\"}\n",
        "User Preferences Summary: [{pref_summary}]\n",
        "\n",
        "Retrieved Points of Interest Context:\n",
        "---\n",
        "{rag_context}\n",
        "---\n",
        "\n",
        "Please generate the detailed city information (excluding weather) based on all instructions in the system prompt. Output only the valid JSON object.\n",
        "\"\"\"\n",
        "    initial_user_part_text = f\"\"\"SYSTEM PROMPT:\n",
        "---\n",
        "{phase2_system_prompt}\n",
        "---\n",
        "\n",
        "USER REQUEST:\n",
        "---\n",
        "{user_content}\"\"\"\n",
        "\n",
        "    current_content_history = [\n",
        "        genai_types.Content(role=\"user\", parts=[genai_types.Part(text=initial_user_part_text)])\n",
        "    ]\n",
        "\n",
        "    # 4. Call Phase 2 LLM\n",
        "    generated_text = None\n",
        "    try:\n",
        "        content_config_with_grounding = genai_types.GenerateContentConfig(\n",
        "            tools=phase2_tools_genai\n",
        "        )\n",
        "\n",
        "        response = client.models.generate_content(\n",
        "            model=PHASE2_MODEL_NAME,\n",
        "            contents=current_content_history,\n",
        "            config=content_config_with_grounding\n",
        "        )\n",
        "\n",
        "        # 5. Process Final LLM Response\n",
        "        if not response.candidates:\n",
        "             print(\"Phase 2 Error: LLM response missing candidates.\")\n",
        "             return None\n",
        "\n",
        "        if not (response.candidates[0].content.parts and hasattr(response.candidates[0].content.parts[0], 'text')):\n",
        "             print(\"Phase 2 Error: LLM response did not contain expected text part.\")\n",
        "             try: print(f\"LLM Raw Response: {response}\")\n",
        "             except Exception: pass\n",
        "             return None\n",
        "\n",
        "        generated_text = response.candidates[0].content.parts[0].text\n",
        "\n",
        "    except google.api_core.exceptions.GoogleAPIError as api_error:\n",
        "        print(f\"Phase 2 Error: Google API Error during generate_content: {api_error}\")\n",
        "        if hasattr(api_error, 'message'): print(f\"API Error Message: {api_error.message}\")\n",
        "        return None\n",
        "    except Exception as llm_call_err:\n",
        "        print(f\"An unexpected error occurred during Phase 2 LLM call: {type(llm_call_err).__name__} - {llm_call_err}\")\n",
        "        traceback.print_exc()\n",
        "        return None\n",
        "\n",
        "    #6. Parse JSON, Add Weather, & Validate\n",
        "    if generated_text:\n",
        "        parsed_data = None\n",
        "        try:\n",
        "            text_to_parse = generated_text.strip()\n",
        "            if text_to_parse.startswith(\"```json\"):\n",
        "                text_to_parse = text_to_parse[7:]\n",
        "                if text_to_parse.endswith(\"```\"):\n",
        "                    text_to_parse = text_to_parse[:-3]\n",
        "            elif text_to_parse.startswith(\"```\"):\n",
        "                 text_to_parse = text_to_parse[3:]\n",
        "                 if text_to_parse.endswith(\"```\"):\n",
        "                    text_to_parse = text_to_parse[:-3]\n",
        "            text_to_parse = text_to_parse.strip()\n",
        "\n",
        "            if not text_to_parse:\n",
        "                 raise ValueError(\"LLM returned empty text after cleaning.\")\n",
        "\n",
        "            parsed_data = json.loads(text_to_parse)\n",
        "\n",
        "            if isinstance(parsed_data, dict):\n",
        "                parsed_data['weather_summary'] = weather_summary_str\n",
        "            else:\n",
        "                print(\"Warning: LLM response parsed but was not a dictionary. Cannot add weather.\")\n",
        "                return None\n",
        "\n",
        "            try:\n",
        "                 city_info = CityInformation(**parsed_data)\n",
        "                 return city_info.dict()\n",
        "            except Exception as pydantic_error:\n",
        "                 print(f\"Phase 2 Warning: Combined data failed Pydantic validation: {pydantic_error}\")\n",
        "                 print(f\"Data that failed validation: {parsed_data}\")\n",
        "                 return parsed_data\n",
        "\n",
        "        except json.JSONDecodeError as json_error:\n",
        "            print(f\"Phase 2 Error: Failed to decode LLM response as JSON: {json_error}\")\n",
        "            print(f\"LLM Raw Output (before cleaning) was:\\n---\\n{generated_text}\\n---\")\n",
        "            return None\n",
        "        except Exception as parse_validate_error:\n",
        "            print(f\"Phase 2 Error: Error during JSON processing or validation: {parse_validate_error}\")\n",
        "            if generated_text: print(f\"LLM Raw Output was:\\n---\\n{generated_text}\\n---\")\n",
        "            traceback.print_exc()\n",
        "            return None\n",
        "    else:\n",
        "        print(\"Phase 2 Error: No text generated by the LLM.\")\n",
        "        return None\n",
        "print(\"Phase 2 execution logic function.\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "rgDBPBf8rLZG"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color:#FFFBEB; padding:15px; border-radius:8px; margin-top:20px; border:1px dashed #F59E0B;\">\n",
        "  <h2 style=\"color:#B45309; border-bottom: 2px solid #D97706; padding-bottom: 5px;\">Step 22: Execute Phase 2 & Initiate Q&A Session</h2>\n",
        "  <p style=\"color:gray; margin-top:10px;\">\n",
        "    This cell executes the second phase of the agent's workflow if a city was successfully selected in Phase 1. It calls the <code>execute_phase2</code> function to generate detailed city information and then initiates an interactive or demo-driven Question & Answer session about that city, depending on the <code>INTERACTIVE_MODE</code> flag.\n",
        "  </p>\n",
        "  <ol style=\"background-color:#FEFCE8; padding:10px 10px 10px 30px; border-radius:6px; border:1px solid #FEF9C3; margin-top:10px; list-style-type: decimal;\">\n",
        "    <li style=\"color:#713F12; margin-bottom:8px;\">\n",
        "      <strong>Check Phase 1 Outcome:</strong> Examines the <code>final_state</code> from the Phase 1 graph execution (Step 16) to see if a city was selected via <code>selected_city_for_phase_2</code>.\n",
        "    </li>\n",
        "     <li style=\"color:#713F12; margin-bottom:8px;\">\n",
        "      <strong>Prepare for Phase 2:</strong> If a city was selected, retrieves necessary details (city name, prefs, image, country) and sets the <code>proceed_to_phase2</code> flag. Otherwise, prints a message indicating Phase 2 cannot start.\n",
        "    </li>\n",
        "    <li style=\"color:#713F12; margin-bottom:8px;\">\n",
        "      <strong>Execute Phase 2 Logic:</strong> If <code>proceed_to_phase2</code> is <code>True</code>, calls the <code>execute_phase2</code> function (defined in Step 21) to trigger RAG, weather fetch, and the Grounding-enabled LLM call. Includes error handling.\n",
        "    </li>\n",
        "     <li style=\"color:#713F12; margin-bottom:8px;\">\n",
        "      <strong>Display Detailed City Information:</strong> If Phase 2 execution is successful and returns data (<code>city_info_dict</code>), extracts the details and renders a rich HTML overview of the city, including summary, weather, POIs, and events.\n",
        "     </li>\n",
        "     <li style=\"color:#713F12; margin-bottom:8px;\">\n",
        "      <strong>Initiate Q&A Session:</strong> If city information was displayed, prepares context strings (summary of displayed POIs/events) and proceeds to the Q&A section.\n",
        "    </li>\n",
        "    <li style=\"color:#713F12; margin-bottom:8px;\">\n",
        "        <strong>Q&A Loop Logic (Handles Interaction Mode):</strong>\n",
        "        <ul>\n",
        "            <li><strong>If <code>INTERACTIVE_MODE</code> is <code>True</code>:</strong> Enters a <code>while True</code> loop, prompts the user for questions using <code>input()</code>, and handles 'quit' commands.</li>\n",
        "            <li><strong>If <code>INTERACTIVE_MODE</code> is <code>False</code> (Demo Mode):</strong> Defines a list of predefined <code>demo_questions</code> (dynamically based on retrieved POIs/events if possible) and iterates through them using a <code>for</code> loop, limited by <code>MAX_DEMO_QUESTIONS</code>.</li>\n",
        "            <li><strong>For Each Question (Both Modes):</strong>\n",
        "                <ul>\n",
        "                  <li>Performs RAG by calling <code>retrieve_rag_documents</code> based on the current question.</li>\n",
        "                  <li>Constructs a detailed prompt for the Q&A LLM, including context about previously shown info, RAG snippets, and the question itself.</li>\n",
        "                  <li>Checks if the Gemini <code>client</code> is available (handles missing API key). If available, calls the Q&A LLM (<code>gemini-1.5-flash-latest</code>).</li>\n",
        "                  <li>Extracts, formats (HTML), and displays the LLM's answer.</li>\n",
        "                  <li>Includes error handling for each Q&A turn.</li>\n",
        "                </ul>\n",
        "            </li>\n",
        "        </ul>\n",
        "    </li>\n",
        "     <li style=\"color:#713F12;\">\n",
        "        <strong>Handle Phase 2 Failure:</strong> If <code>proceed_to_phase2</code> was true but <code>execute_phase2</code> failed (<code>city_info_dict</code> is None), prints an informative error message.\n",
        "    </li>\n",
        "  </ol>\n",
        "  <p style=\"color:gray; margin-top:10px; font-style: italic;\">\n",
        "   This final cell integrates Phase 1 and Phase 2. It displays the detailed city information generated via RAG and Grounding, and then runs a Q&A loop allowing follow-up questions answered using RAG context. The Q&A behavior adapts based on the <code>INTERACTIVE_MODE</code> flag for evaluation purposes.\n",
        "  </p>\n",
        "</div>"
      ],
      "metadata": {
        "id": "g6TzHLo7rLZG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "selected_city = None\n",
        "user_prefs = {}\n",
        "selected_city_img_url = PLACEHOLDER_IMAGE_URL\n",
        "selected_city_country = None\n",
        "proceed_to_phase2 = False\n",
        "city_info_dict = None\n",
        "\n",
        "if 'final_state' in globals() and final_state and isinstance(final_state, dict) and final_state.get('selected_city_for_phase_2'):\n",
        "    selected_city = final_state['selected_city_for_phase_2']\n",
        "    user_prefs = final_state.get('user_preferences', {})\n",
        "    print(f\"‚úÖ Proceeding to Phase 2 for selected city: {selected_city}\")\n",
        "\n",
        "    phase1_recs = final_state.get('recommendations', [])\n",
        "    if isinstance(phase1_recs, list):\n",
        "        for rec in phase1_recs:\n",
        "            if isinstance(rec, dict) and rec.get('city') == selected_city:\n",
        "                selected_city_img_url = rec.get('image_url', PLACEHOLDER_IMAGE_URL)\n",
        "                selected_city_country = rec.get('country')\n",
        "                break\n",
        "\n",
        "    proceed_to_phase2 = True\n",
        "else:\n",
        "    print(\"‚èπÔ∏è Phase 2 cannot start: No valid city selected in Phase 1 or 'final_state' missing/invalid.\")\n",
        "    if 'final_state' in globals() and isinstance(final_state, dict):\n",
        "        print(f\"   Phase 1 Final state details: Finished={final_state.get('is_finished')}, Error={final_state.get('error_message')}, Selection={final_state.get('selected_city_for_phase_2')}\")\n",
        "\n",
        "if proceed_to_phase2:\n",
        "    print(f\"\\n--- Executing Phase 2 for {selected_city} ---\")\n",
        "    try:\n",
        "        city_info_dict = execute_phase2(\n",
        "            selected_city=selected_city,\n",
        "            preferences=user_prefs,\n",
        "            country=selected_city_country\n",
        "        )\n",
        "        if city_info_dict:\n",
        "            print(f\"‚úÖ Phase 2 execution successful. Received city information.\")\n",
        "        else:\n",
        "            print(f\"‚ö†Ô∏è Phase 2 execution completed but returned no data.\")\n",
        "\n",
        "    except Exception as phase2_exec_error:\n",
        "         print(f\"\\n--- ‚ùå An unexpected error occurred calling execute_phase2 ---\")\n",
        "         print(f\"Error Type: {type(phase2_exec_error).__name__}\")\n",
        "         print(f\"Error Details: {phase2_exec_error}\")\n",
        "         traceback.print_exc()\n",
        "         city_info_dict = None\n",
        "\n",
        "if city_info_dict and isinstance(city_info_dict, dict):\n",
        "    city_name = city_info_dict.get('city_name', selected_city)\n",
        "    country_name = city_info_dict.get('country_name', selected_city_country or 'N/A')\n",
        "    general_summary = city_info_dict.get('general_summary', \"No summary available.\")\n",
        "    weather_summary = city_info_dict.get('weather_summary', \"Weather information unavailable.\")\n",
        "    points_of_interest = city_info_dict.get('points_of_interest', [])\n",
        "    events = city_info_dict.get('events', [])\n",
        "\n",
        "    print(\"\\n--- Displaying City Information ---\")\n",
        "    html = f\"\"\"\n",
        "<div style=\"font-family: sans-serif; border: 1px solid #eee; border-radius: 10px; padding: 25px; background-color: #fdfdfd; max-width: 800px; margin: 20px auto; box-shadow: 0 4px 12px rgba(0,0,0,0.1);\">\n",
        "  <h2 style=\"color: #2c3e50; border-bottom: 2px solid #3498db; padding-bottom: 10px; margin-top: 0;\">Explore {city_name}, {country_name}</h2>\n",
        "  <img src=\"{selected_city_img_url}\" alt=\"Image of {city_name}\" style=\"max-width: 100%; height: auto; border-radius: 8px; margin-bottom: 20px; display: block;\">\n",
        "\n",
        "  <div style=\"margin-bottom: 25px;\">\n",
        "    <h3 style=\"color: #34495e; margin-bottom: 8px;\">City Overview</h3>\n",
        "    <p style=\"line-height: 1.6; color: #555; margin-top: 0;\">{general_summary}</p>\n",
        "  </div>\n",
        "\n",
        "  <div style=\"margin-bottom: 25px;\">\n",
        "    <h3 style=\"color: #34495e; margin-bottom: 8px;\">Current Weather</h3>\n",
        "    <p style=\"color: #555; background-color: #ecf0f1; padding: 12px 15px; border-radius: 5px; margin-top: 0;\">‚òÄÔ∏è {weather_summary}</p>\n",
        "  </div>\n",
        "\n",
        "  <div style=\"margin-bottom: 25px;\">\n",
        "    <h3 style=\"color: #34495e; margin-bottom: 15px;\">Points of Interest</h3>\n",
        "\"\"\"\n",
        "    # POI List\n",
        "    if points_of_interest and isinstance(points_of_interest, list):\n",
        "        html += '<ul style=\"list-style: none; padding: 0; margin: 0;\">'\n",
        "        for poi in points_of_interest:\n",
        "            if isinstance(poi, dict):\n",
        "                poi_name = poi.get('name', 'Unknown POI')\n",
        "                poi_type = poi.get('type', 'N/A')\n",
        "                poi_desc = poi.get('description', 'No details provided.')\n",
        "                html += f'<li style=\"border: 1px solid #e0e0e0; border-radius: 5px; padding: 15px; margin-bottom: 12px; background-color: #fff; box-shadow: 0 1px 3px rgba(0,0,0,0.05);\">'\n",
        "                html += f'<strong style=\"color: #2980b9; display: block; margin-bottom: 5px;\">{poi_name}</strong>'\n",
        "                html += f'<span style=\"font-size: 0.9em; color: #888; margin-bottom: 5px; display: inline-block;\">Type: {poi_type}</span><br>'\n",
        "                html += f'<span style=\"font-size: 0.95em; color: #666; line-height: 1.5;\">{poi_desc}</span></li>'\n",
        "            else:\n",
        "                 html += '<li style=\"color: #e74c3c;\">Error: Invalid POI data format found.</li>'\n",
        "        html += \"</ul>\"\n",
        "    else:\n",
        "        html += '<p style=\"color: #777; font-style: italic;\">No specific Points of Interest suggested based on current criteria or data.</p>'\n",
        "    html += \"</div>\"\n",
        "\n",
        "    # Events List\n",
        "    html += '<div style=\"margin-bottom: 15px;\">'\n",
        "    html += '<h3 style=\"color: #34495e; margin-bottom: 15px;\">Current / Upcoming Events</h3>'\n",
        "    if events and isinstance(events, list):\n",
        "        html += '<div style=\"display: flex; flex-wrap: wrap; gap: 10px;\">'\n",
        "        for event in events:\n",
        "             if isinstance(event, dict):\n",
        "                event_name = event.get(\"name\", \"Unknown Event\")\n",
        "                event_summary = event.get(\"summary\", \"No details.\")\n",
        "                html += f'<span style=\"background-color: #9b59b6; color: white; padding: 6px 12px; border-radius: 15px; font-size: 0.9em; cursor: default; display: inline-block; margin-bottom: 5px; line-height: 1.4; box-shadow: 1px 1px 3px rgba(0,0,0,0.1);\" title=\"{event_summary}\">{event_name}</span>'\n",
        "             else:\n",
        "                 html += '<span style=\"color: #e74c3c;\">Error: Invalid Event data format.</span>'\n",
        "        html += \"</div>\"\n",
        "    else:\n",
        "        html += '<p style=\"color: #777; font-style: italic;\">Could not find specific current events via search grounding.</p>'\n",
        "    html += \"</div></div>\"\n",
        "\n",
        "    display(HTML(html))\n",
        "\n",
        "    displayed_pois_text = \"\"\n",
        "    if points_of_interest:\n",
        "        displayed_pois_text = \"\\nPreviously suggested Points of Interest:\\n\"\n",
        "        for i, poi in enumerate(points_of_interest):\n",
        "             if isinstance(poi, dict):\n",
        "                 displayed_pois_text += f\"{i+1}. Name: {poi.get('name', 'N/A')}, Type: {poi.get('type', 'N/A')}, Desc: {poi.get('description', 'N/A')}\\n\"\n",
        "\n",
        "    initial_events_text = \"\"\n",
        "    if events:\n",
        "        initial_events_text = \"\\nSome recent/upcoming events mentioned earlier:\\n\"\n",
        "        for ev in events:\n",
        "             if isinstance(ev, dict):\n",
        "                initial_events_text += f\"- {ev.get('name', 'N/A')}: {ev.get('summary', 'N/A')}\\n\"\n",
        "\n",
        "    # --- Q&A Section ---\n",
        "    print(f\"\\n--- Starting Q&A for: {selected_city} ---\")\n",
        "\n",
        "    # --- Interactive Q&A ---\n",
        "    if INTERACTIVE_MODE:\n",
        "        print(\"Feel free to ask about the places mentioned above or other details.\")\n",
        "        print(\"Type 'quit' or 'exit' to end the chat.\")\n",
        "        while True:\n",
        "            try:\n",
        "                user_question = input(f\"\\nüë§ Ask about {selected_city}: \")\n",
        "                user_question_clean = user_question.strip().lower()\n",
        "                if user_question_clean in [\"quit\", \"exit\", \"q\", \"bye\"]:\n",
        "                    print(\"Ending Q&A session. Safe travels!\")\n",
        "                    break\n",
        "                if not user_question.strip(): continue\n",
        "\n",
        "                # --- Run single Q&A turn ---\n",
        "                # 1. Perform RAG based on the question\n",
        "                rag_query_prefs = {\"user_question\": user_question}\n",
        "                rag_context_docs = retrieve_rag_documents(\n",
        "                    city=selected_city, preferences=rag_query_prefs, collection=poi_collection, embedder=gemini_embedder_query, n_results=3\n",
        "                )\n",
        "                if rag_context_docs: rag_context_for_llm = \"\\n---\\n\".join(rag_context_docs)\n",
        "                else: rag_context_for_llm = \"No specific details found in the local database regarding that topic.\"\n",
        "\n",
        "                # 2. Construct LLM Prompt\n",
        "                qna_prompt = f\"\"\"You are Nomad, a friendly travel assistant discussing {city_name} with a user. Use a helpful and informative tone, avoiding repetitive greetings.\n",
        "\n",
        "Here's some information that was initially presented to the user:\n",
        "POIs: {displayed_pois_text if displayed_pois_text else \"None initially listed.\"}\n",
        "Events: {initial_events_text if initial_events_text else \"None initially listed.\"}\n",
        "(Note: The initial event list might include upcoming or recurring events, not necessarily live ones).\n",
        "\n",
        "Now, answer the user's latest question based on the information above AND the relevant snippets retrieved below.\n",
        "\n",
        "Instructions:\n",
        "1.  **Acknowledge the Question:** Briefly acknowledge the user's topic.\n",
        "2.  **Prioritize Specifics:** If the user asks about a *specific POI or event mentioned above or in the snippets*, focus on providing details found in *either* the initial context OR the retrieved snippets. Combine information if possible.\n",
        "3.  **General Event Questions:** If asked *generally* about \"current events\" or \"what's happening now\", check the initial event list and snippets. If no *clearly current* events are found (besides daily activities like Djemaa El-Fna), explain that the available information focuses on known points of interest and some specific listed events which might not be live, and recommend checking local resources for real-time updates.\n",
        "4.  **Insufficient Info:** If neither the initial context nor the snippets contain relevant information to answer the question, state that you don't have those specific details in the provided context.\n",
        "5.  **Conciseness:** Keep answers concise and relevant to the question.\n",
        "\n",
        "Retrieved Context Snippets (Primarily for POIs/General Info, but might mention events):\n",
        "---\n",
        "{rag_context_for_llm}\n",
        "---\n",
        "\n",
        "User Question: {user_question}\n",
        "\n",
        "Nomad's Answer:\"\"\"\n",
        "\n",
        "                # 3. Call Q&A LLM\n",
        "                QNA_MODEL_NAME = \"gemini-2.0-flash\"\n",
        "                if not client:\n",
        "                     print(\"ü§ñ Nomad: Sorry, my Q&A module is offline (API client not available).\")\n",
        "                     continue\n",
        "\n",
        "                qna_response = client.models.generate_content(\n",
        "                    model=QNA_MODEL_NAME,\n",
        "                    contents=[qna_prompt],\n",
        "                    config=genai_types.GenerateContentConfig(temperature=0.6)\n",
        "                )\n",
        "\n",
        "                # 4. Extract and Style Answer\n",
        "                llm_answer_text = \"Sorry, I had trouble formulating an answer to that.\"\n",
        "                if qna_response.candidates and qna_response.candidates[0].content.parts:\n",
        "                    llm_answer_text = qna_response.candidates[0].content.parts[0].text\n",
        "\n",
        "                formatted_answer = llm_answer_text.replace('\\n', '<br>')\n",
        "                answer_html = f\"\"\"<div style=\"border: 1px solid #4CAF50; border-left: 5px solid #4CAF50; border-radius: 5px; padding: 15px 20px; margin: 15px 0; background-color: #f0fff0; box-shadow: 2px 2px 5px rgba(0,0,0,0.05);\"><strong style=\"color: #2E7D32; display: block; margin-bottom: 8px;\">ü§ñ Nomad:</strong><p style=\"margin: 0; line-height: 1.6; color: #333;\">{formatted_answer}</p></div>\"\"\"\n",
        "                display(HTML(answer_html))\n",
        "                # --- End single Q&A turn ---\n",
        "\n",
        "            except Exception as qna_err:\n",
        "                print(f\"\\n--- ‚ùå Error during Q&A ---\")\n",
        "                print(f\"Error Type: {type(qna_err).__name__}\")\n",
        "                print(f\"Error Details: {qna_err}\")\n",
        "                traceback.print_exc()\n",
        "                print(\"Sorry, I encountered a problem processing that question. Please try phrasing it differently or type 'quit'.\")\n",
        "    # --- End Interactive Q&A ---\n",
        "\n",
        "    # --- Demo Mode Q&A ---\n",
        "    else:\n",
        "        print(\"ü§ñ Demo Mode: Running predefined Q&A questions...\")\n",
        "        demo_questions = []\n",
        "        if points_of_interest and isinstance(points_of_interest, list) and len(points_of_interest) > 0 and isinstance(points_of_interest[0], dict):\n",
        "             demo_questions.append(f\"Tell me more about {points_of_interest[0].get('name', 'the first point of interest')}.\")\n",
        "        else:\n",
        "            demo_questions.append(\"What is there to see there?\")\n",
        "\n",
        "        if events and isinstance(events, list) and len(events) > 0 and isinstance(events[0], dict):\n",
        "             demo_questions.append(f\"What is the {events[0].get('name', 'first event')} about?\")\n",
        "        else:\n",
        "            demo_questions.append(\"Any interesting food recommendations?\")\n",
        "\n",
        "        question_count = 0\n",
        "        MAX_DEMO_QUESTIONS = 2\n",
        "\n",
        "        for user_question in demo_questions:\n",
        "            if question_count >= MAX_DEMO_QUESTIONS:\n",
        "                break\n",
        "            print(f\"\\nüë§ Demo Question: {user_question}\")\n",
        "            try:\n",
        "                # 1. Perform RAG\n",
        "                rag_query_prefs = {\"user_question\": user_question}\n",
        "                rag_context_docs = retrieve_rag_documents(\n",
        "                    city=selected_city, preferences=rag_query_prefs, collection=poi_collection, embedder=gemini_embedder_query, n_results=3\n",
        "                )\n",
        "                if rag_context_docs: rag_context_for_llm = \"\\n---\\n\".join(rag_context_docs)\n",
        "                else: rag_context_for_llm = \"No specific details found in the local database regarding that topic.\"\n",
        "\n",
        "                # 2. Construct LLM Prompt\n",
        "                qna_prompt = f\"\"\"You are Nomad, a friendly travel assistant discussing {city_name} with a user. Use a helpful and informative tone, avoiding repetitive greetings.\n",
        "\n",
        "Here's some information that was initially presented to the user:\n",
        "POIs: {displayed_pois_text if displayed_pois_text else \"None initially listed.\"}\n",
        "Events: {initial_events_text if initial_events_text else \"None initially listed.\"}\n",
        "(Note: The initial event list might include upcoming or recurring events, not necessarily live ones).\n",
        "\n",
        "Now, answer the user's latest question based on the information above AND the relevant snippets retrieved below.\n",
        "\n",
        "Instructions:\n",
        "1.  **Acknowledge the Question:** Briefly acknowledge the user's topic.\n",
        "2.  **Prioritize Specifics:** If the user asks about a *specific POI or event mentioned above or in the snippets*, focus on providing details found in *either* the initial context OR the retrieved snippets. Combine information if possible.\n",
        "3.  **General Event Questions:** If asked *generally* about \"current events\" or \"what's happening now\", check the initial event list and snippets. If no *clearly current* events are found (besides daily activities like Djemaa El-Fna), explain that the available information focuses on known points of interest and some specific listed events which might not be live, and recommend checking local resources for real-time updates.\n",
        "4.  **Insufficient Info:** If neither the initial context nor the snippets contain relevant information to answer the question, state that you don't have those specific details in the provided context.\n",
        "5.  **Conciseness:** Keep answers concise and relevant to the question.\n",
        "\n",
        "Retrieved Context Snippets (Primarily for POIs/General Info, but might mention events):\n",
        "---\n",
        "{rag_context_for_llm}\n",
        "---\n",
        "\n",
        "User Question: {user_question}\n",
        "\n",
        "Nomad's Answer:\"\"\"\n",
        "\n",
        "                # 3. Call Q&A LLM\n",
        "                QNA_MODEL_NAME = \"gemini-2.0-flash\"\n",
        "                if not client:\n",
        "                     print(\"ü§ñ Nomad: Sorry, my Q&A module is offline (API client not available).\")\n",
        "                     continue\n",
        "\n",
        "                qna_response = client.models.generate_content(\n",
        "                    model=QNA_MODEL_NAME,\n",
        "                    contents=[qna_prompt],\n",
        "                    config=genai_types.GenerateContentConfig(temperature=0.6)\n",
        "                )\n",
        "\n",
        "                # 4. Extract and Style Answer\n",
        "                llm_answer_text = \"Sorry, I had trouble formulating an answer to that.\"\n",
        "                if qna_response.candidates and qna_response.candidates[0].content.parts:\n",
        "                    llm_answer_text = qna_response.candidates[0].content.parts[0].text\n",
        "\n",
        "                formatted_answer = llm_answer_text.replace('\\n', '<br>')\n",
        "                answer_html = f\"\"\"<div style=\"border: 1px solid #4CAF50; border-left: 5px solid #4CAF50; border-radius: 5px; padding: 15px 20px; margin: 15px 0; background-color: #f0fff0; box-shadow: 2px 2px 5px rgba(0,0,0,0.05);\"><strong style=\"color: #2E7D32; display: block; margin-bottom: 8px;\">ü§ñ Nomad:</strong><p style=\"margin: 0; line-height: 1.6; color: #333;\">{formatted_answer}</p></div>\"\"\"\n",
        "                display(HTML(answer_html))\n",
        "                # --- End single Q&A turn ---\n",
        "                question_count += 1\n",
        "\n",
        "            except Exception as qna_err:\n",
        "                print(f\"\\n--- ‚ùå Error during Demo Q&A for question: '{user_question}' ---\")\n",
        "                print(f\"Error Type: {type(qna_err).__name__}\")\n",
        "                print(f\"Error Details: {qna_err}\")\n",
        "                print(\"Skipping this demo question due to error.\")\n",
        "\n",
        "        print(\"\\nüèÅ Demo Mode: Finished predefined Q&A questions.\")\n",
        "        # --- End Demo Q&A ---\n",
        "\n",
        "elif proceed_to_phase2:\n",
        "    print(\"\\n--- ‚ùå Phase 2 Failed ---\")\n",
        "    print(f\"Sorry, I couldn't gather the detailed information for {selected_city} due to an error during processing.\")\n",
        "    print(\"Please check the logs in the preceding cells for specific error messages.\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "j77Er7jtrLZG"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr style=\"border:0; height:3px; background-image:linear-gradient(to right, rgba(0,0,0,0), rgba(100,116,139,0.75), rgba(0,0,0,0)); margin-top: 40px;\">\n",
        "\n",
        "<div style=\"background-color:#F8FAFC; padding:20px; border-radius:10px; margin-top:20px; border:1px solid #E2E8F0;\">\n",
        "  <h2 style=\"color:#0F172A; text-align:center; border-bottom: 2px solid #94A3B8; padding-bottom:10px;\">üèÅ Project Conclusion & Future Directions üöÄ</h2>\n",
        "\n",
        "  <h3 style=\"color:#1E293B;\">‚úÖ Summary of Achievements</h3>\n",
        "  <p style=\"color:#475569; line-height: 1.6;\">\n",
        "    This project successfully developed \"Nomad\", a conversational travel recommender agent prototype within a Kaggle notebook. Leveraging LangGraph, the agent engages users to understand their travel preferences (vibe, activities, weather, budget) through a structured dialogue. Based on these preferences, it generates personalized city recommendations, enhances them with images via Function Calling, and verifies them against a local dataset. Upon user selection, the agent provides a detailed city overview, integrating information retrieved via RAG from the Wikivoyage POI dataset, live weather data (via direct tool call), and current events discovered using Grounding (Google Search). Finally, it facilitates a follow-up Q&A session, using RAG to answer user questions about the selected city. The implementation also includes a non-interactive \"Demo Mode\" to ensure end-to-end runnability for evaluation purposes.\n",
        "  </p>\n",
        "\n",
        "  <h3 style=\"color:#1E293B; margin-top:25px;\">üí° Key Capabilities Demonstrated</h3>\n",
        "   <ul style=\"color:#475569; list-style-type: disc; margin-left: 20px; line-height: 1.7;\">\n",
        "      <li><strong>Agents / State Management:</strong> Using LangGraph to orchestrate the multi-step conversational flow and manage state (preferences, recommendations, etc.).</li>\n",
        "      <li><strong>Structured Output (JSON):</strong> Employing Pydantic models and LLM configuration (`with_structured_output`) for reliable parsing of user preferences and generation of recommendations and detailed city info.</li>\n",
        "      <li><strong>Function Calling / Tool Use:</strong> Defining and using tools (`@tool`) to interact with external APIs (Unsplash for images, OpenWeatherMap for weather), triggered via LangGraph's `ToolNode` (images) or direct Python calls (weather).</li>\n",
        "      <li><strong>Retrieval-Augmented Generation (RAG):</strong> Implementing RAG with ChromaDB (Vector Store) and Gemini Embeddings (`text-embedding-004`) on the Wikivoyage dataset to provide relevant POI context and answer specific user questions.</li>\n",
        "       <li><strong>Grounding (Google Search):</strong> Utilizing the Gemini API's grounding capability to fetch relevant, real-world information (current/upcoming events) not present in the static dataset.</li>\n",
        "       <li><strong>Vector Store Integration:</strong> Setting up and using ChromaDB for persistent storage and efficient similarity search of POI embeddings.</li>\n",
        "   </ul>\n",
        "\n",
        "  <h3 style=\"color:#1E293B; margin-top:25px;\">üöß Limitations & Challenges</h3>\n",
        "  <ul style=\"color:#475569; list-style-type: disc; margin-left: 20px; line-height: 1.7;\">\n",
        "      <li><strong>Dataset Quality:</strong> The Wikivoyage dataset, while rich, has inconsistencies, missing fields, and potentially outdated information, impacting POI relevance and the accuracy of the \"Details Available\" check.</li>\n",
        "      <li><strong>Tool Call Robustness:</strong> Image fetching selects the first relevant result, which may not always be optimal. Weather fetching in Phase 2 is currently a direct call, not dynamically triggered by the LLM based on need. Grounding for events can sometimes return past or less relevant items.</li>\n",
        "      <li><strong>RAG Performance:</strong> Retrieval effectiveness depends on embedding quality and query formulation. The current RAG might miss some relevant POIs or return slightly off-topic ones. The `content_for_rag` field could be optimized.</li>\n",
        "      <li><strong>Q&A Simplicity:</strong> The Q&A relies solely on RAG for context within each turn and lacks deeper conversational memory or sophisticated fallback mechanisms beyond stating information isn't available in the retrieved context. Gen AI Evaluation for answer quality wasn't implemented.</li>\n",
        "  </ul>\n",
        "\n",
        "  <h3 style=\"color:#1E293B; margin-top:25px;\">üöÄ Potential Future Work & Refinements (TODO)</h3>\n",
        "  <ul style=\"color:#475569; list-style-type: disc; margin-left: 20px; line-height: 1.7;\">\n",
        "      <li><strong>Enhance Dataset:</strong> Further clean the Wikivoyage data, potentially merge/augment it with data from sources like OpenStreetMap or other travel APIs. Implement smarter handling for missing POI details.</li>\n",
        "      <li><strong>Refine RAG Pipeline:</strong>\n",
        "          <ul>\n",
        "            <li>Experiment with different text chunking strategies for POIs.</li>\n",
        "            <li>Explore more advanced query transformation techniques (e.g., HyDE - Hypothetical Document Embeddings).</li>\n",
        "            <li>Implement a re-ranking step after initial retrieval to improve relevance.</li>\n",
        "          </ul>\n",
        "      </li>\n",
        "      <li><strong>Improve Tool Integration & Robustness:</strong>\n",
        "          <ul>\n",
        "            <li>Modify Phase 2 to allow the LLM to decide *when* to call the weather tool via Function Calling (requires more complex prompt engineering).</li>\n",
        "            <li>Enhance the image tool to fetch multiple options or use basic image analysis. Add more sophisticated error handling/retries within the tool functions.</li>\n",
        "            <li>Refine grounding prompts/queries for events to improve timeliness and relevance.</li>\n",
        "          </ul>\n",
        "      </li>\n",
        "       <li><strong>Advanced Q&A & Evaluation:</strong>\n",
        "          <ul>\n",
        "            <li>Implement Gen AI Evaluation (e.g., using Gemini) to assess the factual grounding and relevance of RAG-based answers in the Q&A loop.</li>\n",
        "            <li>Implement a fallback strategy using Grounding if the RAG evaluation score is low.</li>\n",
        "            <li>Integrate more sophisticated conversational memory techniques.</li>\n",
        "          </ul>\n",
        "       </li>\n",
        "      <li><strong>Model Task Consolidation (Experiment):</strong> While separating parsing and question-asking promotes reliability, one could *experiment* with a single LLM call using advanced prompting and a complex output schema to handle both tasks. However, this is expected to be less robust and harder to manage than the current multi-call approach. **The current separation is likely the better design choice for this workflow.**</li>\n",
        "      <li><strong>Scalability & Optimization:</strong> For production use, explore more scalable vector database solutions and optimize API call patterns.</li>\n",
        "  </ul>\n",
        "\n",
        "   <p style=\"color:#475569; margin-top:25px; text-align:center; font-style:italic;\">\n",
        "    This project demonstrates the power of combining various Gen AI techniques to build a useful and interactive application. There's ample scope for refinement, showcasing the exciting possibilities in the field of conversational AI and personalized recommendations!\n",
        "   </p>\n",
        "</div>"
      ],
      "metadata": {
        "id": "hED7w1P9rLZG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color:#F8FAFC; padding:10px; border-radius:5px; margin-top:15px; border:1px solid #E2E8F0; font-size: 0.9em;\">\n",
        "  <h4 style=\"color:#334155; margin-top:0; margin-bottom:5px;\">Data Sources & External Services Acknowledgement</h4>\n",
        "  <p style=\"color:#475569; margin:0; line-height: 1.5;\">\n",
        "    The Point of Interest (POI) data used in this project originates from <a href=\"https://en.wikivoyage.org/\" target=\"_blank\">Wikivoyage</a> and is licensed under <a href=\"https://creativecommons.org/licenses/by-sa/4.0/\" target=\"_blank\">CC BY-SA 4.0</a>. The specific CSV file was obtained from <a href=\"https://github.com/baturin/wikivoyage-listings\" target=\"_blank\">this GitHub repository</a> and processed for use within this agent.\n",
        "  </p>\n",
        "   <p style=\"color:#475569; margin-top:8px; line-height: 1.5;\">\n",
        "    This project also utilizes external APIs: (    Use of these services requires API keys and is subject to their respective terms of service. Placeholder data is used if keys are unavailable.)\n",
        "    <ul style=\"color:#475569; list-style-type: disc; margin-left: 20px; margin-top: 5px;\">\n",
        "        <li>Image fetching relies on the <a href=\"https://unsplash.com/developers\" target=\"_blank\">Unsplash API</a>.</li>\n",
        "        <li>Weather data is sourced from the <a href=\"https://openweathermap.org/api\" target=\"_blank\">OpenWeatherMap API</a>.</li>\n",
        "    </ul>\n",
        "  </p>\n",
        "</div>"
      ],
      "metadata": {
        "id": "vT6JIPJ4rLZH"
      }
    }
  ]
}